{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995c6fe9",
   "metadata": {},
   "source": [
    "## Dataset generation for GAN to learn NAKAGAMI channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6ae15a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:08:45.396047Z",
     "start_time": "2024-03-10T12:08:40.693786Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential,Model\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fad0f7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:08:45.411966Z",
     "start_time": "2024-03-10T12:08:45.397047Z"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super(GaussianNoise, self).__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 1 or training:\n",
    "            noise = tf.random.normal(tf.shape(inputs), stddev=self.stddev)\n",
    "            return inputs + noise\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GaussianNoise, self).get_config()\n",
    "        config.update({'stddev': self.stddev})\n",
    "        return config\n",
    "    \n",
    "    \n",
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.l2_normalize(inputs, axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "    \n",
    "\n",
    "def generate_nakagami_samples(m, omega, shape):\n",
    "\n",
    "    return tf.random.gamma(shape, m, 1/omega) ** 0.5\n",
    "    \n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if  1 or training:\n",
    "            # noise = tf.random.normal(tf.shape(inputs), **self.distribution_params)\n",
    "            if tf.shape(inputs)[0] == None:\n",
    "                noise = generate_nakagami_samples(m = self.distribution_params[\"m\"], \n",
    "                                              omega = self.distribution_params[\"omega\"], \n",
    "                                              shape = tf.shape(inputs))\n",
    "            else:\n",
    "                noise = generate_nakagami_samples(m = self.distribution_params[\"m\"], \n",
    "                                              omega = self.distribution_params[\"omega\"], \n",
    "                                              shape = tf.shape(inputs)[1:])\n",
    "            return inputs * noise\n",
    "        \n",
    "        else:\n",
    "            return inputs\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b23b0443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:08:45.428013Z",
     "start_time": "2024-03-10T12:08:45.412966Z"
    }
   },
   "outputs": [],
   "source": [
    "def calc_block_accuracy(preds,y_val):\n",
    "    n_bits_per_block = preds.shape[1]\n",
    "    n_correct_bits = np.sum(preds == y_val,axis=1)\n",
    "    block_accuracy = np.mean(n_correct_bits == n_bits_per_block)\n",
    "    return block_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6688e0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:08:45.443572Z",
     "start_time": "2024-03-10T12:08:45.430016Z"
    }
   },
   "outputs": [],
   "source": [
    "def nakagami_channel(m, omega, snr_db, num_samples):\n",
    "    \"\"\"\n",
    "    This function generates samples from a Nakagami-m fading channel.\n",
    "\n",
    "    Args:\n",
    "      m: Shape parameter of the Nakagami distribution (float).\n",
    "      omega: Scale parameter of the Nakagami distribution (float).\n",
    "      num_samples: Number of samples to generate (int).\n",
    "\n",
    "    Returns:\n",
    "      channel: Complex-valued channel coefficients (numpy.ndarray).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "\n",
    "    # Generate random variables from chi-squared distribution with 2*m degrees of freedom\n",
    "    chi_squared = 2 * m * np.random.chisquare(2 * m, size=num_samples)\n",
    "\n",
    "    # Generate real and imaginary parts from independent normal distributions\n",
    "    real_part = np.sqrt(chi_squared / (2 * omega)) * np.random.normal(scale=1, size=num_samples)\n",
    "    imag_part = np.sqrt(chi_squared / (2 * omega)) * np.random.normal(scale=1, size=num_samples)\n",
    "\n",
    "    # affect of noise\n",
    "    # r3ki3g added : noise\n",
    "    noise_var = 10**(-snr_db/10) / (2 * m)\n",
    "    noise_real = np.random.normal(scale=np.sqrt(noise_var), size=num_samples)\n",
    "    noise_imag = np.random.normal(scale=np.sqrt(noise_var), size=num_samples)\n",
    "    real_part += noise_real\n",
    "    imag_part += noise_imag\n",
    "    \n",
    "    # Combine real and imaginary parts into complex channel coefficients\n",
    "    channel = real_part + 1j * imag_part\n",
    "\n",
    "    return channel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39a9aa4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:08:45.458871Z",
     "start_time": "2024-03-10T12:08:45.444569Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating the data set\n",
    "k = 4\n",
    "M = 2**k\n",
    "\n",
    "NUM_CHANNEL_USES = 7\n",
    "\n",
    "n_train = 320 * 100\n",
    "n_val   = 320 * 100 \n",
    "\n",
    "x_train = np.array(np.random.rand(n_train,k)<0.5).astype(np.float32)\n",
    "y_train = x_train\n",
    "\n",
    "\n",
    "x_val = np.array(np.random.rand(n_val,k)<0.5).astype(np.float32)\n",
    "y_val = x_val\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfceff7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:10.899407Z",
     "start_time": "2024-03-10T12:08:45.475917Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  start ----------\n",
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "validation accuracy = 1.0\n"
     ]
    }
   ],
   "source": [
    "# complete_results = []\n",
    "\n",
    "# nakagami_m = 7\n",
    "# gamma_bar = 25\n",
    "# AWGN_std = np.sqrt(OMEGA * 10 ** (-0.1 * gamma_bar) )\n",
    "\n",
    "print(f\"-------  start ----------\")\n",
    "\n",
    "AE = Sequential([\n",
    "\n",
    "\n",
    "                Dense(2*k, activation='tanh',input_shape=(k,)),\n",
    "                Dense(2*k, activation='tanh'),\n",
    "\n",
    "                Dense(2*NUM_CHANNEL_USES, activation='linear'),\n",
    "                L2Normalization(name=\"normalization_layer\"),\n",
    "\n",
    "\n",
    "#                 NakagamiNoiseLayer({\"omega\":OMEGA,\"m\":nakagami_m}),\n",
    "#                 GaussianNoise(stddev=AWGN_std,name=\"channel\"),\n",
    "\n",
    "#                 L2Normalization(name=\"normalization_layer_at_rx\"),\n",
    "\n",
    "               # Dense(3*k, activation='tanh'),\n",
    "    \n",
    "                Dense(2*k, activation='tanh',name=\"decoder_start\"),\n",
    "                Dense(k, activation='sigmoid')\n",
    "\n",
    "\n",
    "\n",
    "                ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "AE.compile(optimizer=Adam(learning_rate=1e-2),loss=\"binary_crossentropy\")\n",
    "AE.fit(x_train,y_train,epochs=10,verbose=0)\n",
    "AE.compile(optimizer=Adam(learning_rate=1e-3),loss=\"binary_crossentropy\")\n",
    "AE.fit(x_train,y_train,epochs=10,verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "preds = AE.predict(x_val)>0.5\n",
    "#         accuracy = np.mean( preds == y_val  )\n",
    "accuracy =  calc_block_accuracy(preds,y_val)\n",
    "print(f\"validation accuracy = {accuracy}\")\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3051c75d",
   "metadata": {},
   "source": [
    "## Apply Nakagami effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbf18be",
   "metadata": {},
   "source": [
    "Need the encodings we present to the channel (i.e \"before_channel\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f99d604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:10.930379Z",
     "start_time": "2024-03-10T12:09:10.901351Z"
    }
   },
   "outputs": [],
   "source": [
    "AE_best = AE # not comparing.. we got only one\n",
    "\n",
    "before_channel = Model(inputs=AE_best.input,\n",
    "                                 outputs=AE_best.get_layer('normalization_layer').output)\n",
    "\n",
    "# not used\n",
    "after_channel = Model(inputs=AE_best.get_layer(\"decoder_start\").input,\n",
    "                                 outputs=AE_best.output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49ae1360",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:10.961341Z",
     "start_time": "2024-03-10T12:09:10.932373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.shape:  (32000, 14)\n",
      "iq_samples.shape:  (32000, 7)\n"
     ]
    }
   ],
   "source": [
    "# get encodings given by DNN for each message in training set\n",
    "enc = before_channel(x_train)\n",
    "print('enc.shape: ', enc.shape)\n",
    "\n",
    "# convert to iq_samples\n",
    "iq_samples = tf.complex(enc[:,0::2], enc[:,1::2])\n",
    "print('iq_samples.shape: ', iq_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbbaf467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:11.118604Z",
     "start_time": "2024-03-10T12:09:10.964330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nakagami_chanel_coeff_tensor.shape :  (100, 320, 7)\n",
      "iq_samples_blocked.shape :  (100, 320, 7)\n",
      "nakagami_affected_iq_samples.shape :  (32000, 7)\n"
     ]
    }
   ],
   "source": [
    "M_POOL       = [0.5,1,1.5]\n",
    "SNR_DB_POOL  = [1,3,6]\n",
    "\n",
    "nakagami_chanel_coeff_tensor = []\n",
    "\n",
    "block_size = 320\n",
    "n_blocks = enc.shape[0] // block_size \n",
    "for i in range(n_blocks):\n",
    "    m = np.random.choice(M_POOL)\n",
    "    snr_db = np.random.choice(SNR_DB_POOL)\n",
    "    nakagami_chanel_coeff_tensor.append( nakagami_channel(m=m, omega=1,snr_db=snr_db, num_samples=(block_size,iq_samples.shape[1])) )\n",
    "\n",
    "nakagami_chanel_coeff_tensor = tf.constant(nakagami_chanel_coeff_tensor)\n",
    "print(\"nakagami_chanel_coeff_tensor.shape : \",nakagami_chanel_coeff_tensor.shape)\n",
    "\n",
    "iq_samples_blocked = np.reshape(iq_samples,(n_blocks,block_size,-1))\n",
    "print(\"iq_samples_blocked.shape : \",iq_samples_blocked.shape)\n",
    "\n",
    "\n",
    "# tested identity flow (enc == received_enc)  with : nakagami_chanel_coeff_tensor =  tf.complex(1.,0.)\n",
    "\n",
    "# element wise multiply\n",
    "nakagami_affected_iq_samples = tf.multiply(nakagami_chanel_coeff_tensor,iq_samples_blocked)\n",
    "# undo the blockking\n",
    "nakagami_affected_iq_samples = tf.reshape(nakagami_affected_iq_samples,(block_size*n_blocks,-1))\n",
    "print(\"nakagami_affected_iq_samples.shape : \",nakagami_affected_iq_samples.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca43d9e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:11.134429Z",
     "start_time": "2024-03-10T12:09:11.119601Z"
    }
   },
   "outputs": [],
   "source": [
    "# nakagami_affected_iq_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9dc5d58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:11.164951Z",
     "start_time": "2024-03-10T12:09:11.135934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concat.shape :  (32000, 7, 2)\n",
      "received_enc.shape :  (32000, 14)\n"
     ]
    }
   ],
   "source": [
    "# need to convert each iq_samples to two encoding\n",
    "real_part =  tf.expand_dims(tf.math.real(nakagami_affected_iq_samples),axis=2)\n",
    "imag_part =  tf.expand_dims(tf.math.imag(nakagami_affected_iq_samples),axis=2)\n",
    "\n",
    "concat = tf.concat((real_part,imag_part),axis=2)\n",
    "print(\"concat.shape : \",concat.shape)\n",
    "received_enc = tf.cast(tf.reshape(concat,(block_size*n_blocks,-1)),tf.float32)\n",
    "print(\"received_enc.shape : \",received_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4dc6f2",
   "metadata": {},
   "source": [
    " ## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bf16b34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T12:09:11.195236Z",
     "start_time": "2024-03-10T12:09:11.166455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enc.shape:  (32000, 14)\n",
      "received_enc.shape:  (32000, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32000, 14), dtype=float32, numpy=\n",
       "array([[-1.3261299 ,  0.602655  ,  1.4276056 , ..., -1.3621914 ,\n",
       "        -0.22705135, -0.64842796],\n",
       "       [-1.3067806 , -0.03183903, -1.6282665 , ...,  0.02971514,\n",
       "         0.19386908,  0.00304524],\n",
       "       [ 0.09778717,  2.8510041 , -0.00686095, ...,  0.79351574,\n",
       "        -0.18268624,  0.33638853],\n",
       "       ...,\n",
       "       [-0.05811842,  0.19765921, -0.10650866, ..., -0.2597239 ,\n",
       "        -0.00629413,  0.31869596],\n",
       "       [-0.50941443,  0.8588244 ,  0.593     , ..., -0.40913337,\n",
       "         0.41534966,  0.2711795 ],\n",
       "       [-1.036339  , -1.2318798 , -0.2640725 , ..., -0.4004926 ,\n",
       "         0.9723525 , -0.63433707]], dtype=float32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enc is the encodings presenet to channel  \n",
    "# messages --> bits --> [trained DNN]  --> enc \n",
    "print('enc.shape: ', enc.shape)\n",
    "\n",
    "\n",
    "# received_enc is the encoding equavalent after Nakagami+noise effects considered\n",
    "# enc --> iq_samples --> [NAKAGAMI+noise effect]  --> affected_iq_smaples --> received_enc\n",
    "print('received_enc.shape: ', received_enc.shape)\n",
    "\n",
    "# see the difference done by the channel\n",
    "enc - received_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ad628",
   "metadata": {},
   "source": [
    "### Saving the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0f022e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448000, 1)\n",
      "(448000, 2)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "enc = np.reshape(enc,(-1,1))\n",
    "received_enc = np.reshape(received_enc,(-1,1))\n",
    "print(enc.shape)\n",
    "data = np.concatenate((enc,received_enc),axis=1)\n",
    "print(data.shape)\n",
    "df = pd.DataFrame(data)  \n",
    "df.to_csv(\"my_data.csv\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dcfafc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(448000,)\n",
      "(448000,)\n"
     ]
    }
   ],
   "source": [
    "df1 =  pd.read_csv('my_data.csv')\n",
    "print(df.iloc[:, 0].shape)\n",
    "print(np.array(df.iloc[:, 0]).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
