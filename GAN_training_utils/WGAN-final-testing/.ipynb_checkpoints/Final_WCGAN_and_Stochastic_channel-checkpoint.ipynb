{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.847986Z",
     "start_time": "2024-04-20T11:34:16.369189Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "#To datasets -> import tensorflow_datasets as tfds\n",
    "\n",
    "# For models\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, \\\n",
    "                                    Dropout, Embedding, Input, Concatenate #, Conv2DTranspose\n",
    "\n",
    "from scipy.stats import nakagami\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import uniform\n",
    "# For visualisation\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.863698Z",
     "start_time": "2024-04-20T11:34:32.847986Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating the data set\n",
    "k = 2\n",
    "M = 2**k\n",
    "\n",
    "NUM_CHANNEL_USES = 2\n",
    "\n",
    "   \n",
    "block_size = 32    # num of messages for frames we use, out of this, we use 1/4 as pilots and 3/4 as messages\n",
    "n_blocks_train = 10**4  ################\n",
    "n_blocks_val = 10**3\n",
    "n_blocks_train_GAN = 10**4 #10**5 ###############\n",
    "\n",
    "n_train = block_size * n_blocks_train\n",
    "n_val   = block_size * n_blocks_val\n",
    "\n",
    "n_train_GAN = block_size * n_blocks_train_GAN\n",
    "\n",
    "num_epoches_AE = 5\n",
    "num_epoches_WCGAN= 1 #100 ##########################\n",
    "\n",
    "WCGAN_training_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.879418Z",
     "start_time": "2024-04-20T11:34:32.865206Z"
    }
   },
   "outputs": [],
   "source": [
    "channel_parameters = {\n",
    "    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "    \"roll_off\" : 0.35,          # Roll off factor\n",
    "    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1) \n",
    "    #\"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period \n",
    "    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1 \n",
    "    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "}\n",
    "\n",
    "nakagami_m = 5 # m=1 for reighley\n",
    "OMEGA = np.sqrt(2)\n",
    "AWGN_std = np.sqrt(1/10**(channel_parameters['snr']/10))#np.sqrt(OMEGA * 10 ** (-0.1 * gamma_bar) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.895596Z",
     "start_time": "2024-04-20T11:34:32.879418Z"
    }
   },
   "outputs": [],
   "source": [
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        out = tf.nn.l2_normalize(inputs, axis=-1)\n",
    "        #print(\"normalize output shape = \",out.shape)\n",
    "        return out\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "    \n",
    "\n",
    "def generate_nakagami_samples(m, omega):\n",
    "      \n",
    "    nakagami_amp_vec = nakagami.rvs(m,omega,size =  NUM_CHANNEL_USES)   # Same gain for the real part and the imaginary part\n",
    "    nakagami_phase_vec = np.random.uniform(low=0.0, high=2*np.pi, size = NUM_CHANNEL_USES)    # phase shift will effect the complex number\n",
    "    nakagami_for_real = np.reshape(nakagami_amp_vec*np.cos(nakagami_phase_vec),(-1,1))\n",
    "    nakagami_for_imag = np.reshape(nakagami_amp_vec*np.sin(nakagami_phase_vec),(-1,1))\n",
    "    fading_vec = np.reshape(np.concatenate((nakagami_for_real,nakagami_for_imag),axis=1),(1,-1))[0]\n",
    "    return  tf.constant(fading_vec, dtype=tf.float32)\n",
    "    \n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "    def call(self, inputs, training=False):\n",
    "        if  1 or training:\n",
    "            fading = generate_nakagami_samples(m = self.distribution_params[\"m\"], \n",
    "                                              omega = self.distribution_params[\"omega\"]) \n",
    "            return inputs * fading\n",
    "        else:\n",
    "            return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.927306Z",
     "start_time": "2024-04-20T11:34:32.895596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Defining the stochastic channel \n",
    "\n",
    "# function to create the complex values\n",
    "def real_to_complex_tensor(inp_tensor):\n",
    "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
    "  real_part = inp_tensor[:, 0]\n",
    "  imag_part = inp_tensor[:, 1]\n",
    "  complex_tensor = tf.complex(real_part, imag_part)\n",
    "  return complex_tensor\n",
    "\n",
    "def complex_to_real_tensor(inp_tensor):\n",
    "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
    "   real_part = tf.reshape(real_part,[-1,1])\n",
    "   imag_part = tf.reshape(imag_part,[-1,1])\n",
    "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
    "\n",
    "# Upsample\n",
    "def upsampling(inp,r):\n",
    "  com_reshape = tf.reshape(inp,[-1,1])\n",
    "  padding = tf.constant([[0,0],[0,r-1]])\n",
    "  upsampled = tf.pad(com_reshape,padding,\"CONSTANT\")\n",
    "  return tf.reshape(upsampled,[-1])\n",
    "\n",
    "# Normalized RRC with time shift\n",
    "def NRRC_filter(num_taps, roll_off):\n",
    "  time_delay =  np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period \n",
    "  print(\"time_delay - \",time_delay)\n",
    "  t = np.linspace(-(num_taps-1)/2,(num_taps-1)/2,num_taps) - time_delay\n",
    "  eps = np.finfo(float).eps # Small epsilon to avoid divisiomn by zero\n",
    "  pi = np.pi\n",
    "  def RRC_filter_coff(t):\n",
    "    if abs(t) < eps:  # For t==0\n",
    "      return 1.0 - roll_off + (4*roll_off/pi)\n",
    "    elif roll_off != 0 and (abs(t-1/(4*roll_off))<eps or abs(t+1/(4*roll_off))<eps):\n",
    "      return (roll_off/np.sqrt(2))*(1 + 2/pi)*np.sin(pi/(4*roll_off)) + (1- 2/pi)*np.cos(pi/(4*roll_off))\n",
    "    else:\n",
    "      nu = np.sin(pi*t*(1-roll_off)) + 4*roll_off*t*np.cos(pi*t*(1+roll_off))\n",
    "      den = pi*t*(1-(4*roll_off*t)**2)\n",
    "      return nu/(den + eps)\n",
    "  filter_coff = np.array([RRC_filter_coff(T) for T in t])\n",
    "  NRRC_filter_coff = filter_coff / np.sum(np.abs(filter_coff))\n",
    "  plt.stem(t,NRRC_filter_coff)  # Plot for visualization\n",
    "  return tf.constant(NRRC_filter_coff,dtype = tf.float32)\n",
    "\n",
    "# Phase offset\n",
    "def PhaseOffset_vec(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "  l = batch_size*r*NUM_CHANNEL_USES+num_taps-1\n",
    "  CFO_off =truncnorm.rvs(-1.96,1.96)*CFO_std  # boundaries will be selected for 95% confidence  # 0.1*CFO_std\n",
    "  print(\"CFO_off =\",CFO_off)   \n",
    "  print(\"Phase offset = \",phase_off)                                          # CFO_min and CFO_max (boundaries) will be selected for 95% confidence\n",
    "  exp_vec = []\n",
    "  for i in range(l):\n",
    "    exp_vec.append(tf.math.exp(tf.constant([0+(2*np.pi*i*CFO_off+phase_off)*1j],dtype=tf.complex64)))\n",
    "  return tf.reshape(tf.stack(exp_vec),[-1])\n",
    "   \n",
    "\n",
    "class UpsamplingLayer(keras.layers.Layer):\n",
    "    def __init__(self, r ):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "    def call(self,inputs):\n",
    "       return upsampling(inputs,self.r)\n",
    "    \n",
    "class PulseShaping(keras.layers.Layer): \n",
    "    def __init__(self,num_taps,roll_off):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "    def call(self, inputs):\n",
    "      padding_size = self.num_taps // 2\n",
    "      paddings = tf.constant([[padding_size, padding_size]])\n",
    "      real_part = tf.pad(tf.math.real(inputs), paddings, \"CONSTANT\")\n",
    "      imag_part = tf.pad(tf.math.imag(inputs), paddings, \"CONSTANT\")\n",
    "      real_part = tf.reshape(real_part,[1,-1,1])\n",
    "      imag_part = tf.reshape(imag_part,[1,-1,1])\n",
    "      real_conv = tf.nn.conv1d(real_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      imag_conv = tf.nn.conv1d(imag_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      real_conv = tf.reshape(real_conv,[-1])\n",
    "      imag_conv = tf.reshape(imag_conv,[-1])\n",
    "      return tf.complex(real_conv,imag_conv)\n",
    "\n",
    "class PhaseOffset(keras.layers.Layer):\n",
    "    def __init__(self,batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "      super().__init__()\n",
    "      self.batch_size = batch_size\n",
    "      self.num_channel_uses = NUM_CHANNEL_USES\n",
    "      self.num_taps = num_taps\n",
    "      self.r = r\n",
    "      self.CFO_std = CFO_std\n",
    "      self.phase_off = phase_off\n",
    "    def call(self,inputs):\n",
    "       return inputs * PhaseOffset_vec(self.batch_size, self.num_channel_uses,self.num_taps,self.r,self.CFO_std, self.phase_off)\n",
    "\n",
    "class StochasticChannelLayer(keras.layers.Layer):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        channel_parameters ---> custom class for parameters store\n",
    "                                channel_parameters = {\n",
    "                                    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                                    \"roll_off\" : 0.35,          # Roll off factor\n",
    "                                    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                                    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                                    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1) \n",
    "                                    #\"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period \n",
    "                                    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                                    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                                    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1 \n",
    "                                    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain, \n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self,name,NUM_CHANNEL_USES,batch_size,channel_parameters,**kwargs):\n",
    "        super(StochasticChannelLayer,self).__init__(name=name,**kwargs)\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(channel_parameters['r'])\n",
    "        self.PulseShaping_inst = PulseShaping(channel_parameters['num_taps'],channel_parameters['roll_off'])\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['CFO_std'],channel_parameters['phase_off'])\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(channel_parameters['snr']/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.943295Z",
     "start_time": "2024-04-20T11:34:32.927306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decoder mask layer\n",
    "\n",
    "class PulseShaping_Dec(keras.layers.Layer): \n",
    "    def __init__(self,num_taps,r,roll_off):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "      self.r =r\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[1,-1,1])\n",
    "      inp_conv = tf.nn.conv1d(inputs,self.nrrc_filter,stride=self.r,padding=\"VALID\")\n",
    "      inp_conv = tf.reshape(inp_conv,[-1])\n",
    "      return inp_conv\n",
    "\n",
    "class DecoderMaskLayer(keras.layers.Layer):  \n",
    "    def __init__(self,name,channel_parameters,NUM_CHANNEL_USES):\n",
    "        super(DecoderMaskLayer,self).__init__(name=name)\n",
    "        # self.Convo = PulseShaping_Dec(channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['roll_off'])\n",
    "        self.Convo = tf.keras.layers.Conv1D(1,channel_parameters['num_taps'],strides=channel_parameters['r'], padding = 'valid',activation = 'relu',use_bias=True)\n",
    "        self.channel_uses = NUM_CHANNEL_USES\n",
    "    def call(self,inputs):\n",
    "        inp = tf.reshape(inputs,[-1,2])\n",
    "        real_part, imag_part = inp[:,0],inp[:,1]\n",
    "        vec_shape = real_part.shape[0]\n",
    "        #print(\"real shape\",real_part.shape)\n",
    "        real_part, imag_part = tf.reshape(real_part,[1,vec_shape,1]), tf.reshape(imag_part,[1,vec_shape,1])\n",
    "        real_part = tf.reshape(self.Convo(real_part),[-1,1])\n",
    "        imag_part = tf.reshape(self.Convo(imag_part),[-1,1])\n",
    "        #print(\"real shape after conv \",real_part.shape)\n",
    "        outputs = tf.concat([real_part,imag_part],1)\n",
    "        return tf.reshape(outputs,[-1,2*self.channel_uses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:32.959191Z",
     "start_time": "2024-04-20T11:34:32.943295Z"
    }
   },
   "outputs": [],
   "source": [
    "# To get the Encoder, channel and the decoder model for given parameteres\n",
    "\n",
    "def AE_out(k,NUM_CHANNEL_USES,num_epoches,channel_parameters):\n",
    "\n",
    "    # generating the data set\n",
    "    x_train = np.array(np.random.rand(n_train,k)<0.5).astype(np.float32)\n",
    "    y_train = x_train\n",
    "    x_val = np.array(np.random.rand(n_val,k)<0.5).astype(np.float32)\n",
    "    y_val = x_val\n",
    "\n",
    "    act_func = 'tanh' # 'relu'\n",
    "\n",
    "    print(f\"-------  start ----------\")\n",
    "\n",
    "    def create_AE():\n",
    "        AE = Sequential([\n",
    "\n",
    "                        Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "                        Dense(2**k, activation=act_func),\n",
    "                        Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "                        L2Normalization(name=\"normalization_layer\"),\n",
    "                        #L2Normalization_Range(NUM_CHANNEL_USES),####\n",
    "                        \n",
    "                        StochasticChannelLayer(\"st_channel\",NUM_CHANNEL_USES,block_size,channel_parameters), \n",
    "                        \n",
    "                        #NakagamiNoiseLayer({\"omega\":OMEGA,\"m\":nakagami_m}),\n",
    "                        #keras.layers.GaussianNoise(stddev = AWGN_std),\n",
    "\n",
    "                        DecoderMaskLayer(\"decoder_mask\",channel_parameters,NUM_CHANNEL_USES),\n",
    "                        Dense(2**k, activation=act_func,name=\"decoder_start\"),\n",
    "                        Dense(2**k, activation=act_func,name=\"decoder_middle\"),\n",
    "                        Dense(k, activation='sigmoid')\n",
    "\n",
    "                        ])\n",
    "        return AE\n",
    "\n",
    "    AE = create_AE()\n",
    "    AE.summary()\n",
    "    history = []\n",
    "\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              patience=3)\n",
    "    AE.compile(optimizer=Adam(learning_rate=1e-2),loss=\"binary_crossentropy\")\n",
    "    history.append(AE.fit(x_train,y_train,batch_size=block_size,epochs=num_epoches,verbose=2,validation_data=(x_val,y_val),callbacks=[callback]))\n",
    "    AE.compile(optimizer=Adam(learning_rate=1e-3),loss=\"binary_crossentropy\")\n",
    "    history.append(AE.fit(x_train,y_train,batch_size=block_size,epochs=num_epoches,verbose=2,validation_data=(x_val,y_val),callbacks=[callback]))\n",
    "\n",
    "    preds = AE.predict(x_val,batch_size=block_size)>0.5\n",
    "    #         accuracy = np.mean( preds == y_val  )\n",
    "    def calc_block_accuracy(preds,y_val):\n",
    "        n_bits_per_block = preds.shape[1]\n",
    "        n_correct_bits = np.sum(preds == y_val,axis=1)\n",
    "        block_accuracy = np.mean(n_correct_bits == n_bits_per_block)\n",
    "        return block_accuracy\n",
    "    accuracy =  calc_block_accuracy(preds,y_val)\n",
    "    print(f\"validation accuracy = {accuracy}\")\n",
    "\n",
    "    encoder = Model(inputs=AE.input,outputs=AE.get_layer('normalization_layer').output)\n",
    "    channel = Model(inputs = AE.get_layer(\"st_channel\").input,outputs=AE.get_layer(\"st_channel\").output)\n",
    "    decoder = Model(inputs=AE.get_layer(\"decoder_mask\").input,outputs=AE.output)\n",
    "\n",
    "    return  encoder , channel, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional wasserstein GAN\n",
    "https://www.kaggle.com/code/ritvik1909/wasserstein-gan-with-gradient-penalty\n",
    "\n",
    "https://github.com/Mohammad-Rahmdel/WassersteinGAN-GradientPenalty-Tensorflow/blob/master/WGAN-GP_MNIST.ipynb\n",
    "\n",
    "https://machinelearningmastery.com/how-to-code-a-wasserstein-generative-adversarial-network-wgan-from-scratch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:34.085584Z",
     "start_time": "2024-04-20T11:34:32.959191Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 828)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 956)          0           ['input_1[0][0]',                \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          122496      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 128)          0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          16512       ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 572)          73788       ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 229,308\n",
      "Trainable params: 229,308\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 572)]        0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 828)]        0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1400)         0           ['input_3[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 32)           44832       ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 32)           0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           1056        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 32)           0           ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           1056        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 32)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1)            33          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 46,977\n",
      "Trainable params: 46,977\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Conditional Wasserstein GAN\n",
    "\n",
    "\"\"\"\n",
    "Conditional info ----> Pilot encoder symbols  + Channel outputs for pilot symbols +  + Encoder outputs (all the channel uses)\n",
    "                       If the num_channel_uses = 2, there will be two vectors of length 4,  concaternated. \n",
    "                       block_size = 32\n",
    "                       num_taps = 31\n",
    "                       upsampling factor = 4  \n",
    "                       First vector is the real and imaginary of the encoder outputs (4)\n",
    "                       Pilot encoder symbols  -> 2* NUM_CHANNEL_USES * block_size = 128\n",
    "                       Channel outputs for pilot symbols -> 2* NUM_CHANNEL_USES * block_size*channel_parameters['r']+2*(channel_parameters['num_taps']-1) = 572\n",
    "Genarator inputs ----> Noise vector of encoder outpus size (2* NUM_CHANNEL_USES * block_size = 128) + conditional infomation\n",
    "Discriminator inputs -> Channel output of real samples + conditional information\n",
    " \"\"\"\n",
    "\n",
    "def build_generator():\n",
    "    inp_length = 2* NUM_CHANNEL_USES * block_size\n",
    "    noise = Input(shape= (inp_length,))\n",
    "    # input_pilot_conditional = Input(shape=(inp_length,))\n",
    "    # channel_output_pilot_conditionals = Input(shape=(inp_length*channel_parameters['r']+2*(channel_parameters['num_taps']-1),))\n",
    "    # enc_out_conditional = Input(shape = (inp_length,))#(shape=(2,)) # real and imag parts of any symbol\n",
    "    conditional_arr = Input(shape=(2*inp_length+inp_length*channel_parameters['r']+2*(channel_parameters['num_taps']-1)),)\n",
    "    concat = Concatenate()([noise,conditional_arr])\n",
    "\n",
    "    l = Dense(128)(concat)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(128)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(128)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    output = Dense(inp_length*channel_parameters['r']+2*(channel_parameters['num_taps']-1),activation='linear')(l)#(2,activation = 'linear')(l) # real and imag parts of any symbol\n",
    "\n",
    "    model = Model([noise,conditional_arr],output)\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "generator.summary()\n",
    "# tf.keras.utils.plot_model(generator, show_shapes=True)\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    inp_length = 2* NUM_CHANNEL_USES * block_size\n",
    "    dicr_inp = Input(shape =(inp_length*channel_parameters['r']+2*(channel_parameters['num_taps']-1),))\n",
    "    # input_pilot_conditional = Input(shape=(inp_length,))#(2  **k  *NUM_CHANNEL_USES  *2,))\n",
    "    # channel_output_pilot_conditionals = Input(shape=(inp_length*channel_parameters['r']+2*(channel_parameters['num_taps']-1),))\n",
    "    # enc_out_conditional = Input(shape = (inp_length,))#(shape=(2,)) # real and imag parts of any symbol\n",
    "    conditional_arr = Input(shape=(2*inp_length+inp_length*channel_parameters['r']+2*(channel_parameters['num_taps']-1)),)\n",
    "    concat = Concatenate()([dicr_inp,conditional_arr])\n",
    "\n",
    "    l = Dense(32)(concat)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(32)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(32)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    output = Dense(1,activation = 'linear')(l)\n",
    "\n",
    "    model = Model([dicr_inp,conditional_arr],output)\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "discriminator.summary()\n",
    "# tf.keras.utils.plot_model(discriminator, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:34.100645Z",
     "start_time": "2024-04-20T11:34:34.085584Z"
    }
   },
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty(batch_size, real, fake, conditional_arr,discriminator):\n",
    "    epsilon = tf.random.normal([batch_size, 1], 0.0, 1.0)#tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon*real + (1-epsilon)*fake #real + epsilon * diff\n",
    "    interpolated=[interpolated,conditional_arr]##############\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm =tf.sqrt(tf.reduce_sum(tf.square(grads[0]), axis=[1])+tf.reduce_sum(tf.square(grads[1]), axis=[1])) #tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T11:34:34.258849Z",
     "start_time": "2024-04-20T11:34:34.105673Z"
    }
   },
   "outputs": [],
   "source": [
    "# CWGAN definition\n",
    "# https://www.kaggle.com/code/ritvik1909/wasserstein-gan-with-gradient-penalty\n",
    "\n",
    "# optimizers\n",
    "opt_g = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "opt_d = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "\n",
    "# models remain the same\n",
    "generator_CWGAN = build_generator()\n",
    "discriminator_CWGAN = build_discriminator()\n",
    "\n",
    "# custom training step to include Wasserstein loss and gradient penalty\n",
    "class WGANGP(Model):\n",
    "    def __init__(self ,latent_dim ,discriminator_extra_steps , generator, discriminator, **kwargs):\n",
    "        super(WGANGP, self).__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim        # 2*NUM_CHANNEL_USES prefered\n",
    "        self.d_steps = discriminator_extra_steps    # prefered 5\n",
    "        self.lambda_gp = 10.0  # gradient penalty weight\n",
    "\n",
    "    def compile(self, g_optimizer, d_optimizer,**kwargs): #, g_loss_fn, d_loss_fn, **kwargs):\n",
    "        super(WGANGP, self).compile(**kwargs)\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        #self.g_loss_fn = g_loss_fn\n",
    "        #self.d_loss_fn = d_loss_fn\n",
    "\n",
    "    def train_step(self,dataset):# real_channel_outputs,input_pilot_conditionals,channel_output_pilot_conditionals,enc_out_conditional ):\n",
    "\n",
    "        real_channel_outputs,conditional_arr = dataset\n",
    "\n",
    "        ########################################\n",
    "        # if isinstance(real_channel_outputs, tuple):\n",
    "        #     real_channel_outputs = real_channel_outputs[0]\n",
    "\n",
    "        batch_size = tf.shape(real_channel_outputs)[0]\n",
    "        #print(\"GAN batch \",tf.shape(real_channel_outputs)[0])\n",
    "\n",
    "        # train discriminator (critic)\n",
    "        for _ in range(self.d_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            inputs = [random_latent_vectors,conditional_arr]\n",
    "            real_channel_dic_in = [real_channel_outputs,conditional_arr]\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_channel_outputs = self.generator(inputs, training=True)\n",
    "                fake_channel_disc_in = [fake_channel_outputs,conditional_arr]\n",
    "                fake_logits = self.discriminator(fake_channel_disc_in, training=True)\n",
    "                real_logits = self.discriminator(real_channel_dic_in, training=True)\n",
    "                # d_cost = self.d_loss_fn(tf.ones_like(real_logits), real_logits) + \\\n",
    "                #         self.d_loss_fn(-tf.ones_like(fake_logits), fake_logits)\n",
    "                d_cost = -tf.reduce_mean(real_logits) + tf.reduce_mean(fake_logits)\n",
    "                gp = gradient_penalty(batch_size, real_channel_outputs, fake_channel_outputs, conditional_arr,self.discriminator)\n",
    "                d_loss = d_cost + self.lambda_gp * gp\n",
    "\n",
    "            d_grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # train generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        inputs = [random_latent_vectors,conditional_arr]\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_channel_outputs = self.generator(inputs, training=True)\n",
    "            generated_disc_in = [generated_channel_outputs,conditional_arr]\n",
    "            generated_channel_output_logits = self.discriminator(generated_disc_in, training=True)\n",
    "            g_loss = -tf.reduce_mean(generated_channel_output_logits) #self.g_loss_fn(-tf.ones_like(generated_channel_output_logits), generated_channel_output_logits)\n",
    "\n",
    "        g_grads = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n",
    "\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}\n",
    "\n",
    "# # compile the model\n",
    "# gan = WGANGP(2*NUM_CHANNEL_USES,5,generator_CWGAN, discriminator_CWGAN)\n",
    "# gan.summary()\n",
    "# gan.compile(\n",
    "#     g_optimizer=opt_g,\n",
    "#     d_optimizer=opt_d,\n",
    "#     #g_loss_fn=wasserstein_loss,\n",
    "#     #d_loss_fn=wasserstein_loss,\n",
    "# )\n",
    "\n",
    "# # training\n",
    "# history = gan.fit(dataset, batch_size=block_size, epochs=num_epoches_WCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T12:03:00.503119Z",
     "start_time": "2024-04-20T12:03:00.496925Z"
    }
   },
   "outputs": [],
   "source": [
    "full_message_space = []\n",
    "for i in range(2**k):\n",
    "    binary_str = bin(i)[2:]\n",
    "    binary_str = binary_str.zfill(k)\n",
    "    binary_int_list = [int(bit) for bit in binary_str]\n",
    "    full_message_space.append(binary_int_list)\n",
    "assert block_size%2**k==0 and block_size>=2**k, \"cannot insert the pilots\"\n",
    "\n",
    "pilot_portion_of_block = np.tile(np.array(full_message_space),(8//(2**k),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T12:06:34.369414Z",
     "start_time": "2024-04-20T12:06:34.355349Z"
    }
   },
   "outputs": [],
   "source": [
    "if False and \"just testing the below function \":\n",
    "    n_train_GAN_payload = n_train_GAN//4  *3 # onlt 75% payload --> 25% pilots\n",
    "    x_train_GAN_payload = np.array(np.random.rand(n_train_GAN_payload,k)<0.5).astype(np.float32)\n",
    "    x_train_GAN = np.zeros((n_train_GAN,k))\n",
    "    for block_i in range(n_blocks_train_GAN//4):\n",
    "        x_train_GAN[32*block_i:32*block_i+8,:] = pilot_portion_of_block\n",
    "        x_train_GAN[32*block_i+8:32*(block_i+1),:] = x_train_GAN_payload[24*block_i:24*(block_i+1),:]\n",
    "\n",
    "    print(np.all(x_train_GAN[0:8,:] == x_train_GAN[32:40,:])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T12:06:52.815368Z",
     "start_time": "2024-04-20T12:06:52.805274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create GAN dataset\n",
    "\"\"\"\n",
    "ex:- \n",
    "    block_size = 32\n",
    "    NUM_CHANNEL_USES = 2\n",
    "    r = 4 (upsampling factor in the channel)\n",
    "    num_taps = 31 (taps for RRC filter used in the channel)\n",
    "\n",
    "    For a block,\n",
    "    expected channel input size = block_size,2*NUM_CHANNEL_USES = (32,4)\n",
    "    expected channel output size = block_size*2*NUM_CHANNEL_USES*r + 2*(num_taps-1) \n",
    "                                 = 32*2*2*4 + 2*(31-1) = 572\n",
    "    conditionala_array ---> channel_input_pilot_samples (32*4 =128) + channel_output_pilot_samples (32*4*4+2*(31-1) = 572) + encoder_output (channel input) (32*4=128)\n",
    "    \"\"\"\n",
    "\n",
    "def creat_GAN_dataset(k,NUM_CHANNEL_USES,encoder,channel,channel_parameters):\n",
    "    n_train_GAN_payload = n_train_GAN//4  *3 # onlt 75% payload --> 25% pilots\n",
    "    x_train_GAN_payload = np.array(np.random.rand(n_train_GAN_payload,k)<0.5).astype(np.float32)\n",
    "    x_train_GAN = np.zeros((n_train_GAN,k))\n",
    "    for block_i in range(n_blocks_train_GAN//4):\n",
    "        x_train_GAN[32*block_i:32*block_i+8,:] = pilot_portion_of_block\n",
    "        x_train_GAN[32*block_i+8:32*(block_i+1),:] = x_train_GAN_payload[24*block_i:24*(block_i+1),:]\n",
    "    \n",
    "    enc_out = encoder.predict(x_train_GAN,batch_size=block_size)\n",
    "    print(enc_out.shape)\n",
    "    channel_out = channel.predict(enc_out, batch_size = block_size)\n",
    "    print(channel_out.shape)\n",
    "    chan_out_block_size=(block_size*channel_parameters['r']*2*NUM_CHANNEL_USES+2*(channel_parameters['num_taps']-1))\n",
    "    print(\"chan_out_block_size = \",chan_out_block_size)\n",
    "\n",
    "    enc_out = np.reshape(enc_out,(-1,4,block_size*2*NUM_CHANNEL_USES))\n",
    "    channel_out = np.reshape(channel_out,(-1,4,chan_out_block_size))\n",
    "    enc_out_p_arr = np.reshape(np.repeat(enc_out[:,0,:],3,0),(-1,block_size*2*NUM_CHANNEL_USES))    # No need to reshape\n",
    "    enc_out_cond_arr= np.reshape(enc_out[:,1:4,:],(-1,block_size*2*NUM_CHANNEL_USES))\n",
    "    chan_out_p_arr = np.reshape(np.repeat(channel_out[:,0,:],3,0),(-1,chan_out_block_size)) # No need to reshape\n",
    "    chan_out_real_arr = np.reshape(channel_out[:,1:4,:],(-1,chan_out_block_size))\n",
    "    \n",
    "    conditional_arr = np.concatenate((enc_out_p_arr, chan_out_p_arr,enc_out_cond_arr),axis = 1)\n",
    "    return chan_out_real_arr, conditional_arr\n",
    "\n",
    "# chan_out_real_arr, conditional_arr = creat_GAN_dataset(k,NUM_CHANNEL_USES,encoder,channel,channel_parameters)\n",
    "# print(\"chan_out_real_arr shape\",chan_out_real_arr.shape)\n",
    "# print(\"conditional_arr shape\",conditional_arr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the GAN model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T12:06:55.266949Z",
     "start_time": "2024-04-20T12:06:55.245376Z"
    }
   },
   "outputs": [],
   "source": [
    "def Train_and_Get_CWGAN(channel_parameters_list,k,NUM_CHANNEL_USES):\n",
    "\n",
    "    # optimizers\n",
    "    opt_g = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "    opt_d = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "    # models remain the same\n",
    "    generator_CWGAN = build_generator()\n",
    "    discriminator_CWGAN = build_discriminator()\n",
    "    # compile the model\n",
    "    gan = WGANGP(2*NUM_CHANNEL_USES*block_size,5,generator_CWGAN, discriminator_CWGAN)\n",
    "    gan.compile(\n",
    "        g_optimizer=opt_g,\n",
    "        d_optimizer=opt_d,\n",
    "        #g_loss_fn=wasserstein_loss,\n",
    "        #d_loss_fn=wasserstein_loss,\n",
    "    )\n",
    "\n",
    "    # the part below will train the model for different channel instances\n",
    "\n",
    "    history = []\n",
    "    i=0\n",
    "    for channel_parameters in channel_parameters_list:\n",
    "\n",
    "        # GAN dataset\n",
    "        if i==0:\n",
    "            encoder , channel, decoder = AE_out(k,NUM_CHANNEL_USES,num_epoches_AE,channel_parameters)   # need to fix encoder after the first channel, if we train for sevaral channels\n",
    "            encoder_1=encoder\n",
    "            decoder_1=decoder\n",
    "            channel_1=channel\n",
    "        else:\n",
    "            inp_length = 2* NUM_CHANNEL_USES * block_size\n",
    "            chan_model = Sequential([\n",
    "                Input(shape= (inp_length,)),\n",
    "                StochasticChannelLayer(\"st_channel\",NUM_CHANNEL_USES,block_size,channel_parameters)])\n",
    "            channel = Model(inputs = chan_model.get_layer(\"st_channel\").input,outputs=chan_model.get_layer(\"st_channel\").output) \n",
    "\n",
    "        chan_out_real_arr, conditional_arr = creat_GAN_dataset(k,NUM_CHANNEL_USES,encoder_1,channel,channel_parameters)\n",
    "        i+=1\n",
    "        # training\n",
    "        history.append(gan.fit(chan_out_real_arr, conditional_arr, batch_size=WCGAN_training_batch_size, epochs=num_epoches_WCGAN))\n",
    "\n",
    "    return gan , encoder_1, channel_1, decoder_1, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-20T12:06:56.453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  start ----------\n",
      "time_delay -  (0.8792610811127999,)\n",
      "CFO_off = -0.016086844081690227\n",
      "Phase offset =  5.961698624639039\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 4)                 12        \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 20        \n",
      "                                                                 \n",
      " Encode_last_dense (Dense)   (None, 4)                 20        \n",
      "                                                                 \n",
      " normalization_layer (L2Norm  (None, 4)                0         \n",
      " alization)                                                      \n",
      "                                                                 \n",
      " st_channel (StochasticChann  (572,)                   0         \n",
      " elLayer)                                                        \n",
      "                                                                 \n",
      " decoder_mask (DecoderMaskLa  (32, 4)                  32        \n",
      " yer)                                                            \n",
      "                                                                 \n",
      " decoder_start (Dense)       (32, 4)                   20        \n",
      "                                                                 \n",
      " decoder_middle (Dense)      (32, 4)                   20        \n",
      "                                                                 \n",
      " dense_26 (Dense)            (32, 2)                   10        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134\n",
      "Trainable params: 134\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "CFO_off = -0.015425211537552304\n",
      "Phase offset =  5.961698624639039\n",
      "CFO_off = -0.0006334432809634866\n",
      "Phase offset =  5.961698624639039\n",
      "CFO_off = 0.019968369841700254\n",
      "Phase offset =  5.961698624639039\n",
      "10000/10000 - 17s - loss: 0.3788 - val_loss: 0.9183 - 17s/epoch - 2ms/step\n",
      "Epoch 2/5\n",
      "10000/10000 - 14s - loss: 0.3697 - val_loss: 0.9482 - 14s/epoch - 1ms/step\n",
      "Epoch 3/5\n",
      "10000/10000 - 14s - loss: 0.3689 - val_loss: 0.9612 - 14s/epoch - 1ms/step\n",
      "Epoch 4/5\n",
      "10000/10000 - 15s - loss: 0.3696 - val_loss: 0.9614 - 15s/epoch - 1ms/step\n",
      "Epoch 1/5\n",
      "CFO_off = 0.000511608214449425\n",
      "Phase offset =  5.961698624639039\n",
      "CFO_off = 0.01588086400671074\n",
      "Phase offset =  5.961698624639039\n",
      "CFO_off = 0.016308447182085784\n",
      "Phase offset =  5.961698624639039\n",
      "10000/10000 - 17s - loss: 0.6929 - val_loss: 0.6807 - 17s/epoch - 2ms/step\n",
      "Epoch 2/5\n",
      "10000/10000 - 15s - loss: 0.6679 - val_loss: 0.5940 - 15s/epoch - 1ms/step\n",
      "Epoch 3/5\n"
     ]
    }
   ],
   "source": [
    "channel_parameters = {\n",
    "                        \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                        \"roll_off\" : 0.35,          # Roll off factor\n",
    "                        \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                        \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                        \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1) \n",
    "                        #\"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period \n",
    "                        \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                        \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                        \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1 \n",
    "                        \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }   \n",
    "\n",
    "# If the moedl needs to be trained for different channel instances, add thoes channel parameteres inside the channel_parameteres_list\n",
    "channel_parameters_list = [channel_parameters]\n",
    "cwgan , encoder, channel,decoder, history = Train_and_Get_CWGAN(channel_parameters_list,k,NUM_CHANNEL_USES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-20T12:07:01.093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ploting\n",
    "print(history[0].history.keys())\n",
    "plt.plot(history[0].history['d_loss']) # history[0] for the first channel instance\n",
    "plt.plot(history[0].history['g_loss'])\n",
    "plt.title('plot of losses '+str(num_epoches_WCGAN)+' epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['d_loss', 'g_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 10s 957us/step\n",
      "(320000, 4)\n",
      "10000/10000 [==============================] - 11s 1ms/step\n",
      "(5720000,)\n",
      "chan_out_block_size =  572\n",
      "118/118 [==============================] - 0s 3ms/step\n",
      "chan_out_real_arr shape (7500, 572)\n",
      "conditional_arr shape (7500, 828)\n",
      "gan_out shape (7500, 572)\n",
      "(4290000,)\n",
      "(4290000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chan_out_real_arr, conditional_arr = creat_GAN_dataset(k,NUM_CHANNEL_USES,encoder,channel,channel_parameters)\n",
    "\n",
    "random_latent_vectors = tf.random.normal(shape=(conditional_arr.shape[0], 2*NUM_CHANNEL_USES*block_size))\n",
    "gan_inputs = [random_latent_vectors, conditional_arr]\n",
    "gan_out = cwgan.generator.predict(gan_inputs,batch_size=64)\n",
    "\n",
    "print(\"chan_out_real_arr shape\",chan_out_real_arr.shape)\n",
    "print(\"conditional_arr shape\",conditional_arr.shape)\n",
    "print(\"gan_out shape\",gan_out.shape)\n",
    "\n",
    "chan_out_values = np.reshape(chan_out_real_arr,(-1))\n",
    "gan_out_values = np.reshape(gan_out,(-1))\n",
    "print(chan_out_values.shape)\n",
    "print(gan_out_values.shape)\n",
    "\n",
    "# Creating multiple histograms\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 4))\n",
    "axes[0].hist(chan_out_values, bins=30, color='Yellow', edgecolor='black')\n",
    "axes[0].set_title('chan_out hist')\n",
    " \n",
    "axes[1].hist(gan_out_values, bins=30, color='Pink', edgecolor='black')\n",
    "axes[1].set_title('gen_out hist')\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('Values')\n",
    "    ax.set_ylabel('Frequency')\n",
    " \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
