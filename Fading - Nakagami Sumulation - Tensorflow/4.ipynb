{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6ae15a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:17:52.675617Z",
     "start_time": "2024-02-06T10:17:48.690308Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential,Model\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad0f7e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:17:58.459515Z",
     "start_time": "2024-02-06T10:17:58.450168Z"
    }
   },
   "outputs": [],
   "source": [
    "class GaussianNoise(tf.keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super(GaussianNoise, self).__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if 1 or training:\n",
    "            noise = tf.random.normal(tf.shape(inputs), stddev=self.stddev)\n",
    "            return inputs + noise\n",
    "        return inputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(GaussianNoise, self).get_config()\n",
    "        config.update({'stddev': self.stddev})\n",
    "        return config\n",
    "    \n",
    "    \n",
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.l2_normalize(inputs, axis=-1)\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "    \n",
    "\n",
    "def generate_nakagami_samples(m, omega, shape):\n",
    "\n",
    "    return tf.random.gamma(shape, m, 1/omega) ** 0.5\n",
    "    \n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        if  1 or training:\n",
    "            # noise = tf.random.normal(tf.shape(inputs), **self.distribution_params)\n",
    "            if tf.shape(inputs)[0] == None:\n",
    "                noise = generate_nakagami_samples(m = self.distribution_params[\"m\"], \n",
    "                                              omega = self.distribution_params[\"omega\"], \n",
    "                                              shape = tf.shape(inputs))\n",
    "            else:\n",
    "                noise = generate_nakagami_samples(m = self.distribution_params[\"m\"], \n",
    "                                              omega = self.distribution_params[\"omega\"], \n",
    "                                              shape = tf.shape(inputs)[1:])\n",
    "            return inputs * noise\n",
    "        \n",
    "        else:\n",
    "            return inputs\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39a9aa4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:17:59.805359Z",
     "start_time": "2024-02-06T10:17:59.773856Z"
    }
   },
   "outputs": [],
   "source": [
    "# generating the data set\n",
    "k = 7 #3\n",
    "M = 2**k\n",
    "\n",
    "\n",
    "n_train = 1000 * M\n",
    "n_val = 100 * M\n",
    "\n",
    "x_train = np.array(np.random.rand(n_train,k)<0.5).astype(np.float32)\n",
    "y_train = x_train\n",
    "\n",
    "\n",
    "x_val = np.array(np.random.rand(n_val,k)<0.5).astype(np.float32)\n",
    "y_val = x_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfceff7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:22:32.978444Z",
     "start_time": "2024-02-06T10:18:02.760542Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------  start of attempt : 1 ----------\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4751\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4653\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4658\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4645\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4632\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4645\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4640\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4657\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4638\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4634\n",
      "400/400 [==============================] - 0s 827us/step\n",
      "accuracy = 0.6879799107142858\n",
      "-------  start of attempt : 2 ----------\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4763\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4658\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4649\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4647\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4638\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4635\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4643\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4641\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4643\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4638\n",
      "400/400 [==============================] - 0s 681us/step\n",
      "accuracy = 0.6903348214285714\n",
      "-------  start of attempt : 3 ----------\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4789\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4642\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4639\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4636\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4647\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4645\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4630\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4631\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4639\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4631\n",
      "400/400 [==============================] - 0s 716us/step\n",
      "accuracy = 0.6858370535714285\n",
      "-------  start of attempt : 4 ----------\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4807\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4655\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4642\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4653\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4641\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4645\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4635\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4647\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4650\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 4s 1ms/step - loss: 0.4638\n",
      "400/400 [==============================] - 0s 722us/step\n",
      "accuracy = 0.6898995535714286\n",
      "-------  start of attempt : 5 ----------\n",
      "Epoch 1/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4752\n",
      "Epoch 2/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4648\n",
      "Epoch 3/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4661\n",
      "Epoch 4/10\n",
      "4000/4000 [==============================] - 6s 1ms/step - loss: 0.4653\n",
      "Epoch 5/10\n",
      "4000/4000 [==============================] - 5s 1ms/step - loss: 0.4640\n",
      "Epoch 6/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4644\n",
      "Epoch 7/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4647\n",
      "Epoch 8/10\n",
      "4000/4000 [==============================] - 8s 2ms/step - loss: 0.4646\n",
      "Epoch 9/10\n",
      "4000/4000 [==============================] - 7s 2ms/step - loss: 0.4636\n",
      "Epoch 10/10\n",
      "4000/4000 [==============================] - 6s 2ms/step - loss: 0.4646\n",
      "400/400 [==============================] - 0s 827us/step\n",
      "accuracy = 0.6893638392857143\n",
      "Accuracies:  [0.6879799107142858, 0.6903348214285714, 0.6858370535714285, 0.6898995535714286, 0.6893638392857143]\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "models = []\n",
    "attempts = 0\n",
    "while True:\n",
    "        attempts += 1\n",
    "        print(f\"-------  start of attempt : {attempts} ----------\")\n",
    "        AE = Sequential([\n",
    "            \n",
    "\n",
    "                                Dense(2*k, activation='tanh',input_shape=(k,)),\n",
    "                                Dense(2*k, activation='tanh'),\n",
    "\n",
    "                                Dense(2, activation='linear'),\n",
    "                                L2Normalization(name=\"normalization_layer\"),\n",
    "\n",
    "\n",
    "                                NakagamiNoiseLayer({\"omega\":1,\"m\":5}),\n",
    "                                GaussianNoise(stddev=0.51,name=\"channel\"),\n",
    "\n",
    "                                L2Normalization(name=\"normalization_layer_at_rx\"),\n",
    "\n",
    "                                Dense(2*k, activation='tanh'),\n",
    "                                Dense(k, activation='sigmoid')\n",
    "\n",
    "\n",
    "\n",
    "                        ])\n",
    "\n",
    "        AE.build()\n",
    "        #     AE.summary()\n",
    "        \n",
    "        AE.compile(optimizer=Adam(learning_rate=1e-2),loss=\"binary_crossentropy\")\n",
    "        AE.fit(x_train,y_train,epochs=10,)\n",
    "        \n",
    "        preds = AE.predict(x_val)>0.5\n",
    "        accuracy = np.mean( preds == y_val  )\n",
    "        print(f\"accuracy = {accuracy}\")\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        models.append(AE)\n",
    "        \n",
    "        if accuracy > 0.97 or attempts >= 5:\n",
    "            break\n",
    "        \n",
    "        \n",
    "        \n",
    "print(\"Accuracies: \", accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72daf727",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efc35c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:08:26.830676Z",
     "start_time": "2024-02-06T10:08:26.800701Z"
    }
   },
   "outputs": [],
   "source": [
    "# select the best out of all the AE models saved in AE\n",
    "bestIndex = np.argmax(accuracies)\n",
    "print(\"best accuracy: \", max(accuracies))\n",
    "AE_best = models[bestIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d1097c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T05:26:48.093363Z",
     "start_time": "2024-02-06T05:26:48.077501Z"
    }
   },
   "outputs": [],
   "source": [
    "# bc = before_channel.predict(np.array([\n",
    "    \n",
    "#     [0,0],\n",
    "#     [0,1],\n",
    "#     [1,0],\n",
    "#     [1,1]\n",
    "  \n",
    "    \n",
    "# ]))\n",
    "\n",
    "\n",
    "\n",
    "# bc = before_channel.predict(np.array([\n",
    "\n",
    "#             [0,0,0,0],\n",
    "#             [0,0,0,1],\n",
    "#             [0,0,1,0],\n",
    "#             [0,0,1,1],\n",
    "#             [0,1,0,0],\n",
    "#             [0,1,0,1],\n",
    "#             [0,1,1,0],\n",
    "#             [0,1,1,1],\n",
    "#             [1,0,0,0],\n",
    "#             [1,0,0,1],\n",
    "#             [1,0,1,0],\n",
    "#             [1,0,1,1],\n",
    "#             [1,1,0,0],\n",
    "#             [1,1,0,1],\n",
    "#             [1,1,1,0],\n",
    "#             [1,1,1,1]\n",
    "    \n",
    "# ]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e19db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:04:16.260108Z",
     "start_time": "2024-02-06T10:04:14.934057Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "before_channel = Model(inputs=AE_best.input,\n",
    "                                 outputs=AE_best.get_layer('normalization_layer').output)\n",
    "\n",
    "after_channel  = Model(inputs=AE_best.input,\n",
    "                                 outputs=AE_best.get_layer('channel').output)\n",
    "\n",
    "after_channel_normalized = Model(inputs=AE_best.input,\n",
    "                                 outputs=AE_best.get_layer('normalization_layer_at_rx').output)\n",
    "    \n",
    "    \n",
    "bc = before_channel.predict(np.array([\n",
    "    [0,0,0],\n",
    "    [0,0,1],\n",
    "    [0,1,0],\n",
    "    [0,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1],\n",
    "    [1,1,0],\n",
    "    [1,1,1],\n",
    "    \n",
    "  \n",
    "  \n",
    "    \n",
    "]))\n",
    "    \n",
    "\n",
    "ac = after_channel.predict(x_val[:1000,:])\n",
    "acn = after_channel_normalized.predict(x_val[:1000,:])\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,3,figsize=(15,4))\n",
    "ax[0].scatter(bc[:,0],bc[:,1],c=\"red\")\n",
    "ax[0].set_title(\"before channel\")\n",
    "\n",
    "\n",
    "ax[1].scatter(ac[:,0],ac[:,1],c=\"blue\",s=3)\n",
    "ax[1].set_title(\"after channel\")\n",
    "\n",
    "\n",
    "ax[2].scatter(ac[:,0],ac[:,1],c=\"blue\",s=3)\n",
    "ax[2].scatter(bc[:,0],bc[:,1],c=\"red\") # seconded to avoid occlusion\n",
    "ax[2].set_title(\"both before and after channel normalized\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86de1783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T17:27:06.704979Z",
     "start_time": "2024-02-05T17:27:06.691544Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# m = 1.5  # Shape parameter\n",
    "# omega = 2.0  # Scale parameter\n",
    "# num_samples = 1000\n",
    "# nakagami_samples = generate_nakagami_samples((None,num_samples,),m, omega)\n",
    "\n",
    "\n",
    "# # Compute the histogram\n",
    "# hist, bins = np.histogram(nakagami_samples, bins=20)  # Adjust the number of bins as needed\n",
    "\n",
    "# # Plot the histogram\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# plt.hist(nakagami_samples, bins=20, color='blue', alpha=0.7)  # Plot the histogram bars\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.title('Histogram of Nakagami Samples')\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a76c483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-05T17:27:06.720584Z",
     "start_time": "2024-02-05T17:27:06.707018Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb5a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RicianFadingLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, K, stddev, **kwargs):\n",
    "        super(RicianFadingLayer, self).__init__(**kwargs)\n",
    "        self.K = K  # Rician factor (K-factor)\n",
    "        self.stddev = stddev  # Standard deviation of Rayleigh fading\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Generate Rayleigh fading components\n",
    "#         rayleigh = tf.random.normal(tf.shape(inputs), mean=0.0, stddev=self.stddev)\n",
    "        rayleigh = tf.random.rayleigh(shape=tf.shape(inputs),scale=self.stddev)\n",
    "    \n",
    "        # Generate line-of-sight (LOS) component\n",
    "        LOS = tf.sqrt(self.K / (self.K + 1)) * tf.random.normal(tf.shape(inputs), mean=0.0, stddev=self.stddev)\n",
    "        \n",
    "        # Combine LOS and Rayleigh components\n",
    "        rician = LOS + rayleigh\n",
    "        # Apply Rician fading to input signals\n",
    "        return inputs * rician\n",
    "\n",
    "# # Example usage:\n",
    "# # Create a Rician fading layer with K-factor 3 and standard deviation 0.1\n",
    "# rician_layer = RicianFadingLayer(K=3, stddev=0.1)\n",
    "\n",
    "# # Generate some input signals\n",
    "# inputs = tf.random.normal((32, 64))  # Example input shape: (batch_size, input_dim)\n",
    "\n",
    "# # Apply Rician fading to the input signals\n",
    "# outputs = rician_layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1b98c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:05:13.773517Z",
     "start_time": "2024-02-06T10:05:13.682078Z"
    }
   },
   "outputs": [],
   "source": [
    "preds = AE_best.predict(x_val) > 0.5\n",
    "accuracy = np.mean(  preds == y_val  )\n",
    "\n",
    "\n",
    "print(f\"accuracy = {accuracy}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62bf9e96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T10:32:32.970290Z",
     "start_time": "2024-02-06T10:32:32.947778Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12800, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val.shape\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
