{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSTgsilO1_ur"
   },
   "source": [
    "online version of this notebook : https://colab.research.google.com/drive/12iz5_mTOmTa0oyn5IZZYnEskVUonViVW#scrollTo=VSTgsilO1_ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.368137Z",
     "start_time": "2024-04-16T11:41:06.672690Z"
    },
    "id": "pWavhXJRGytK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNx0nzHGxCtg"
   },
   "source": [
    "## PARAMS\n",
    "<a name=\"params\">.</a>\n",
    "<a href=\"#datasyn\">go to data gen</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.383918Z",
     "start_time": "2024-04-16T11:41:10.369137Z"
    },
    "id": "eQvOU0nYbPdu"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "\n",
    "k = 4\n",
    "NUM_CHANNEL_USES = 7\n",
    "block_size = 320\n",
    "\n",
    "snr = 6 #9 for training\n",
    "\n",
    "model_training_num_of_frames = 10**3 #10**4\n",
    "model_validating_num_of_frames = 10**2 #10**3\n",
    "\n",
    "n_train = block_size * model_training_num_of_frames\n",
    "n_val   = block_size * model_validating_num_of_frames\n",
    "\n",
    "# Geanerating dataset\n",
    "model_output_num_of_frames = 10**5\n",
    "n_out = block_size * model_output_num_of_frames\n",
    "\n",
    "num_epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.399543Z",
     "start_time": "2024-04-16T11:41:10.384978Z"
    },
    "id": "8llGxbteuvUt"
   },
   "outputs": [],
   "source": [
    "SLICED_Y_LENGTH = 16\n",
    "BATCH_SIZE =  1\n",
    "\n",
    "# in teh feature extractor path \"f\" : design param\n",
    "# Our experiments have shown that even a\n",
    "# small number of features, e.g., F = 4, significantly improves\n",
    "# the performance.\n",
    "N_FEATURES_EXTRACTED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.415510Z",
     "start_time": "2024-04-16T11:41:10.400549Z"
    },
    "id": "AU4v5qeU_LTW"
   },
   "outputs": [],
   "source": [
    "def R2C(a):\n",
    "\n",
    "    aa = tf.cast(tf.reshape(a,shape=(BATCH_SIZE,-1,2)),tf.float32)\n",
    "\n",
    "    aaa = tf.complex(aa[:,:,0],aa[:,:,1])\n",
    "    return aaa\n",
    "\n",
    "def C2R(a):\n",
    "    real, imag = tf.expand_dims(tf.math.real(a),axis=2) ,tf.expand_dims(tf.math.imag(a), axis=2)\n",
    "    R = tf.concat((real,imag),axis=2)\n",
    "    R = tf.reshape(R , (BATCH_SIZE,-1)  )\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9Oj3oPvZcHV"
   },
   "source": [
    "# Stochastic Channel Model & Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsd5N4qhfV0O"
   },
   "source": [
    "### Additional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.430676Z",
     "start_time": "2024-04-16T11:41:10.416517Z"
    },
    "id": "a73PhgGbfYlk"
   },
   "outputs": [],
   "source": [
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        out = tf.nn.l2_normalize(inputs, axis=-1)\n",
    "        print(\"normalize output shape = \",out.shape)\n",
    "        return out\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "\n",
    "\n",
    "def generate_nakagami_samples(m, omega):\n",
    "    nakagami_amp_vec = nakagami.rvs(m,omega,size =  NUM_CHANNEL_USES)   # Same gain for the real part and the imaginary part\n",
    "    nakagami_phase_vec = np.random.uniform(low=0.0, high=2*np.pi, size = NUM_CHANNEL_USES)    # phase shift will effect the complex number\n",
    "    nakagami_for_real = np.reshape(nakagami_amp_vec*np.cos(nakagami_phase_vec),(-1,1))\n",
    "    nakagami_for_imag = np.reshape(nakagami_amp_vec*np.sin(nakagami_phase_vec),(-1,1))\n",
    "    fading_vec = np.reshape(np.concatenate((nakagami_for_real,nakagami_for_imag),axis=1),(1,-1))[0]\n",
    "    return  tf.constant(fading_vec, dtype=tf.float32)\n",
    "\n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      fading = generate_nakagami_samples(m = self.distribution_params[\"m\"],\n",
    "                                        omega = self.distribution_params[\"omega\"])\n",
    "      return inputs * fading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1ejiEuHf1B0"
   },
   "source": [
    "### Stochastic channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.894380Z",
     "start_time": "2024-04-16T11:41:10.431699Z"
    },
    "id": "Tm8yRX0xa_ul"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import uniform\n",
    "\n",
    "channel_parameters = {\n",
    "    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "    \"roll_off\" : 0.35,          # Roll off factor\n",
    "    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1\n",
    "    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.925258Z",
     "start_time": "2024-04-16T11:41:10.894380Z"
    },
    "id": "gA_f6Q7cZiUN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Making the stochasticChannelLayer\n",
    "\n",
    "# function to create the complex values\n",
    "def real_to_complex_tensor(inp_tensor):\n",
    "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
    "  real_part = inp_tensor[:, 0]\n",
    "  imag_part = inp_tensor[:, 1]\n",
    "  complex_tensor = tf.complex(real_part, imag_part)\n",
    "  return complex_tensor\n",
    "\n",
    "def complex_to_real_tensor(inp_tensor):\n",
    "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
    "   real_part = tf.reshape(real_part,[-1,1])\n",
    "   imag_part = tf.reshape(imag_part,[-1,1])\n",
    "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
    "\n",
    "# Upsample\n",
    "def upsampling(inp,r):\n",
    "  com_reshape = tf.reshape(inp,[-1,1])\n",
    "  padding = tf.constant([[0,0],[0,r-1]])\n",
    "  upsampled = tf.pad(com_reshape,padding,\"CONSTANT\")\n",
    "  return tf.reshape(upsampled,[-1])\n",
    "\n",
    "# Normalized RRC with time shift\n",
    "def NRRC_filter(num_taps, roll_off, time_delay):\n",
    "  t = np.linspace(-(num_taps-1)/2,(num_taps-1)/2,num_taps) - time_delay\n",
    "  eps = np.finfo(float).eps # Small epsilon to avoid divisiomn by zero\n",
    "  pi = np.pi\n",
    "  def RRC_filter_coff(t):\n",
    "    if abs(t) < eps:  # For t==0\n",
    "      return 1.0 - roll_off + (4*roll_off/pi)\n",
    "    elif roll_off != 0 and (abs(t-1/(4*roll_off))<eps or abs(t+1/(4*roll_off))<eps):\n",
    "      return (roll_off/np.sqrt(2))*(1 + 2/pi)*np.sin(pi/(4*roll_off)) + (1- 2/pi)*np.cos(pi/(4*roll_off))\n",
    "    else:\n",
    "      nu = np.sin(pi*t*(1-roll_off)) + 4*roll_off*t*np.cos(pi*t*(1+roll_off))\n",
    "      den = pi*t*(1-(4*roll_off*t)**2)\n",
    "      return nu/(den + eps)\n",
    "  filter_coff = np.array([RRC_filter_coff(T) for T in t])\n",
    "  NRRC_filter_coff = filter_coff / np.sum(np.abs(filter_coff))\n",
    "  print(f\"Time_delay = {time_delay}\")\n",
    "  plt.stem(t,NRRC_filter_coff)  # Plot for visualization\n",
    "  return tf.constant(NRRC_filter_coff,dtype = tf.float32)\n",
    "\n",
    "# Phase offset\n",
    "def PhaseOffset_vec(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "  l = batch_size*r*NUM_CHANNEL_USES+num_taps-1\n",
    "  CFO_off = 0.1*CFO_std# truncnorm.rvs(-1.96,1.96)*CFO_std  # boundaries will be selected for 95% confidence\n",
    "  print(\"CFO_off =\",CFO_off)\n",
    "  print(\"Phase offset = \",phase_off)                                          # CFO_min and CFO_max (boundaries) will be selected for 95% confidence\n",
    "  exp_vec = []\n",
    "  for i in range(l):\n",
    "    exp_vec.append(tf.math.exp(tf.constant([0+(2*np.pi*i*CFO_off+phase_off)*1j],dtype=tf.complex64)))\n",
    "  return tf.reshape(tf.stack(exp_vec),[-1])\n",
    "\n",
    "\n",
    "class UpsamplingLayer(keras.layers.Layer):\n",
    "    def __init__(self, r =channel_parameters[\"r\"]):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "    def call(self,inputs):\n",
    "       return upsampling(inputs,self.r)\n",
    "\n",
    "class PulseShaping(keras.layers.Layer):\n",
    "    def __init__(self,num_taps,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "    def call(self, inputs):\n",
    "      padding_size = self.num_taps // 2\n",
    "      paddings = tf.constant([[padding_size, padding_size]])\n",
    "      real_part = tf.pad(tf.math.real(inputs), paddings, \"CONSTANT\")\n",
    "      imag_part = tf.pad(tf.math.imag(inputs), paddings, \"CONSTANT\")\n",
    "      real_part = tf.reshape(real_part,[1,-1,1])\n",
    "      imag_part = tf.reshape(imag_part,[1,-1,1])\n",
    "      real_conv = tf.nn.conv1d(real_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      imag_conv = tf.nn.conv1d(imag_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      real_conv = tf.reshape(real_conv,[-1])\n",
    "      imag_conv = tf.reshape(imag_conv,[-1])\n",
    "      return tf.complex(real_conv,imag_conv)\n",
    "\n",
    "class PhaseOffset(keras.layers.Layer):\n",
    "    def __init__(self,batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "      super().__init__()\n",
    "      self.batch_size = batch_size\n",
    "      self.num_channel_uses = NUM_CHANNEL_USES\n",
    "      self.num_taps = num_taps\n",
    "      self.r = r\n",
    "      self.CFO_std = CFO_std\n",
    "      self.phase_off = phase_off\n",
    "    def call(self,inputs):\n",
    "       return inputs * PhaseOffset_vec(self.batch_size, self.num_channel_uses,self.num_taps,self.r,self.CFO_std, self.phase_off)\n",
    "\n",
    "class StochasticChannelLayer(keras.layers.Layer):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        channel_parameters ---> custom class for parameters store\n",
    "                                channel_parameters = {\n",
    "                                    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                                    \"roll_off\" : 0.35,          # Roll off factor\n",
    "                                    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                                    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                                    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "                                    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "                                    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                                    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                                    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1\n",
    "                                    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain,\n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self, NUM_CHANNEL_USES,batch_size,channel_parameters):\n",
    "        super().__init__()\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(channel_parameters[\"r\"])\n",
    "        self.PulseShaping_inst = PulseShaping(channel_parameters['num_taps'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['CFO_std'],channel_parameters['phase_off'])\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(channel_parameters['snr']/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x\n",
    "\n",
    "\n",
    "# Stochastic channel model\n",
    "class StochasticChannelModel(keras.Model):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        channel_parameters ---> custom class for parameters store\n",
    "                                channel_parameters = {\n",
    "                                    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                                    \"roll_off\" : 0.35,          # Roll off factor\n",
    "                                    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                                    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                                    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "                                    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "                                    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                                    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                                    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1\n",
    "                                    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain,\n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self, NUM_CHANNEL_USES,batch_size,channel_parameters):\n",
    "        super().__init__()\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(channel_parameters['r'])\n",
    "        self.PulseShaping_inst = PulseShaping(channel_parameters['num_taps'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['CFO_std'],channel_parameters['phase_off'])\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(channel_parameters['snr']/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.941244Z",
     "start_time": "2024-04-16T11:41:10.930680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decoder mask layer\n",
    "\n",
    "class PulseShaping_Dec(keras.layers.Layer):\n",
    "    def __init__(self,num_taps,r,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "      self.r =r\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[1,-1,1])\n",
    "      inp_conv = tf.nn.conv1d(inputs,self.nrrc_filter,stride=self.r,padding=\"VALID\")\n",
    "      inp_conv = tf.reshape(inp_conv,[-1])\n",
    "      return inp_conv\n",
    "\n",
    "\n",
    "class DecoderMaskLayer(keras.layers.Layer):\n",
    "    def __init__(self,channel_parameters,NUM_CHANNEL_USES):\n",
    "        super().__init__()\n",
    "        # self.Convo = PulseShaping_Dec(channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.Convo = tf.keras.layers.Conv1D(1,channel_parameters['num_taps'],strides=channel_parameters['r'], padding = 'valid',activation = 'relu',use_bias=True)\n",
    "        self.channel_uses = NUM_CHANNEL_USES\n",
    "    def call(self,inputs):\n",
    "        inp = tf.reshape(inputs,[-1,2])\n",
    "        real_part, imag_part = inp[:,0],inp[:,1]\n",
    "        vec_shape = real_part.shape[0]\n",
    "        #print(\"real shape\",real_part.shape)\n",
    "        real_part, imag_part = tf.reshape(real_part,[1,vec_shape,1]), tf.reshape(imag_part,[1,vec_shape,1])\n",
    "        real_part = tf.reshape(self.Convo(real_part),[-1,1])\n",
    "        imag_part = tf.reshape(self.Convo(imag_part),[-1,1])\n",
    "        #print(\"real shape after conv \",real_part.shape)\n",
    "        outputs = tf.concat([real_part,imag_part],1)\n",
    "        return tf.reshape(outputs,[-1,2*self.channel_uses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG_PMHaC_Nbd"
   },
   "source": [
    "## Main Blocks in the Sequence Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.972973Z",
     "start_time": "2024-04-16T11:41:10.943253Z"
    },
    "id": "Mx-vTDXeUVmT"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeatureExtractor(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->FeatureExtractor->cf1\")\n",
    "\n",
    "        self.cf2 = Dense(N_FEATURES_EXTRACTED,name=\"r3->FeatureExtractor->cf2\")\n",
    "\n",
    "        self.cf_state = Dense(8,name=\"featureExtractor_stateFC\")\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE):\n",
    "       \n",
    "\n",
    "        # combine the sliced_y and prev_state_FE\n",
    "        sliced_y = tf.concat([sliced_y,prev_state_FE],axis=1)\n",
    "\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "\n",
    "        state_FE = self.cf_state(sliced_y) # state calculated here\n",
    "\n",
    "        sliced_y = self.cf2(state_FE)\n",
    "\n",
    "        return sliced_y,state_FE\n",
    "\n",
    "class PhaseEstimator(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->PhaseEstimator->cf1\")\n",
    "        self.cf2 = Dense(2,name=\"r3->PhaseEstimator->cf2\")\n",
    "\n",
    "        self.cf_state = Dense(8,name=\"PhaseEstimator_stateFC\")\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_PE):\n",
    "        # combine sliced_y and prev_state_PE\n",
    "        sliced_y = tf.concat([sliced_y,prev_state_PE],axis=1)\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "\n",
    "        state_PE = self.cf_state(sliced_y) # state calculated here\n",
    "\n",
    "        sliced_y = self.cf2(state_PE)\n",
    "\n",
    "        return sliced_y,state_PE\n",
    "\n",
    "\n",
    "class Rx_Decoder_old(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "        self.cf2 = Dense(256)\n",
    "        self.cf3 = Dense(16)\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "class Rx_Decoder_new(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->Rx_Decoder_new->cf1\")\n",
    "        self.cf2 = Dense(256,name=\"r3->Rx_Decoder_new->cf2\")\n",
    "        self.cf3 = Dense(16,name=\"final_out_cf3\")\n",
    "\n",
    "        # useless\n",
    "        #self.cf4_state = Dense(8,name=\"state_dense_cf4\")\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        # state = self.cf4_state(concat)\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InternalSlicer(Model):\n",
    "    def __init__(self,l1,l2,complex_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the slice boundaries\n",
    "        mid = complex_length // 2\n",
    "        self.start = mid - l1\n",
    "        self.end = mid + l2 + 1\n",
    "\n",
    "    def call(self,sliced_y):\n",
    "\n",
    "        ret = C2R(R2C(sliced_y)[:, self.start:self.end])\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "def phase_multiply(internally_sliced_y,estimated_phase):\n",
    "    # (a,b) * (c,d) = (ac-bd,ad+bc)\n",
    "\n",
    "    internally_sliced_y_complex = R2C(internally_sliced_y)\n",
    "    estimated_phase_complex = R2C(estimated_phase)\n",
    "    phase_corrected_complex = estimated_phase_complex * internally_sliced_y_complex\n",
    "\n",
    "    phase_corrected = C2R(phase_corrected_complex)\n",
    "    return phase_corrected\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T9CJbZr_UgK"
   },
   "source": [
    "## Fake data syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:10.988305Z",
     "start_time": "2024-04-16T11:41:10.976000Z"
    },
    "id": "mj1GemkdxHCs"
   },
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "\n",
    "# m = 512* 2** 2\n",
    "# X = tf.random.normal(shape=(block_size,SLICED_Y_LENGTH),\n",
    "#                      mean=0,\n",
    "#                      stddev=1)\n",
    "\n",
    "# Y = tf.random.uniform(shape=(m,1),\n",
    "#                       minval=0,\n",
    "#                       maxval=16,\n",
    "#                       dtype=tf.int32)\n",
    "# Y = keras.utils.to_categorical(Y,16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4xqcXAB_XdM"
   },
   "source": [
    "## Main Model : Sequence Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.019756Z",
     "start_time": "2024-04-16T11:41:10.992767Z"
    },
    "id": "M_bSkx9vHEAd"
   },
   "outputs": [],
   "source": [
    "# sequence decoder\n",
    "\n",
    "\n",
    "class SequenceDecoder(Model):\n",
    "\n",
    "    def __init__(self,take_prev_phase_state=False):\n",
    "        super(SequenceDecoder,self).__init__()\n",
    "\n",
    "        self.take_prev_phase_state = take_prev_phase_state\n",
    "\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.phase_estimator = PhaseEstimator()\n",
    "        self.internal_slicer = InternalSlicer(l1=3,l2=3,complex_length=SLICED_Y_LENGTH//2)\n",
    "\n",
    "        if take_prev_phase_state:\n",
    "            self.rx_decoder_RNN = Rx_Decoder_new()\n",
    "        else:\n",
    "            raise Exception(\"How here come??\")\n",
    "            #self.rx_decoder = Rx_Decoder_old()\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE=None,prev_state_PE=None):\n",
    "\n",
    "        if prev_state_PE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_PE = tf.constant(tf.zeros((block_size,8)))\n",
    "        if prev_state_FE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_FE = tf.constant(tf.zeros((block_size,8)))\n",
    "\n",
    "\n",
    "        # RNN conn starts here\n",
    "\n",
    "        output_FE = self.feature_extractor(sliced_y,prev_state_FE=prev_state_FE)\n",
    "        extracted_features,state_FE = output_FE[0], output_FE[1]\n",
    "\n",
    "\n",
    "\n",
    "        output_PE = self.phase_estimator(sliced_y,prev_state_PE=prev_state_PE)\n",
    "        estimated_phase,state_PE = output_PE[0], output_PE[1]\n",
    "\n",
    "        # RNN conn ends here\n",
    "\n",
    "        internally_sliced_y = self.internal_slicer(sliced_y)\n",
    "\n",
    "\n",
    "\n",
    "        phase_corrected_ = phase_multiply(internally_sliced_y,estimated_phase)\n",
    "\n",
    "        concat = tf.concat((extracted_features,phase_corrected_),axis=1)\n",
    "        if self.take_prev_phase_state:\n",
    "            st_hat = self.rx_decoder_RNN(concat)\n",
    "            return (st_hat,state_FE,state_PE)\n",
    "        else:\n",
    "            raise Exception(\"How came here????\")\n",
    "            print(\"--PROBLEM--\")\n",
    "            st_hat = self.rx_decoder(concat)\n",
    "            return st_hat\n",
    "\n",
    "\n",
    "\n",
    "    def custom_train(self,X,Y,epochs=1): # X =  vertically stacked sliced_y, y = message index\n",
    "\n",
    "        # tarin per each time step\n",
    "        for _ in range(epochs):\n",
    "\n",
    "            # temp_prev_state_PE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last PE state here\n",
    "            # temp_prev_state_FE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last FE state here\n",
    "\n",
    "            temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "            temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "\n",
    "            loss_acc = 0\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                print(f\"iterration : {i}\")\n",
    "                x =  tf.expand_dims(X[i,:],axis=0)\n",
    "\n",
    "                y = tf.expand_dims(Y[i,:],axis=0)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    output = self.call(x,\n",
    "                                       prev_state_PE=temp_prev_state_PE,\n",
    "                                       prev_state_FE=temp_prev_state_FE)\n",
    "\n",
    "                    st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                    loss = self.compiled_loss(y,st_hat)\n",
    "\n",
    "                    #temp_prev_state = state ###### assign add dala balanna\n",
    "\n",
    "                    temp_prev_state_FE = (state_FE)\n",
    "                    temp_prev_state_PE = (state_PE)\n",
    "\n",
    "                grads = tape.gradient(loss,self.trainable_variables)\n",
    "                self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "                loss_acc += loss.numpy() / X.shape[0] # take the mean\n",
    "                print(\"loss (individual): \", loss.numpy())\n",
    "            print(f'Epoch  : {_}/{epochs} --> Loss = {loss_acc}')\n",
    "\n",
    "        # returning the final batch's loss\n",
    "        return loss_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T06:45:05.437856Z",
     "start_time": "2024-04-15T06:45:05.422233Z"
    },
    "id": "jq24YZr4baut"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.035313Z",
     "start_time": "2024-04-16T11:41:11.020777Z"
    },
    "id": "KqIhonChiDnM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the SD\n",
    "# tested and worked\n",
    "# mySD =   SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "# mySD.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# mySD.custom_train(X,Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.051014Z",
     "start_time": "2024-04-16T11:41:11.036291Z"
    },
    "id": "_rXUaAKBtGjj"
   },
   "outputs": [],
   "source": [
    "# mySD.build((2048,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft4zIJOAb70O"
   },
   "source": [
    "# Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.066537Z",
     "start_time": "2024-04-16T11:41:11.052014Z"
    },
    "id": "t3LnggrMdYqV"
   },
   "outputs": [],
   "source": [
    "AWGN_std = np.sqrt(1/10**(snr/10))\n",
    "act_func = 'tanh' # 'relu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.081956Z",
     "start_time": "2024-04-16T11:41:11.068038Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "4hLPpWIedf60",
    "outputId": "8341a7e9-8951-4f82-f9ee-2ba4bf06660a"
   },
   "outputs": [],
   "source": [
    "# # Encoder\n",
    "# Encoder = Sequential([\n",
    "#                     Dense(2**k, activation=act_func,input_shape=(2**k,)),#Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "#                     Dense(2**k, activation=act_func),\n",
    "#                     Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "#                     L2Normalization(name=\"normalization_layer\"),\n",
    "# ])\n",
    "\n",
    "# # Channel\n",
    "# Stochastic_channel = StochasticChannelModel(NUM_CHANNEL_USES,block_size,r,roll_off,L,time_delay,CFO_std,snr)\n",
    "\n",
    "# # Sequence decoder\n",
    "# Seq_decoder = SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "# # Auto encoder\n",
    "# Autoencoder = Sequential([\n",
    "#     Encoder,\n",
    "#     Stochastic_channel,\n",
    "#     # Seq_decoder\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.097665Z",
     "start_time": "2024-04-16T11:41:11.083940Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "D6QP70azZKLR",
    "outputId": "3bddf272-7540-429e-f177-585c26f9e1c3"
   },
   "outputs": [],
   "source": [
    "# Autoencoder.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#                     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "\n",
    "# # cxannot connect the RNN for a whoe batch\n",
    "\n",
    "# # history = Autoencoder.fit(x_train,\n",
    "# #                           y_train,\n",
    "# #                           batch_size=block_size,\n",
    "# #                           epochs=num_epoches,\n",
    "# #                           verbose=2,\n",
    "# #                           validation_data=(x_val,y_val))\n",
    "\n",
    "# train_history = Autoencoder.custom_train(x_train,y_train,epochs=1)\n",
    "# print(\"train_history\", train_history)\n",
    "\n",
    "\n",
    "# def calc_block_accuracy(preds,y_val):\n",
    "#     n_bits_per_block = preds.shape[1]\n",
    "#     n_correct_bits = np.sum(preds == y_val,axis=1)\n",
    "#     block_accuracy = np.mean(n_correct_bits == n_bits_per_block)\n",
    "#     return block_accuracy\n",
    "\n",
    "# preds = AE.predict(x_val,batch_size=block_size)>0.5\n",
    "# accuracy =  calc_block_accuracy(preds,y_val)\n",
    "# print(f\"validation accuracy = {accuracy}\")\n",
    "# print(f\"snr = {snr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "420o_lm0p9b9"
   },
   "source": [
    "<a href=\"#params\">go toparams</a><br/>\n",
    "\n",
    "<a name=\"datasyn\">Generate Data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.831166Z",
     "start_time": "2024-04-16T11:41:11.098857Z"
    },
    "id": "zhVsDdfPpM6V"
   },
   "outputs": [],
   "source": [
    "# synthesize some data\n",
    "x_train = tf.cast(tf.random.uniform((block_size,),minval=0,maxval=2**k),\n",
    "                  (tf.int32))\n",
    "\n",
    "y_train = tf.expand_dims(x_train,axis=1)\n",
    "\n",
    "x_train =  tf.one_hot(x_train,depth=2**k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPSeSA6tq-4r"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.846047Z",
     "start_time": "2024-04-16T11:41:11.832167Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d5-uKR_o-71",
    "outputId": "a605d800-01cf-42be-f1b8-1e947919655c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (320, 16)\n",
      "y_train.shape:  (320, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:11.861700Z",
     "start_time": "2024-04-16T11:41:11.848571Z"
    }
   },
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def ExternalSlicer(input_vec,padding=30,gamma=4):\n",
    "    '''\n",
    "    input_vec: should be the real and imag parts separately.\n",
    "    padding  : how much the window should expand per each side\n",
    "    '''\n",
    "    assert len(input_vec.shape) == 1, \"Need 1D vector. Cannot process multiple frames at once\"\n",
    "    assert (input_vec.shape[0]-2*padding ) / (2 * NUM_CHANNEL_USES * gamma) == block_size\n",
    "    \n",
    "    output_array = []\n",
    "    \n",
    "    for i in range(block_size):\n",
    "        window_size = (2 * NUM_CHANNEL_USES * gamma)\n",
    "        start = window_size * i\n",
    "        end = start + window_size + padding * 2\n",
    "        output_array.append(input_vec[start:end])\n",
    "    \n",
    "    return tf.stack(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T13:20:10.045427Z",
     "start_time": "2024-04-16T13:20:10.021707Z"
    }
   },
   "outputs": [],
   "source": [
    "class End2EndSys(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(End2EndSys,self).__init__()\n",
    "        \n",
    "        self.encoder = Sequential([\n",
    "                    Dense(2**k, activation=act_func,input_shape=(None,2**k,),name=\"e2es->encoder->cf1\"),#Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "                    Dense(2**k, activation=act_func,name=\"e2es->encoder->cf2\"),\n",
    "                    Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "                    L2Normalization(name=\"normalization_layer\"),\n",
    "                    ])\n",
    "\n",
    "        # Channel\n",
    "        self.stochastic_channel = StochasticChannelModel(NUM_CHANNEL_USES,block_size,channel_parameters)\n",
    "\n",
    "        # conv layer to mimim the external slicer\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv1D(1,\n",
    "                                            channel_parameters['num_taps'],\n",
    "                                            strides=1, \n",
    "                                            padding = 'valid',\n",
    "                                            activation = 'linear',\n",
    "                                            use_bias=True)\n",
    "       \n",
    "        # Sequence decoder\n",
    "        self.seq_decoder = SequenceDecoder(take_prev_phase_state=True)\n",
    "    \n",
    "    \n",
    "    def call(self,x):\n",
    "        \n",
    "        encodings = self.encoder(x)\n",
    "        \n",
    "        all_y = self.stochastic_channel(encodings)\n",
    "        print(\"all_y.shape\", all_y.shape)\n",
    "        \n",
    "        all_y  = tf.reshape(all_y,(1,-1,1))\n",
    "        slices = self.conv1(all_y)\n",
    "        slices = tf.reshape(slices, (-1,1))\n",
    "        \n",
    "        print(\"slices.shape\", slices.shape)\n",
    "#         return \n",
    "        \n",
    "#         slices = ExternalSlicer(all_y,)\n",
    "        st_hat_array = []\n",
    "        \n",
    "        temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "        temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "\n",
    "        # take one slice only --- for testing\n",
    "        for i in range(slices.shape[0]):\n",
    "            test_slice = tf.expand_dims(slices[i,:],axis=0)\n",
    "\n",
    "            \n",
    "            output = self.seq_decoder(test_slice,temp_prev_state_FE,temp_prev_state_PE)\n",
    "            # update states as well\n",
    "            st_hat,temp_prev_state_FE,temp_prev_state_PE = output[0], output[1], output[2]\n",
    "        \n",
    "            st_hat_array.append(st_hat[0])\n",
    "        \n",
    "        return tf.stack(st_hat_array)\n",
    "        \n",
    "#     @tf.function\n",
    "\n",
    "    def custom_fit(self,x,y,epochs=1):\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            \n",
    "            loss_acc = 0.\n",
    "            \n",
    "            temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "            temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "            \n",
    "            with tf.GradientTape(persistent=False) as tape:\n",
    "                \n",
    "                encodings = self.encoder(x,\n",
    "                                         training=True)\n",
    "                print(\"r3 1\")\n",
    "\n",
    "                all_y = tf.expand_dims(self.stochastic_channel(encodings),axis=1)\n",
    "                \n",
    "                print(\"r3 2\")\n",
    "                print(\"all_y.shape\", all_y.shape)\n",
    "                \n",
    "                \n",
    "#                 slices = ExternalSlicer(all_y,)\n",
    "                slices = self.conv1(all_y)\n",
    "                print(\"r3 3\")\n",
    "    #             st_hat_array = []\n",
    "\n",
    "    \n",
    "                for i in range(slices.shape[0]):\n",
    "                    print(\"iteration\" , i)\n",
    "                    test_slice = tf.expand_dims(slices[i,:],axis=0)\n",
    "                    corr_label = tf.expand_dims(y[i,:],axis=0)\n",
    "\n",
    "\n",
    "                    output = self.seq_decoder(test_slice,temp_prev_state_FE,temp_prev_state_PE)\n",
    "                    # update states as well\n",
    "                    st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                    loss = self.compiled_loss(corr_label,st_hat)\n",
    "\n",
    "    #                 st_hat_array.append(st_hat[0])\n",
    "                    with tape.stop_recording():\n",
    "                        grads = tape.gradient(loss,self.trainable_variables)\n",
    "                        self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "                    temp_prev_state_FE = state_FE\n",
    "                    temp_prev_state_PE = state_PE\n",
    "                    \n",
    "#                     print(type(loss.numpy()))\n",
    "                    loss_acc += loss.numpy() / slices.shape[0]\n",
    "\n",
    "                print(f'Epoch  : {_}/{epochs} --> Loss = {loss_acc}')\n",
    "\n",
    "    \n",
    "        \n",
    "        return loss_acc\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T13:20:12.634760Z",
     "start_time": "2024-04-16T13:20:11.966847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize output shape =  (None, None, 14)\n",
      "Time_delay = 0.26500269667542686\n",
      "normalize output shape =  (320, 14)\n",
      "CFO_off = 0.002\n",
      "Phase offset =  4.352955427379389\n",
      "all_y.shape (17980,)\n",
      "slices.shape (17950, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"internal_slicer_12\" (type InternalSlicer).\n\nInput to reshape is a tensor with 1 values, but the requested shape requires a multiple of 2 [Op:Reshape]\n\nCall arguments received by layer \"internal_slicer_12\" (type InternalSlicer):\n  • sliced_y=tf.Tensor(shape=(1, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/3005569218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mend2end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnd2EndSys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mend2end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/1110185502.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_slice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_FE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_PE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[1;31m# update states as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mst_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_FE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_PE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/2383730040.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, sliced_y, prev_state_FE, prev_state_PE)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# RNN conn ends here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0minternally_sliced_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_slicer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/3457594865.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, sliced_y)\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msliced_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC2R\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR2C\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/2295811411.py\u001b[0m in \u001b[0;36mR2C\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mR2C\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maaa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"internal_slicer_12\" (type InternalSlicer).\n\nInput to reshape is a tensor with 1 values, but the requested shape requires a multiple of 2 [Op:Reshape]\n\nCall arguments received by layer \"internal_slicer_12\" (type InternalSlicer):\n  • sliced_y=tf.Tensor(shape=(1, 1), dtype=float32)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end2end = End2EndSys()\n",
    "end2end(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T13:19:13.397344Z",
     "start_time": "2024-04-16T13:19:12.710718Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize output shape =  (None, None, 14)\n",
      "Time_delay = 0.26500269667542686\n",
      "normalize output shape =  (320, 14)\n",
      "r3 1\n",
      "CFO_off = 0.002\n",
      "Phase offset =  4.352955427379389\n",
      "r3 2\n",
      "all_y.shape (17980, 1)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'End2EndSys' object has no attribute 'Convo'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/718030588.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mend2end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/3745857291.py\u001b[0m in \u001b[0;36mcustom_fit\u001b[1;34m(self, x, y, epochs)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m#                 slices = ExternalSlicer(all_y,)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[0mslices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConvo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"r3 3\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m#             st_hat_array = []\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'End2EndSys' object has no attribute 'Convo'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "end2end = End2EndSys()\n",
    "# end2end(x_train).shape\n",
    "\n",
    "end2end.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "               loss=SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "\n",
    "end2end.custom_fit(x_train,y_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:20.811497Z",
     "start_time": "2024-04-16T11:41:20.797570Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMXg7FqQsYoU",
    "outputId": "2de71e71-5be4-45dc-cb21-5f6044d91932"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.1875, 60)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17980/320,17980%320\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:21.653390Z",
     "start_time": "2024-04-16T11:41:20.812499Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7XwICWFtf06",
    "outputId": "79af9993-71f3-4dbc-fd03-1e8a6412c8a8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14928/4097829577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": [
    "Encoder(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:21.662931Z",
     "start_time": "2024-04-16T11:41:21.662931Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6VG8egR82WV",
    "outputId": "ec21fdc1-1486-4e42-f996-2b827bb1d792"
   },
   "outputs": [],
   "source": [
    "(2*28+30) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:21.663927Z",
     "start_time": "2024-04-16T11:41:21.663927Z"
    },
    "id": "3FbYic3G88ti"
   },
   "outputs": [],
   "source": [
    "(17980-60)/(28*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T11:41:21.664926Z",
     "start_time": "2024-04-16T11:41:21.664926Z"
    }
   },
   "outputs": [],
   "source": [
    "ExternalSlicer(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
