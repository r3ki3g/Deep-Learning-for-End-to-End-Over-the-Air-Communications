{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSTgsilO1_ur"
   },
   "source": [
    "online version of this notebook : https://colab.research.google.com/drive/12iz5_mTOmTa0oyn5IZZYnEskVUonViVW#scrollTo=VSTgsilO1_ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:18.492358Z",
     "start_time": "2024-04-16T15:54:14.287838Z"
    },
    "id": "pWavhXJRGytK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNx0nzHGxCtg"
   },
   "source": [
    "## PARAMS\n",
    "<a name=\"params\">.</a>\n",
    "<a href=\"#datasyn\">go to data gen</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:18.507884Z",
     "start_time": "2024-04-16T15:54:18.493359Z"
    },
    "id": "eQvOU0nYbPdu"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "\n",
    "k = 4\n",
    "NUM_CHANNEL_USES = 7\n",
    "block_size = 320\n",
    "\n",
    "snr = 6 #9 for training\n",
    "\n",
    "model_training_num_of_frames = 10**3 #10**4\n",
    "model_validating_num_of_frames = 10**2 #10**3\n",
    "\n",
    "n_train = block_size * model_training_num_of_frames\n",
    "n_val   = block_size * model_validating_num_of_frames\n",
    "\n",
    "# Geanerating dataset\n",
    "model_output_num_of_frames = 10**5\n",
    "n_out = block_size * model_output_num_of_frames\n",
    "\n",
    "num_epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:18.522891Z",
     "start_time": "2024-04-16T15:54:18.509390Z"
    },
    "id": "8llGxbteuvUt"
   },
   "outputs": [],
   "source": [
    "SLICED_Y_LENGTH = 16\n",
    "BATCH_SIZE =  1\n",
    "\n",
    "# in teh feature extractor path \"f\" : design param\n",
    "# Our experiments have shown that even a\n",
    "# small number of features, e.g., F = 4, significantly improves\n",
    "# the performance.\n",
    "N_FEATURES_EXTRACTED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:18.538281Z",
     "start_time": "2024-04-16T15:54:18.526892Z"
    },
    "id": "AU4v5qeU_LTW"
   },
   "outputs": [],
   "source": [
    "def R2C(a):\n",
    "\n",
    "    aa = tf.cast(tf.reshape(a,shape=(BATCH_SIZE,-1,2)),tf.float32)\n",
    "\n",
    "    aaa = tf.complex(aa[:,:,0],aa[:,:,1])\n",
    "    return aaa\n",
    "\n",
    "def C2R(a):\n",
    "    real, imag = tf.expand_dims(tf.math.real(a),axis=2) ,tf.expand_dims(tf.math.imag(a), axis=2)\n",
    "    R = tf.concat((real,imag),axis=2)\n",
    "    R = tf.reshape(R , (BATCH_SIZE,-1)  )\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9Oj3oPvZcHV"
   },
   "source": [
    "# Stochastic Channel Model & Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsd5N4qhfV0O"
   },
   "source": [
    "### Additional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:18.553931Z",
     "start_time": "2024-04-16T15:54:18.539329Z"
    },
    "id": "a73PhgGbfYlk"
   },
   "outputs": [],
   "source": [
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        out = tf.nn.l2_normalize(inputs, axis=-1)\n",
    "        print(\"normalize output shape = \",out.shape)\n",
    "        return out\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "\n",
    "\n",
    "def generate_nakagami_samples(m, omega):\n",
    "    nakagami_amp_vec = nakagami.rvs(m,omega,size =  NUM_CHANNEL_USES)   # Same gain for the real part and the imaginary part\n",
    "    nakagami_phase_vec = np.random.uniform(low=0.0, high=2*np.pi, size = NUM_CHANNEL_USES)    # phase shift will effect the complex number\n",
    "    nakagami_for_real = np.reshape(nakagami_amp_vec*np.cos(nakagami_phase_vec),(-1,1))\n",
    "    nakagami_for_imag = np.reshape(nakagami_amp_vec*np.sin(nakagami_phase_vec),(-1,1))\n",
    "    fading_vec = np.reshape(np.concatenate((nakagami_for_real,nakagami_for_imag),axis=1),(1,-1))[0]\n",
    "    return  tf.constant(fading_vec, dtype=tf.float32)\n",
    "\n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      fading = generate_nakagami_samples(m = self.distribution_params[\"m\"],\n",
    "                                        omega = self.distribution_params[\"omega\"])\n",
    "      return inputs * fading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1ejiEuHf1B0"
   },
   "source": [
    "### Stochastic channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:18.990213Z",
     "start_time": "2024-04-16T15:54:18.554955Z"
    },
    "id": "Tm8yRX0xa_ul"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import uniform\n",
    "\n",
    "channel_parameters = {\n",
    "    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "    \"roll_off\" : 0.35,          # Roll off factor\n",
    "    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1\n",
    "    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:19.022250Z",
     "start_time": "2024-04-16T15:54:18.991448Z"
    },
    "id": "gA_f6Q7cZiUN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Making the stochasticChannelLayer\n",
    "\n",
    "# function to create the complex values\n",
    "def real_to_complex_tensor(inp_tensor):\n",
    "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
    "  real_part = inp_tensor[:, 0]\n",
    "  imag_part = inp_tensor[:, 1]\n",
    "  complex_tensor = tf.complex(real_part, imag_part)\n",
    "  return complex_tensor\n",
    "\n",
    "def complex_to_real_tensor(inp_tensor):\n",
    "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
    "   real_part = tf.reshape(real_part,[-1,1])\n",
    "   imag_part = tf.reshape(imag_part,[-1,1])\n",
    "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
    "\n",
    "# Upsample\n",
    "def upsampling(inp,r):\n",
    "  com_reshape = tf.reshape(inp,[-1,1])\n",
    "  padding = tf.constant([[0,0],[0,r-1]])\n",
    "  upsampled = tf.pad(com_reshape,padding,\"CONSTANT\")\n",
    "  return tf.reshape(upsampled,[-1])\n",
    "\n",
    "# Normalized RRC with time shift\n",
    "def NRRC_filter(num_taps, roll_off, time_delay):\n",
    "  t = np.linspace(-(num_taps-1)/2,(num_taps-1)/2,num_taps) - time_delay\n",
    "  eps = np.finfo(float).eps # Small epsilon to avoid divisiomn by zero\n",
    "  pi = np.pi\n",
    "  def RRC_filter_coff(t):\n",
    "    if abs(t) < eps:  # For t==0\n",
    "      return 1.0 - roll_off + (4*roll_off/pi)\n",
    "    elif roll_off != 0 and (abs(t-1/(4*roll_off))<eps or abs(t+1/(4*roll_off))<eps):\n",
    "      return (roll_off/np.sqrt(2))*(1 + 2/pi)*np.sin(pi/(4*roll_off)) + (1- 2/pi)*np.cos(pi/(4*roll_off))\n",
    "    else:\n",
    "      nu = np.sin(pi*t*(1-roll_off)) + 4*roll_off*t*np.cos(pi*t*(1+roll_off))\n",
    "      den = pi*t*(1-(4*roll_off*t)**2)\n",
    "      return nu/(den + eps)\n",
    "  filter_coff = np.array([RRC_filter_coff(T) for T in t])\n",
    "  NRRC_filter_coff = filter_coff / np.sum(np.abs(filter_coff))\n",
    "  print(f\"Time_delay = {time_delay}\")\n",
    "  plt.stem(t,NRRC_filter_coff)  # Plot for visualization\n",
    "  return tf.constant(NRRC_filter_coff,dtype = tf.float32)\n",
    "\n",
    "# Phase offset\n",
    "def PhaseOffset_vec(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "  l = batch_size*r*NUM_CHANNEL_USES+num_taps-1\n",
    "  CFO_off = 0.1*CFO_std# truncnorm.rvs(-1.96,1.96)*CFO_std  # boundaries will be selected for 95% confidence\n",
    "  print(\"CFO_off =\",CFO_off)\n",
    "  print(\"Phase offset = \",phase_off)                                          # CFO_min and CFO_max (boundaries) will be selected for 95% confidence\n",
    "  exp_vec = []\n",
    "  for i in range(l):\n",
    "    exp_vec.append(tf.math.exp(tf.constant([0+(2*np.pi*i*CFO_off+phase_off)*1j],dtype=tf.complex64)))\n",
    "  return tf.reshape(tf.stack(exp_vec),[-1])\n",
    "\n",
    "\n",
    "class UpsamplingLayer(keras.layers.Layer):\n",
    "    def __init__(self, r =channel_parameters[\"r\"]):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "    def call(self,inputs):\n",
    "       return upsampling(inputs,self.r)\n",
    "\n",
    "class PulseShaping(keras.layers.Layer):\n",
    "    def __init__(self,num_taps,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "    def call(self, inputs):\n",
    "      padding_size = self.num_taps // 2\n",
    "      paddings = tf.constant([[padding_size, padding_size]])\n",
    "      real_part = tf.pad(tf.math.real(inputs), paddings, \"CONSTANT\")\n",
    "      imag_part = tf.pad(tf.math.imag(inputs), paddings, \"CONSTANT\")\n",
    "      real_part = tf.reshape(real_part,[1,-1,1])\n",
    "      imag_part = tf.reshape(imag_part,[1,-1,1])\n",
    "      real_conv = tf.nn.conv1d(real_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      imag_conv = tf.nn.conv1d(imag_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      real_conv = tf.reshape(real_conv,[-1])\n",
    "      imag_conv = tf.reshape(imag_conv,[-1])\n",
    "      return tf.complex(real_conv,imag_conv)\n",
    "\n",
    "class PhaseOffset(keras.layers.Layer):\n",
    "    def __init__(self,batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "      super().__init__()\n",
    "      self.batch_size = batch_size\n",
    "      self.num_channel_uses = NUM_CHANNEL_USES\n",
    "      self.num_taps = num_taps\n",
    "      self.r = r\n",
    "      self.CFO_std = CFO_std\n",
    "      self.phase_off = phase_off\n",
    "    def call(self,inputs):\n",
    "       return inputs * PhaseOffset_vec(self.batch_size, self.num_channel_uses,self.num_taps,self.r,self.CFO_std, self.phase_off)\n",
    "\n",
    "class StochasticChannelLayer(keras.layers.Layer):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        channel_parameters ---> custom class for parameters store\n",
    "                                channel_parameters = {\n",
    "                                    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                                    \"roll_off\" : 0.35,          # Roll off factor\n",
    "                                    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                                    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                                    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "                                    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "                                    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                                    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                                    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1\n",
    "                                    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain,\n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self, NUM_CHANNEL_USES,batch_size,channel_parameters):\n",
    "        super().__init__()\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(channel_parameters[\"r\"])\n",
    "        self.PulseShaping_inst = PulseShaping(channel_parameters['num_taps'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['CFO_std'],channel_parameters['phase_off'])\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(channel_parameters['snr']/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x\n",
    "\n",
    "\n",
    "# Stochastic channel model\n",
    "class StochasticChannelModel(keras.Model):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        channel_parameters ---> custom class for parameters store\n",
    "                                channel_parameters = {\n",
    "                                    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                                    \"roll_off\" : 0.35,          # Roll off factor\n",
    "                                    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                                    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                                    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "                                    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "                                    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                                    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                                    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1\n",
    "                                    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain,\n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self, NUM_CHANNEL_USES,batch_size,channel_parameters):\n",
    "        super().__init__()\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(channel_parameters['r'])\n",
    "        self.PulseShaping_inst = PulseShaping(channel_parameters['num_taps'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['CFO_std'],channel_parameters['phase_off'])\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(channel_parameters['snr']/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:54:19.038369Z",
     "start_time": "2024-04-16T15:54:19.024238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Decoder mask layer\n",
    "\n",
    "class PulseShaping_Dec(keras.layers.Layer):\n",
    "    def __init__(self,num_taps,r,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "      self.r =r\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[1,-1,1])\n",
    "      inp_conv = tf.nn.conv1d(inputs,self.nrrc_filter,stride=self.r,padding=\"VALID\")\n",
    "      inp_conv = tf.reshape(inp_conv,[-1])\n",
    "      return inp_conv\n",
    "\n",
    "\n",
    "class DecoderMaskLayer(keras.layers.Layer):\n",
    "    def __init__(self,channel_parameters,NUM_CHANNEL_USES):\n",
    "        super().__init__()\n",
    "        # self.Convo = PulseShaping_Dec(channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.Convo = tf.keras.layers.Conv1D(1,channel_parameters['num_taps'],strides=channel_parameters['r'], padding = 'valid',activation = 'relu',use_bias=True)\n",
    "        self.channel_uses = NUM_CHANNEL_USES\n",
    "    def call(self,inputs):\n",
    "        inp = tf.reshape(inputs,[-1,2])\n",
    "        real_part, imag_part = inp[:,0],inp[:,1]\n",
    "        vec_shape = real_part.shape[0]\n",
    "        #print(\"real shape\",real_part.shape)\n",
    "        real_part, imag_part = tf.reshape(real_part,[1,vec_shape,1]), tf.reshape(imag_part,[1,vec_shape,1])\n",
    "        real_part = tf.reshape(self.Convo(real_part),[-1,1])\n",
    "        imag_part = tf.reshape(self.Convo(imag_part),[-1,1])\n",
    "        #print(\"real shape after conv \",real_part.shape)\n",
    "        outputs = tf.concat([real_part,imag_part],1)\n",
    "        return tf.reshape(outputs,[-1,2*self.channel_uses])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG_PMHaC_Nbd"
   },
   "source": [
    "## Main Blocks in the Sequence Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:01.961531Z",
     "start_time": "2024-04-16T15:55:01.939364Z"
    },
    "id": "Mx-vTDXeUVmT"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeatureExtractor(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->FeatureExtractor->cf1\")\n",
    "\n",
    "        self.cf2 = Dense(N_FEATURES_EXTRACTED,name=\"r3->FeatureExtractor->cf2\")\n",
    "\n",
    "        self.cf_state = Dense(8,name=\"featureExtractor_stateFC\")\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE):\n",
    "       \n",
    "\n",
    "        # combine the sliced_y and prev_state_FE\n",
    "        sliced_y = tf.concat([sliced_y,prev_state_FE],axis=1)\n",
    "\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "\n",
    "        state_FE = self.cf_state(sliced_y) # state calculated here\n",
    "\n",
    "        sliced_y = self.cf2(state_FE)\n",
    "\n",
    "        return sliced_y,state_FE\n",
    "\n",
    "class PhaseEstimator(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->PhaseEstimator->cf1\")\n",
    "        self.cf2 = Dense(2,name=\"r3->PhaseEstimator->cf2\")\n",
    "\n",
    "        self.cf_state = Dense(8,name=\"PhaseEstimator_stateFC\")\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_PE):\n",
    "        # combine sliced_y and prev_state_PE\n",
    "        sliced_y = tf.concat([sliced_y,prev_state_PE],axis=1)\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "\n",
    "        state_PE = self.cf_state(sliced_y) # state calculated here\n",
    "\n",
    "        sliced_y = self.cf2(state_PE)\n",
    "\n",
    "        return sliced_y,state_PE\n",
    "\n",
    "\n",
    "class Rx_Decoder_old(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "        self.cf2 = Dense(256)\n",
    "        self.cf3 = Dense(16)\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "class Rx_Decoder_new(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->Rx_Decoder_new->cf1\")\n",
    "        self.cf2 = Dense(256,name=\"r3->Rx_Decoder_new->cf2\")\n",
    "        self.cf3 = Dense(16,name=\"final_out_cf3\")\n",
    "\n",
    "        # useless\n",
    "        #self.cf4_state = Dense(8,name=\"state_dense_cf4\")\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        # state = self.cf4_state(concat)\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InternalSlicer(Model):\n",
    "    def __init__(self,l1,l2,complex_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the slice boundaries\n",
    "        mid = complex_length // 2\n",
    "        self.start = mid - l1\n",
    "        self.end = mid + l2 + 1\n",
    "\n",
    "    def call(self,sliced_y):\n",
    "        \n",
    "        print(\"r3 : sliced_y.shape\",sliced_y.shape)\n",
    "\n",
    "        ret = C2R(R2C(sliced_y)[:, self.start:self.end])\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "def phase_multiply(internally_sliced_y,estimated_phase):\n",
    "    # (a,b) * (c,d) = (ac-bd,ad+bc)\n",
    "\n",
    "    internally_sliced_y_complex = R2C(internally_sliced_y)\n",
    "    estimated_phase_complex = R2C(estimated_phase)\n",
    "    phase_corrected_complex = estimated_phase_complex * internally_sliced_y_complex\n",
    "\n",
    "    phase_corrected = C2R(phase_corrected_complex)\n",
    "    return phase_corrected\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T9CJbZr_UgK"
   },
   "source": [
    "## Fake data syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:01.977180Z",
     "start_time": "2024-04-16T15:55:01.963519Z"
    },
    "id": "mj1GemkdxHCs"
   },
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "\n",
    "# m = 512* 2** 2\n",
    "# X = tf.random.normal(shape=(block_size,SLICED_Y_LENGTH),\n",
    "#                      mean=0,\n",
    "#                      stddev=1)\n",
    "\n",
    "# Y = tf.random.uniform(shape=(m,1),\n",
    "#                       minval=0,\n",
    "#                       maxval=16,\n",
    "#                       dtype=tf.int32)\n",
    "# Y = keras.utils.to_categorical(Y,16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4xqcXAB_XdM"
   },
   "source": [
    "## Main Model : Sequence Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:01.992662Z",
     "start_time": "2024-04-16T15:55:01.978177Z"
    },
    "id": "M_bSkx9vHEAd"
   },
   "outputs": [],
   "source": [
    "# sequence decoder\n",
    "\n",
    "\n",
    "class SequenceDecoder(Model):\n",
    "\n",
    "    def __init__(self,take_prev_phase_state=False):\n",
    "        super(SequenceDecoder,self).__init__()\n",
    "\n",
    "        self.take_prev_phase_state = take_prev_phase_state\n",
    "\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.phase_estimator = PhaseEstimator()\n",
    "        self.internal_slicer = InternalSlicer(l1=4,l2=4,complex_length=SLICED_Y_LENGTH//2)\n",
    "\n",
    "        if take_prev_phase_state:\n",
    "            self.rx_decoder_RNN = Rx_Decoder_new()\n",
    "        else:\n",
    "            raise Exception(\"How here come??\")\n",
    "            #self.rx_decoder = Rx_Decoder_old()\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE=None,prev_state_PE=None):\n",
    "\n",
    "        if prev_state_PE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_PE = tf.constant(tf.zeros((block_size,8)))\n",
    "        if prev_state_FE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_FE = tf.constant(tf.zeros((block_size,8)))\n",
    "\n",
    "\n",
    "        # RNN conn starts here\n",
    "\n",
    "        output_FE = self.feature_extractor(sliced_y,prev_state_FE=prev_state_FE)\n",
    "        extracted_features,state_FE = output_FE[0], output_FE[1]\n",
    "\n",
    "\n",
    "\n",
    "        output_PE = self.phase_estimator(sliced_y,prev_state_PE=prev_state_PE)\n",
    "        estimated_phase,state_PE = output_PE[0], output_PE[1]\n",
    "\n",
    "        # RNN conn ends here\n",
    "\n",
    "        internally_sliced_y = self.internal_slicer(sliced_y)\n",
    "\n",
    "\n",
    "\n",
    "        phase_corrected_ = phase_multiply(internally_sliced_y,estimated_phase)\n",
    "\n",
    "        concat = tf.concat((extracted_features,phase_corrected_),axis=1)\n",
    "        if self.take_prev_phase_state:\n",
    "            st_hat = self.rx_decoder_RNN(concat)\n",
    "            return (st_hat,state_FE,state_PE)\n",
    "        else:\n",
    "            raise Exception(\"How came here????\")\n",
    "            print(\"--PROBLEM--\")\n",
    "            st_hat = self.rx_decoder(concat)\n",
    "            return st_hat\n",
    "\n",
    "\n",
    "\n",
    "    def custom_train(self,X,Y,epochs=1): # X =  vertically stacked sliced_y, y = message index\n",
    "\n",
    "        # tarin per each time step\n",
    "        for _ in range(epochs):\n",
    "\n",
    "            # temp_prev_state_PE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last PE state here\n",
    "            # temp_prev_state_FE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last FE state here\n",
    "\n",
    "            temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "            temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "\n",
    "            loss_acc = 0\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                print(f\"iterration : {i}\")\n",
    "                x =  tf.expand_dims(X[i,:],axis=0)\n",
    "\n",
    "                y = tf.expand_dims(Y[i,:],axis=0)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    output = self.call(x,\n",
    "                                       prev_state_PE=temp_prev_state_PE,\n",
    "                                       prev_state_FE=temp_prev_state_FE)\n",
    "\n",
    "                    st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                    loss = self.compiled_loss(y,st_hat)\n",
    "\n",
    "                    #temp_prev_state = state ###### assign add dala balanna\n",
    "\n",
    "                    temp_prev_state_FE = (state_FE)\n",
    "                    temp_prev_state_PE = (state_PE)\n",
    "\n",
    "                grads = tape.gradient(loss,self.trainable_variables)\n",
    "                self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "                loss_acc += loss.numpy() / X.shape[0] # take the mean\n",
    "                print(\"loss (individual): \", loss.numpy())\n",
    "            print(f'Epoch  : {_}/{epochs} --> Loss = {loss_acc}')\n",
    "\n",
    "        # returning the final batch's loss\n",
    "        return loss_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T06:45:05.437856Z",
     "start_time": "2024-04-15T06:45:05.422233Z"
    },
    "id": "jq24YZr4baut"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.009314Z",
     "start_time": "2024-04-16T15:55:01.993616Z"
    },
    "id": "KqIhonChiDnM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the SD\n",
    "# tested and worked\n",
    "# mySD =   SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "# mySD.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# mySD.custom_train(X,Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.025124Z",
     "start_time": "2024-04-16T15:55:02.012328Z"
    },
    "id": "_rXUaAKBtGjj"
   },
   "outputs": [],
   "source": [
    "# mySD.build((2048,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft4zIJOAb70O"
   },
   "source": [
    "# Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.040184Z",
     "start_time": "2024-04-16T15:55:02.026119Z"
    },
    "id": "t3LnggrMdYqV"
   },
   "outputs": [],
   "source": [
    "AWGN_std = np.sqrt(1/10**(snr/10))\n",
    "act_func = 'tanh' # 'relu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.055451Z",
     "start_time": "2024-04-16T15:55:02.041224Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "4hLPpWIedf60",
    "outputId": "8341a7e9-8951-4f82-f9ee-2ba4bf06660a"
   },
   "outputs": [],
   "source": [
    "# # Encoder\n",
    "# Encoder = Sequential([\n",
    "#                     Dense(2**k, activation=act_func,input_shape=(2**k,)),#Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "#                     Dense(2**k, activation=act_func),\n",
    "#                     Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "#                     L2Normalization(name=\"normalization_layer\"),\n",
    "# ])\n",
    "\n",
    "# # Channel\n",
    "# Stochastic_channel = StochasticChannelModel(NUM_CHANNEL_USES,block_size,r,roll_off,L,time_delay,CFO_std,snr)\n",
    "\n",
    "# # Sequence decoder\n",
    "# Seq_decoder = SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "# # Auto encoder\n",
    "# Autoencoder = Sequential([\n",
    "#     Encoder,\n",
    "#     Stochastic_channel,\n",
    "#     # Seq_decoder\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.071405Z",
     "start_time": "2024-04-16T15:55:02.056444Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "D6QP70azZKLR",
    "outputId": "3bddf272-7540-429e-f177-585c26f9e1c3"
   },
   "outputs": [],
   "source": [
    "# Autoencoder.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#                     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "\n",
    "# # cxannot connect the RNN for a whoe batch\n",
    "\n",
    "# # history = Autoencoder.fit(x_train,\n",
    "# #                           y_train,\n",
    "# #                           batch_size=block_size,\n",
    "# #                           epochs=num_epoches,\n",
    "# #                           verbose=2,\n",
    "# #                           validation_data=(x_val,y_val))\n",
    "\n",
    "# train_history = Autoencoder.custom_train(x_train,y_train,epochs=1)\n",
    "# print(\"train_history\", train_history)\n",
    "\n",
    "\n",
    "# def calc_block_accuracy(preds,y_val):\n",
    "#     n_bits_per_block = preds.shape[1]\n",
    "#     n_correct_bits = np.sum(preds == y_val,axis=1)\n",
    "#     block_accuracy = np.mean(n_correct_bits == n_bits_per_block)\n",
    "#     return block_accuracy\n",
    "\n",
    "# preds = AE.predict(x_val,batch_size=block_size)>0.5\n",
    "# accuracy =  calc_block_accuracy(preds,y_val)\n",
    "# print(f\"validation accuracy = {accuracy}\")\n",
    "# print(f\"snr = {snr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "420o_lm0p9b9"
   },
   "source": [
    "<a href=\"#params\">go toparams</a><br/>\n",
    "\n",
    "<a name=\"datasyn\">Generate Data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.086619Z",
     "start_time": "2024-04-16T15:55:02.074395Z"
    },
    "id": "zhVsDdfPpM6V"
   },
   "outputs": [],
   "source": [
    "# synthesize some data\n",
    "x_train = tf.cast(tf.random.uniform((block_size,),minval=0,maxval=2**k),\n",
    "                  (tf.int32))\n",
    "\n",
    "y_train = tf.expand_dims(x_train,axis=1)\n",
    "\n",
    "x_train =  tf.one_hot(x_train,depth=2**k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPSeSA6tq-4r"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.101890Z",
     "start_time": "2024-04-16T15:55:02.088619Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d5-uKR_o-71",
    "outputId": "a605d800-01cf-42be-f1b8-1e947919655c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (320, 16)\n",
      "y_train.shape:  (320, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:55:02.117520Z",
     "start_time": "2024-04-16T15:55:02.102885Z"
    }
   },
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def ExternalSlicer(input_vec,padding=30,gamma=4):\n",
    "    '''\n",
    "    input_vec: should be the real and imag parts separately.\n",
    "    padding  : how much the window should expand per each side\n",
    "    '''\n",
    "    assert len(input_vec.shape) == 1, \"Need 1D vector. Cannot process multiple frames at once\"\n",
    "    assert (input_vec.shape[0]-2*padding ) / (2 * NUM_CHANNEL_USES * gamma) == block_size\n",
    "    \n",
    "    output_array = []\n",
    "    \n",
    "    for i in range(block_size):\n",
    "        window_size = (2 * NUM_CHANNEL_USES * gamma)\n",
    "        start = window_size * i\n",
    "        end = start + window_size + padding * 2\n",
    "        output_array.append(input_vec[start:end])\n",
    "    \n",
    "    return tf.stack(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:57.839021Z",
     "start_time": "2024-04-16T15:56:57.819102Z"
    }
   },
   "outputs": [],
   "source": [
    "class End2EndSys(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(End2EndSys,self).__init__()\n",
    "        \n",
    "        self.encoder = Sequential([\n",
    "            \n",
    "                    Dense(2**k, activation=act_func,input_shape=(None,2**k,),name=\"e2es->encoder->cf1\"),#Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "                    Dense(2**k, activation=act_func,name=\"e2es->encoder->cf2\"),\n",
    "                    Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "                    L2Normalization(name=\"normalization_layer\"),\n",
    "            \n",
    "                    ])\n",
    "\n",
    "        # Channel\n",
    "        self.stochastic_channel = StochasticChannelModel(NUM_CHANNEL_USES,block_size,channel_parameters)\n",
    "\n",
    "        # conv layer to mimim the external slicer\n",
    "        padding=30\n",
    "        gamma=4\n",
    "        window_size = (2 * NUM_CHANNEL_USES * gamma)\n",
    "        taps = 0 + window_size + padding * 2\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv1D(window_size,\n",
    "                                            taps, #channel_parameters['num_taps']+30,\n",
    "                                            strides=window_size, \n",
    "                                            padding = 'valid',\n",
    "                                            activation = 'linear',\n",
    "                                            use_bias=True)\n",
    "       \n",
    "        # Sequence decoder\n",
    "        self.seq_decoder = SequenceDecoder(take_prev_phase_state=True)\n",
    "    \n",
    "    \n",
    "    def call(self,x):\n",
    "        \n",
    "        encodings = self.encoder(x)\n",
    "        \n",
    "        all_y = self.stochastic_channel(encodings)\n",
    "        print(\"all_y.shape\", all_y.shape)\n",
    "        \n",
    "        all_y  = tf.reshape(all_y,(1,-1,1))\n",
    "        slices = self.conv1(all_y)\n",
    "        slices = tf.reshape(slices, (-1,1))\n",
    "        \n",
    "        print(\"slices.shape\", slices.shape)\n",
    "#         return \n",
    "        \n",
    "#         slices = ExternalSlicer(all_y,)\n",
    "        st_hat_array = []\n",
    "        \n",
    "        temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "        temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "\n",
    "        # take one slice only --- for testing\n",
    "        for i in range(slices.shape[0]):\n",
    "            test_slice = tf.expand_dims(slices[i,:],axis=0)\n",
    "\n",
    "            \n",
    "            output = self.seq_decoder(test_slice,temp_prev_state_FE,temp_prev_state_PE)\n",
    "            # update states as well\n",
    "            st_hat,temp_prev_state_FE,temp_prev_state_PE = output[0], output[1], output[2]\n",
    "        \n",
    "            st_hat_array.append(st_hat[0])\n",
    "        \n",
    "        return tf.stack(st_hat_array)\n",
    "        \n",
    "#     @tf.function\n",
    "\n",
    "    def custom_fit(self,x,y,epochs=1):\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            \n",
    "            loss_acc = 0.\n",
    "            \n",
    "            temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "            temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "            \n",
    "            with tf.GradientTape(persistent=False) as tape:\n",
    "                \n",
    "                encodings = self.encoder(x,\n",
    "                                         training=True)\n",
    "                print(\"r3 1\")\n",
    "\n",
    "                all_y = tf.expand_dims(self.stochastic_channel(encodings),axis=1)\n",
    "                \n",
    "                print(\"r3 2\")\n",
    "                print(\"all_y.shape\", all_y.shape)\n",
    "                \n",
    "                \n",
    "#                 slices = ExternalSlicer(all_y,)\n",
    "                slices = self.conv1(all_y)\n",
    "                print(\"r3 3\")\n",
    "    #             st_hat_array = []\n",
    "\n",
    "    \n",
    "                for i in range(slices.shape[0]):\n",
    "                    print(\"iteration\" , i)\n",
    "                    test_slice = tf.expand_dims(slices[i,:],axis=0)\n",
    "                    corr_label = tf.expand_dims(y[i,:],axis=0)\n",
    "\n",
    "\n",
    "                    output = self.seq_decoder(test_slice,temp_prev_state_FE,temp_prev_state_PE)\n",
    "                    # update states as well\n",
    "                    st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                    loss = self.compiled_loss(corr_label,st_hat)\n",
    "\n",
    "    #                 st_hat_array.append(st_hat[0])\n",
    "                    with tape.stop_recording():\n",
    "                        grads = tape.gradient(loss,self.trainable_variables)\n",
    "                        self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "                    temp_prev_state_FE = state_FE\n",
    "                    temp_prev_state_PE = state_PE\n",
    "                    \n",
    "#                     print(type(loss.numpy()))\n",
    "                    loss_acc += loss.numpy() / slices.shape[0]\n",
    "\n",
    "                print(f'Epoch  : {_}/{epochs} --> Loss = {loss_acc}')\n",
    "\n",
    "    \n",
    "        \n",
    "        return loss_acc\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.539767Z",
     "start_time": "2024-04-16T15:56:57.841041Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize output shape =  (None, None, 14)\n",
      "Time_delay = -0.7730157637550279\n",
      "normalize output shape =  (320, 14)\n",
      "CFO_off = 0.002\n",
      "Phase offset =  1.8662559008321036\n",
      "all_y.shape (17980,)\n",
      "slices.shape (17920, 1)\n",
      "r3 : sliced_y.shape (1, 1)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"internal_slicer_2\" (type InternalSlicer).\n\nInput to reshape is a tensor with 1 values, but the requested shape requires a multiple of 2 [Op:Reshape]\n\nCall arguments received by layer \"internal_slicer_2\" (type InternalSlicer):\n  • sliced_y=tf.Tensor(shape=(1, 1), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/3005569218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mend2end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEnd2EndSys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mend2end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/2450560621.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_slice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_FE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_PE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[1;31m# update states as well\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mst_hat\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_FE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtemp_prev_state_PE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/1692618317.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, sliced_y, prev_state_FE, prev_state_PE)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# RNN conn ends here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0minternally_sliced_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal_slicer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/1786362670.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, sliced_y)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"r3 : sliced_y.shape\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msliced_y\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC2R\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR2C\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliced_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6772/2295811411.py\u001b[0m in \u001b[0;36mR2C\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mR2C\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0maa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0maaa\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maa\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"internal_slicer_2\" (type InternalSlicer).\n\nInput to reshape is a tensor with 1 values, but the requested shape requires a multiple of 2 [Op:Reshape]\n\nCall arguments received by layer \"internal_slicer_2\" (type InternalSlicer):\n  • sliced_y=tf.Tensor(shape=(1, 1), dtype=float32)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end2end = End2EndSys()\n",
    "end2end(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.543293Z",
     "start_time": "2024-04-16T15:56:58.543293Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "end2end = End2EndSys()\n",
    "# end2end(x_train).shape\n",
    "\n",
    "end2end.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "               loss=SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "\n",
    "end2end.custom_fit(x_train,y_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.544284Z",
     "start_time": "2024-04-16T15:56:58.544284Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMXg7FqQsYoU",
    "outputId": "2de71e71-5be4-45dc-cb21-5f6044d91932"
   },
   "outputs": [],
   "source": [
    "17980/320,17980%320\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.545249Z",
     "start_time": "2024-04-16T15:56:58.545249Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7XwICWFtf06",
    "outputId": "79af9993-71f3-4dbc-fd03-1e8a6412c8a8"
   },
   "outputs": [],
   "source": [
    "Encoder(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.546242Z",
     "start_time": "2024-04-16T15:56:58.546242Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6VG8egR82WV",
    "outputId": "ec21fdc1-1486-4e42-f996-2b827bb1d792"
   },
   "outputs": [],
   "source": [
    "(2*28+30) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.546242Z",
     "start_time": "2024-04-16T15:56:58.546242Z"
    },
    "id": "3FbYic3G88ti"
   },
   "outputs": [],
   "source": [
    "(17980-60)/(28*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:56:58.547239Z",
     "start_time": "2024-04-16T15:56:58.547239Z"
    }
   },
   "outputs": [],
   "source": [
    "ExternalSlicer(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
