{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "SLICED_Y_LENGTH = 16\n",
        "BATCH_SIZE =  512\n",
        "\n",
        "# in teh feature extractor path \"f\" : design param\n",
        "# Our experiments have shown that even a\n",
        "# small number of features, e.g., F = 4, significantly improves\n",
        "# the performance.\n",
        "N_FEATURES_EXTRACTED = 8"
      ],
      "metadata": {
        "id": "9H4m9y5MDYUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-q0PcGuCnzZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class InternalSlicer(nn.Module):\n",
        "    def __init__(self, l1, l2, complex_length):\n",
        "        super(InternalSlicer, self).__init__()\n",
        "\n",
        "        mid = complex_length // 2\n",
        "        self.start = mid - l1\n",
        "        self.end = mid + l2 + 1\n",
        "\n",
        "    def forward(self, sliced_y):\n",
        "        return self.C2R(self.R2C(sliced_y)[:, :, self.start:self.end])\n",
        "\n",
        "    def R2C(self, a):\n",
        "        aa = a.view(BATCH_SIZE, -1, 2).to(torch.float32)\n",
        "        aaa = torch.complex(aa[:, :, 0], aa[:, :, 1])\n",
        "        return aaa\n",
        "\n",
        "    def C2R(self, a):\n",
        "        real, imag = torch.unsqueeze(a.real, 2), torch.unsqueeze(a.imag, 2)\n",
        "        R = torch.cat((real, imag), 2)\n",
        "        return R.view(BATCH_SIZE, -1)\n",
        "\n",
        "\n",
        "def phase_multiply(internally_sliced_y, estimated_phase):\n",
        "    internally_sliced_y_complex = internally_sliced_y.view(BATCH_SIZE, -1, 2).to(torch.float32)\n",
        "    estimated_phase_complex = estimated_phase.view(BATCH_SIZE, -1, 2).to(torch.float32)\n",
        "    phase_corrected_complex = estimated_phase_complex * internally_sliced_y_complex\n",
        "    phase_corrected = phase_corrected_complex.view(BATCH_SIZE, -1)\n",
        "    return phase_corrected\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(FeatureExtractor, self).__init__()\n",
        "\n",
        "        self.cf1 = nn.Linear(SLICED_Y_LENGTH, 256)\n",
        "        self.cf2 = nn.Linear(256, N_FEATURES_EXTRACTED)\n",
        "\n",
        "    def forward(self, sliced_y):\n",
        "        sliced_y = F.relu(self.cf1(sliced_y))\n",
        "        sliced_y = self.cf2(sliced_y)\n",
        "        return sliced_y\n",
        "\n",
        "\n",
        "class PhaseEstimator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PhaseEstimator, self).__init__()\n",
        "\n",
        "        self.cf1 = nn.Linear(SLICED_Y_LENGTH, 256)\n",
        "        self.cf2 = nn.Linear(256, 2)\n",
        "\n",
        "    def forward(self, sliced_y):\n",
        "        sliced_y = F.relu(self.cf1(sliced_y))\n",
        "        sliced_y = self.cf2(sliced_y)\n",
        "        return sliced_y\n",
        "\n",
        "\n",
        "class Rx_Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Rx_Decoder, self).__init__()\n",
        "\n",
        "        self.cf1 = nn.Linear(256, 256)\n",
        "        self.cf2 = nn.Linear(256, 256)\n",
        "        self.cf3 = nn.Linear(256, 16)\n",
        "\n",
        "    def forward(self, concat):\n",
        "        concat = F.relu(self.cf1(concat))\n",
        "        concat = F.relu(self.cf2(concat))\n",
        "        concat = self.cf3(concat)\n",
        "        return concat\n",
        "\n",
        "\n",
        "class SequenceDecoder(nn.Module):\n",
        "    def __init__(self, take_prev_phase_state=False):\n",
        "        super(SequenceDecoder, self).__init__()\n",
        "\n",
        "        self.take_prev_phase_state = take_prev_phase_state\n",
        "\n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "        self.phase_estimator = PhaseEstimator()\n",
        "        self.internal_slicer = InternalSlicer(l1=3, l2=3, complex_length=SLICED_Y_LENGTH // 2)\n",
        "        self.rx_decoder = Rx_Decoder()\n",
        "\n",
        "    def forward(self, sliced_y, prev_phase_state=None):\n",
        "        if self.take_prev_phase_state:\n",
        "            assert prev_phase_state is not None, \"RNN need the previous phase state as an input\"\n",
        "\n",
        "        extracted_features = self.feature_extractor(sliced_y)\n",
        "        estimated_phase = self.phase_estimator(sliced_y)\n",
        "        internally_sliced_y = self.internal_slicer(sliced_y)\n",
        "\n",
        "        phase_corrected_ = phase_multiply(internally_sliced_y, estimated_phase)\n",
        "\n",
        "        concat = torch.cat((extracted_features, phase_corrected_, prev_phase_state), dim=1)\n",
        "\n",
        "        st_hat = self.rx_decoder(concat)\n",
        "\n",
        "        return st_hat\n"
      ],
      "metadata": {
        "id": "zN-jCsz-DGW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Convert data to torch tensors\n",
        "X_tensor = torch.tensor(X.numpy(), dtype=torch.float32)\n",
        "Y_tensor = torch.tensor(Y.numpy(), dtype=torch.int64)\n",
        "\n",
        "# Initialize the model\n",
        "mySD = SequenceDecoder()\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(mySD.parameters(), lr=1e-2)\n",
        "\n",
        "# Training loop\n",
        "epochs = 2\n",
        "batch_size = BATCH_SIZE\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    num_batches = len(X) // batch_size\n",
        "\n",
        "    # Shuffle the data\n",
        "    permutation = torch.randperm(len(X_tensor))\n",
        "    X_tensor_shuffled = X_tensor[permutation]\n",
        "    Y_tensor_shuffled = Y_tensor[permutation]\n",
        "\n",
        "    for i in range(0, len(X_tensor), batch_size):\n",
        "        # Get the inputs and labels\n",
        "        inputs = X_tensor_shuffled[i:i+batch_size]\n",
        "        labels = Y_tensor_shuffled[i:i+batch_size].squeeze()\n",
        "\n",
        "        # Zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = mySD(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/num_batches:.4f}\")\n"
      ],
      "metadata": {
        "id": "vo5RnNekDxeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate fake data\n",
        "m = 512* 2** 2\n",
        "X = tf.random.normal(shape=(m,SLICED_Y_LENGTH),\n",
        "                     mean=0,\n",
        "                     stddev=1)\n",
        "\n",
        "Y = tf.random.uniform(shape=(m,1),\n",
        "                      minval=0,\n",
        "                      maxval=16,\n",
        "                      dtype=tf.int32)\n",
        "# Y = keras.utils.to_categorical(Y,16)\n"
      ],
      "metadata": {
        "id": "uQfLFwxpDdzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}