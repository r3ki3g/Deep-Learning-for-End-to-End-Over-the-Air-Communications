{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "online version of this notebook : https://colab.research.google.com/drive/12iz5_mTOmTa0oyn5IZZYnEskVUonViVW#scrollTo=VSTgsilO1_ur"
      ],
      "metadata": {
        "id": "VSTgsilO1_ur"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pWavhXJRGytK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense\n",
        "from keras.models import Model, Sequential\n",
        "from keras.activations import relu, softmax\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_feature_extractor():\n",
        "  raise NotImplementedError()\n",
        "\n",
        "def get_internal_slicer():\n",
        "  raise NotImplementedError()\n",
        "\n",
        "\n",
        "def get_rx_decoder():\n",
        "  raise NotImplementedError()\n",
        "\n",
        "def phase_multiply(internally_sliced_y,h):\n",
        "  raise NotImplementedError()"
      ],
      "metadata": {
        "id": "4k-_9gsVQnu1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PARAMS"
      ],
      "metadata": {
        "id": "MNx0nzHGxCtg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SLICED_Y_LENGTH = 16\n",
        "BATCH_SIZE =  2048\n",
        "\n",
        "# in teh feature extractor path \"f\" : design param\n",
        "# Our experiments have shown that even a\n",
        "# small number of features, e.g., F = 4, significantly improves\n",
        "# the performance.\n",
        "N_FEATURES_EXTRACTED = 8"
      ],
      "metadata": {
        "id": "8llGxbteuvUt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def R2C(a):\n",
        "#     print(\"reached here 01\")\n",
        "#     print(a.shape)\n",
        "    aa = tf.cast(tf.reshape(a,shape=(BATCH_SIZE,-1,2)),tf.float32)\n",
        "    # print(aa)\n",
        "    aaa = tf.complex(aa[:,:,0],aa[:,:,1])\n",
        "    return aaa\n",
        "\n",
        "def C2R(a):\n",
        "    real, imag = tf.expand_dims(tf.math.real(a),axis=2) ,tf.expand_dims(tf.math.imag(a), axis=2)\n",
        "    R = tf.concat((real,imag),axis=2)\n",
        "    R = tf.reshape(R , (BATCH_SIZE,-1)  )\n",
        "    return R\n"
      ],
      "metadata": {
        "id": "AU4v5qeU_LTW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Blocks in the Sequence Decoder"
      ],
      "metadata": {
        "id": "HG_PMHaC_Nbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class FeatureExtractor(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cf1 = Dense(256)\n",
        "        self.cf2 = Dense(N_FEATURES_EXTRACTED)\n",
        "\n",
        "    def call(self,sliced_y):\n",
        "        print(\"sliced_y.shape\", sliced_y.shape)\n",
        "        sliced_y = self.cf1(sliced_y)\n",
        "        sliced_y = relu(sliced_y)\n",
        "        sliced_y = self.cf2(sliced_y)\n",
        "        return sliced_y\n",
        "\n",
        "class PhaseEstimator(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cf1 = Dense(256)\n",
        "        self.cf2 = Dense(2)\n",
        "\n",
        "\n",
        "    def call(self,sliced_y):\n",
        "        sliced_y = self.cf1(sliced_y)\n",
        "        sliced_y = relu(sliced_y)\n",
        "        sliced_y = self.cf2(sliced_y)\n",
        "        return sliced_y\n",
        "\n",
        "\n",
        "class Rx_Decoder(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cf1 = Dense(256)\n",
        "        self.cf2 = Dense(256)\n",
        "        self.cf3 = Dense(16)\n",
        "\n",
        "    def call(self,concat):\n",
        "\n",
        "        concat = self.cf1(concat)\n",
        "        concat = relu(concat)\n",
        "        concat = self.cf2(concat)\n",
        "        concat = relu(concat)\n",
        "\n",
        "        concat = self.cf3(concat)\n",
        "\n",
        "        # do not use softmax here : put from logit  = True in loss func\n",
        "        # concat = softmax(concat)\n",
        "\n",
        "        return concat\n",
        "\n",
        "\n",
        "class Rx_Decoder_RNN(Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cf1 = Dense(256)\n",
        "        self.cf2 = Dense(256)\n",
        "        self.cf3 = Dense(16,name=\"final_out_cf3\")\n",
        "\n",
        "        self.cf4_state = Dense(8,name=\"state_dense_cf4\")\n",
        "\n",
        "    def call(self,concat):\n",
        "\n",
        "        concat = self.cf1(concat)\n",
        "        concat = relu(concat)\n",
        "        concat = self.cf2(concat)\n",
        "        concat = relu(concat)\n",
        "\n",
        "        state = self.cf4_state(concat)\n",
        "        concat = self.cf3(concat)\n",
        "\n",
        "\n",
        "\n",
        "        # do not use softmax here : put from logit  = True in loss func\n",
        "        # concat = softmax(concat)\n",
        "\n",
        "        return concat,state\n",
        "\n",
        "class InternalSlicer(Model):\n",
        "    def __init__(self,l1,l2,complex_length):\n",
        "        super().__init__()\n",
        "\n",
        "        # define the slice boundaries\n",
        "        mid = complex_length // 2\n",
        "        self.start = mid - l1\n",
        "        self.end = mid + l2 + 1\n",
        "\n",
        "    def call(self,sliced_y):\n",
        "        print(f\"internal slicer : sliced_y.shape : {sliced_y.shape}\")\n",
        "        ret = C2R(R2C(sliced_y)[:, self.start:self.end])\n",
        "        print(f\"internal slicer : ret.shape : {ret.shape}\")\n",
        "        return ret\n",
        "\n",
        "\n",
        "def phase_multiply(internally_sliced_y,estimated_phase):\n",
        "    # (a,b) * (c,d) = (ac-bd,ad+bc)\n",
        "    print(\"internally_sliced_y.shape:\", internally_sliced_y.shape)\n",
        "    print(\"estimated_phase.shape: \", estimated_phase.shape)\n",
        "    internally_sliced_y_complex = R2C(internally_sliced_y)\n",
        "    estimated_phase_complex = R2C(estimated_phase)\n",
        "    phase_corrected_complex = estimated_phase_complex * internally_sliced_y_complex\n",
        "\n",
        "    phase_corrected = C2R(phase_corrected_complex)\n",
        "    return phase_corrected\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mx-vTDXeUVmT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fake data syn"
      ],
      "metadata": {
        "id": "2T9CJbZr_UgK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate fake data\n",
        "m = 512* 2** 2\n",
        "X = tf.random.normal(shape=(m,SLICED_Y_LENGTH),\n",
        "                     mean=0,\n",
        "                     stddev=1)\n",
        "\n",
        "Y = tf.random.uniform(shape=(m,1),\n",
        "                      minval=0,\n",
        "                      maxval=16,\n",
        "                      dtype=tf.int32)\n",
        "# Y = keras.utils.to_categorical(Y,16)\n"
      ],
      "metadata": {
        "id": "mj1GemkdxHCs"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Model : Sequence Decoder Class"
      ],
      "metadata": {
        "id": "R4xqcXAB_XdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sequence decoder\n",
        "\n",
        "\n",
        "class SequenceDecoder(Model):\n",
        "\n",
        "    def __init__(self,take_prev_phase_state=False):\n",
        "        super(SequenceDecoder,self).__init__()\n",
        "\n",
        "        self.take_prev_phase_state = take_prev_phase_state\n",
        "\n",
        "        self.feature_extractor = FeatureExtractor()\n",
        "        self.phase_estimator = PhaseEstimator()\n",
        "        self.internal_slicer = InternalSlicer(l1=3,l2=3,complex_length=SLICED_Y_LENGTH//2)\n",
        "        if take_prev_phase_state:\n",
        "            self.rx_decoder_RNN = Rx_Decoder_RNN()\n",
        "        else:\n",
        "            self.rx_decoder = Rx_Decoder()\n",
        "\n",
        "\n",
        "\n",
        "    def call(self,sliced_y,prev_phase_state=None):\n",
        "\n",
        "        if prev_phase_state is None:\n",
        "            raise Exception(\"Use RNN version damn it!\")\n",
        "        if self.take_prev_phase_state:\n",
        "            assert prev_phase_state is not None, \"RNN need the previous phase state as an input\"\n",
        "\n",
        "        extracted_features = self.feature_extractor(sliced_y)\n",
        "        estimated_phase = self.phase_estimator(sliced_y)\n",
        "        internally_sliced_y = self.internal_slicer(sliced_y)\n",
        "\n",
        "        print(\"SD call estimated_phase.shape\",estimated_phase.shape)\n",
        "        print(\"SD call internally_sliced_y.shape\",internally_sliced_y.shape)\n",
        "\n",
        "        phase_corrected_ = phase_multiply(internally_sliced_y,estimated_phase)\n",
        "\n",
        "        concat = tf.concat((extracted_features,phase_corrected_,prev_phase_state),axis=1)\n",
        "        if self.take_prev_phase_state:\n",
        "            st_hat,phase_state = self.rx_decoder_RNN(concat)\n",
        "            return (st_hat,phase_state)\n",
        "        else:\n",
        "            print(\"--PROBLEM--\")\n",
        "            st_hat = self.rx_decoder(concat)\n",
        "            return st_hat\n",
        "\n",
        "\n",
        "\n",
        "    def custom_train(self,X,Y,epochs=1): # X =  vertically stacked sliced_y, y = message index\n",
        "\n",
        "        temp_prev_state = tf.constant(tf.zeros((X.shape[0],8)))\n",
        "        loss_acc = 0\n",
        "\n",
        "        for i in range(epochs):\n",
        "            print(f\"iterration : {i}\")\n",
        "            x = X # tf.expand_dims(X[i,:],axis=0)\n",
        "            print(\"x shape:\", x.shape)\n",
        "            y = Y # tf.expand_dims(Y[i,:],axis=0)\n",
        "            print(\"y shape:\", y.shape)\n",
        "            with tf.GradientTape() as tape:\n",
        "                output = self.call(x,prev_phase_state=temp_prev_state)\n",
        "                pred_logits,state = output[0], output[1]\n",
        "                loss = self.compiled_loss(y,pred_logits)\n",
        "\n",
        "                temp_prev_state = state ###### assign add dala balanna\n",
        "\n",
        "            grads = tape.gradient(loss,self.trainable_variables)\n",
        "            self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
        "\n",
        "            loss_acc += tf.stop_gradient(loss).numpy()\n",
        "\n",
        "        return loss_acc\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "M_bSkx9vHEAd"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq24YZr4baut",
        "outputId": "b811e62d-179c-40a5-bf70-fd918ef682e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([2048, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test the SD\n",
        "\n",
        "mySD =   SequenceDecoder(take_prev_phase_state=True)\n",
        "\n",
        "mySD.compile(optimizer=Adam(learning_rate=1e-2),\n",
        "             loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "\n",
        "mySD.custom_train(X,Y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqIhonChiDnM",
        "outputId": "09e1e63c-b254-44c5-924a-44c5a770b2e5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['rx__decoder_rnn_3/state_dense_cf4/kernel:0', 'rx__decoder_rnn_3/state_dense_cf4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iterration : 0\n",
            "x shape: (2048, 16)\n",
            "y shape: (2048, 1)\n",
            "sliced_y.shape (2048, 16)\n",
            "internal slicer : sliced_y.shape : (2048, 16)\n",
            "internal slicer : ret.shape : (2048, 14)\n",
            "SD call estimated_phase.shape (2048, 2)\n",
            "SD call internally_sliced_y.shape (2048, 14)\n",
            "internally_sliced_y.shape: (2048, 14)\n",
            "estimated_phase.shape:  (2048, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['rx__decoder_rnn_3/state_dense_cf4/kernel:0', 'rx__decoder_rnn_3/state_dense_cf4/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.785886526107788"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mySD.build((2048,16))"
      ],
      "metadata": {
        "id": "_rXUaAKBtGjj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "886c5cc4-308b-41d4-c9b2-34388018f839"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "Use RNN version damn it!",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c8209bb85a4d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmySD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    540\u001b[0m                     )\n\u001b[1;32m    541\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                     raise ValueError(\n",
            "\u001b[0;32m<ipython-input-27-02c11cd236b9>\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, sliced_y, prev_phase_state)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprev_phase_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Use RNN version damn it!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_prev_phase_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mprev_phase_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"RNN need the previous phase state as an input\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: Use RNN version damn it!"
          ]
        }
      ]
    }
  ]
}