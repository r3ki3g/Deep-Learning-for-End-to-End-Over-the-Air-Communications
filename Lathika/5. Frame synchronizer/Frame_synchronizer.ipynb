{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# For models\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.layers import  Dense, Input\n",
    "\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing parameters \n",
    "k = 4\n",
    "NUM_CHANNEL_USES = 4\n",
    "\n",
    "sampling_factor = 4 # r\n",
    "N_msg = 2*NUM_CHANNEL_USES*sampling_factor  # complex numbers converted into real\n",
    "l = 6\n",
    "N_seq =(2*l-1)*N_msg \n",
    "frame_size = 100*N_msg\n",
    "q = 1   # strides = 1 (considered all values as real -> moving half of a complex number)\n",
    "\n",
    "block_size = 32    # num of messages for frames we use, out of this, we use 1/4 as pilots and 3/4 as messages\n",
    "n_blocks_train = 10**4  ################\n",
    "n_blocks_val = 10**3\n",
    "\n",
    "n_train = block_size * n_blocks_train\n",
    "n_val   = block_size * n_blocks_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4  5  6  7]\n",
      " [ 2  3  4  5  6  7  8]\n",
      " [ 3  4  5  6  7  8  9]\n",
      " [ 4  5  6  7  8  9 10]]\n",
      "tf.Tensor(\n",
      "[[ 1  2  3  4  5  6  7]\n",
      " [ 2  3  4  5  6  7  8]\n",
      " [ 3  4  5  6  7  8  9]\n",
      " [ 4  5  6  7  8  9 10]], shape=(4, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "def create_2d_array(arr, window_size, stride):\n",
    "    num_windows = (len(arr) - window_size) // stride + 1\n",
    "    shape = (num_windows, window_size)\n",
    "    strides = (arr.strides[0] * stride, arr.strides[0])\n",
    "    return np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)\n",
    "\n",
    "arr = np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "window_size = 7\n",
    "stride = 1\n",
    "\n",
    "result = create_2d_array(arr, window_size, stride)\n",
    "print(result)\n",
    "\n",
    "def create_2d_array_tf(arr, window_size, stride):\n",
    "    num_windows = (arr.shape[0] - window_size) // stride + 1\n",
    "    windows = []\n",
    "    for i in range(num_windows):\n",
    "        window = arr[i * stride:i * stride + window_size]\n",
    "        windows.append(window)\n",
    "    return tf.stack(windows)\n",
    "\n",
    "arr = tf.constant([1,2,3,4,5,6,7,8,9,10], dtype=tf.int32)\n",
    "window_size = 7\n",
    "stride = 1\n",
    "\n",
    "result = create_2d_array_tf(arr, window_size, stride)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]\n",
      " [0 0 1 0]], shape=(4, 4), dtype=int32)\n",
      "tf.Tensor([0. 0. 1. 0.], shape=(4,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def circular_shift(tensor):\n",
    "    shape = tensor.shape\n",
    "    rows = shape[0]\n",
    "    for i in range(rows):\n",
    "        shift_amount = i\n",
    "        current_row = tensor[i, :]\n",
    "        shifted_row = tf.roll(current_row, shift=shift_amount, axis=0)\n",
    "        tensor = tf.tensor_scatter_nd_update(tensor, [[i]], tf.expand_dims(shifted_row, axis=0))\n",
    "    return tensor\n",
    "\n",
    "# Test the function with your example\n",
    "input_tensor = tf.constant([[0,0,1,0],[0,1,0,0],[1,0,0,0],[0,0,0,1]], dtype=tf.int32)\n",
    "result = circular_shift(input_tensor)\n",
    "print(result)\n",
    "print(tf.reduce_sum(result,0)/result.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating offset estimator\n",
    "\"\"\"\n",
    "input is the matrix with massage sequences as rows, \n",
    "different between two rows are q,\n",
    "there are m = N-N_seq+1 rows for a frame\n",
    " \"\"\"\n",
    "class OffsetEstimator(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.OE = Sequential([\n",
    "            Input(shape=(N_seq,),name='OE_input'),\n",
    "            Dense(256,input_shape=(N_seq,),name = 'dense_layer_1',activation='relu'),\n",
    "            Dense(256,name = 'dense_layer_2',activation='relu'),\n",
    "            Dense(256,name = 'dense_layer_3',activation='relu'),\n",
    "            Dense(N_msg,name = 'dense_layer_4',activation='softmax'),\n",
    "        ])\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "    def call(self,inputs):\n",
    "        tau_vec_matrix = self.OE(inputs, training=False)\n",
    "        tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix),0)/result.shape[1]   # This vector has size of N_msg, and has the maximum mean value,                                                                         # corresponding to the shift\n",
    "        r = np.argmax(tau_sum_vec) # (or use tf.math.argmax)\n",
    "        i = r-1 -N_msg(np.fix((r-1)/(N_msg/2)))\n",
    "        return i\n",
    "    def compile(self, optimizer):\n",
    "        super().compile()\n",
    "        self.optimizer = optimizer\n",
    "    def train_step(self,data):   # frame_offset is a index value [-8,7] if N_msg = 16. frame_offset is the label we use to train the model \n",
    "        inputs,frame_offset = data\n",
    "        batch_size = inputs.shape[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            tau_vec_matrix = self.OE(inputs, training=True)\n",
    "            tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix),0)/result.shape[1]   # This vector has size of N_msg, and has the maximum mean value,                                                                         # corresponding to the shift\n",
    "            r = np.argmax(tau_sum_vec) # (or use tf.math.argmax)\n",
    "            i = r-1 -N_msg(np.fix((r-1)/(N_msg/2)))\n",
    "            # compute the loss\n",
    "            loss = keras.losses.mean_squared_error(i,frame_offset)\n",
    "        # Compute gradient\n",
    "        trainable_vars = self.trainable_variables\n",
    "        gradients = tape.gradient(loss,trainable_vars)\n",
    "        # Update weights\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "        # matrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.mae_metric.update_state(i, frame_offset)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
    "    def test_step(self,data):\n",
    "        inputs,frame_offset = data\n",
    "        tau_vec_matrix = self.OE(inputs, training=False)\n",
    "        tau_sum_vec = tf.reduce_sum(circular_shift(tau_vec_matrix),0)/result.shape[1]   # This vector has size of N_msg, and has the maximum mean value,                                                                         # corresponding to the shift\n",
    "        r = np.argmax(tau_sum_vec) # (or use tf.math.argmax)\n",
    "        i = r-1 -N_msg(np.fix((r-1)/(N_msg/2)))\n",
    "        # compute the loss\n",
    "        loss = keras.losses.mean_squared_error(i,frame_offset)\n",
    "        # matrics\n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.mae_metric.update_state(i, frame_offset)\n",
    "        return {\"loss\": self.loss_tracker.result(), \"mae\": self.mae_metric.result()}\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.mae_metric]\n",
    "    \n",
    "    \n",
    "OE_model = OffsetEstimator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train OE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_offset(frame):\n",
    "    seq_matrix = create_2d_array(frame,N_seq,q)\n",
    "    i_b = OE_model(seq_matrix)   # Frame offset index value\n",
    "    return i_b\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
