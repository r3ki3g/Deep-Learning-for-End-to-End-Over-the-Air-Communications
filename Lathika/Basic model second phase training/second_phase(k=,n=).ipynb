{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rx_4n_2k.model as model\n",
    "import rx_4n_2k.__init__ as init\n",
    "import os\n",
    "import h5py\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "n = 2\n",
    "\n",
    "learning_rate = 1e-2\n",
    "n_epochs = 10\n",
    "\n",
    "weight_path = 'rx_4n_2k\\weights.h5'\n",
    "input_data_path = r'received_iq.csv'\n",
    "label_data_path = r'actual_labels.csv'\n",
    "\n",
    "best_model_name_and_path = r'best_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(load_weights=True, debug=False):\n",
    "    m = model.create_model()\n",
    "    if load_weights:\n",
    "        loadWeights(m, debug=debug)\n",
    "    return m\n",
    "\n",
    "## Utility functions:\n",
    "\n",
    "\n",
    "def loadWeights(model, filename=weight_path, debug=False):\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        # Every layer is an h5 group. Ignore non-groups (such as /0)\n",
    "        for g in f:\n",
    "            if isinstance(f[g], h5py.Group):\n",
    "                group = f[g]\n",
    "                layerName = group.attrs['Name']\n",
    "                numVars = int(group.attrs['NumVars'])\n",
    "                if debug:\n",
    "                    print(\"layerName:\", layerName)\n",
    "                    print(\"    numVars:\", numVars)\n",
    "                # Find the layer index from its namevar\n",
    "                layerIdx = layerNum(model, layerName)\n",
    "                layer = model.layers[layerIdx]\n",
    "                if debug:\n",
    "                    print(\"    layerIdx=\", layerIdx)\n",
    "                # Every weight is an h5 dataset in the layer group. Read the weights \n",
    "                # into a list in the correct order\n",
    "                weightList = [0]*numVars\n",
    "                for d in group:\n",
    "                    dataset = group[d]\n",
    "                    varName = dataset.attrs['Name']\n",
    "                    shp     = intList(dataset.attrs['Shape'])\n",
    "                    weightNum = int(dataset.attrs['WeightNum'])\n",
    "                    # Read the weight and put it into the right position in the list\n",
    "                    if debug:\n",
    "                        print(\"    varName:\", varName)\n",
    "                        print(\"        shp:\", shp)\n",
    "                        print(\"        weightNum:\", weightNum)\n",
    "                    weightList[weightNum] = tf.constant(dataset[()], shape=shp)\n",
    "                # Assign the weights into the layer\n",
    "                for w in range(numVars):\n",
    "                    if debug:\n",
    "                        print(\"Copying variable of shape:\")\n",
    "                        print(weightList[w].shape)\n",
    "                    layer.variables[w].assign(weightList[w])\n",
    "                    if debug:\n",
    "                        print(\"Assignment successful.\")\n",
    "                        print(\"Set variable value:\")\n",
    "                        print(layer.variables[w])\n",
    "                # Finalize layer state\n",
    "                if hasattr(layer, 'finalize_state'):\n",
    "                    layer.finalize_state()\n",
    "\n",
    "def layerNum(model, layerName):\n",
    "    # Returns the index to the layer\n",
    "    layers = model.layers\n",
    "    for i in range(len(layers)):\n",
    "        if layerName==layers[i].name:\n",
    "            return i\n",
    "    print(\"\")\n",
    "    print(\"WEIGHT LOADING FAILED. MODEL DOES NOT CONTAIN LAYER WITH NAME: \", layerName)\n",
    "    print(\"\")\n",
    "    return -1\n",
    "\n",
    "def intList(myList): \n",
    "    # Converts a list of numbers into a list of ints.\n",
    "    return list(map(int, myList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decimal_to_onehot_array(decimal_array,k):\n",
    "\n",
    "  one_hot_array = np.zeros((len(decimal_array), 2**k), dtype=np.float32)\n",
    "\n",
    "  # Use bitwise AND operation with powers of 2 to get individual bits\n",
    "  for i, num in enumerate(decimal_array):\n",
    "    one_hot_array[i,num]=1\n",
    "    # for j in range(k):\n",
    "    #   one_hot_array[i, k-j-1] = (num & (2**j)) != 0\n",
    "  return one_hot_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        0\n",
      "0   -0.299422364232565-0.196514844617445i\n",
      "1  -0.123069949070052+0.0469773601491152i\n",
      "2   -0.331475405155046-0.231331290499908i\n",
      "3  -0.136061816847937+0.0649977259307791i\n",
      "4   -0.204147585407668+0.215834226385493i\n",
      "[-0.29942236-0.19651484j -0.12306995+0.04697736j -0.33147541-0.23133129j\n",
      " -0.13606182+0.06499773j]\n",
      "[1 1 3 1]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 1. 0. 0.]]\n",
      "(838800, 4)\n",
      "(838800, 4)\n",
      "(629100, 4) (629100, 4)\n",
      "(209700, 4) (209700, 4)\n"
     ]
    }
   ],
   "source": [
    "decoder = load_model(load_weights=True, debug=False)\n",
    "\n",
    "# Getting data and setting up inputs and outputs to the model\n",
    "df_inp = pd.read_csv(input_data_path,header =None)\n",
    "df_out = pd.read_csv(label_data_path,header= None)\n",
    "print(df_inp.head())\n",
    "inp_stream = np.array([complex(i.replace('i','j')) for i in df_inp.iloc[:, 0]])\n",
    "print(inp_stream[0:4])\n",
    "inp_stream = np.concatenate((np.reshape(np.real(inp_stream),(-1,1)),np.reshape(np.imag(inp_stream),(-1,1))),axis=1)\n",
    "inp_stream = np.reshape(inp_stream,(-1,2*n))  # convert to a one demensional array\n",
    "out_stream = np.array([int(i) for i in df_out.iloc[:, 0]])\n",
    "print(out_stream[0:4])\n",
    "out_stream = decimal_to_onehot_array(out_stream,k)\n",
    "print(out_stream[0:4])\n",
    "# Spliting\n",
    "train_x,val_x = np.split(inp_stream,[int(0.75 * len(inp_stream))])\n",
    "train_y,val_y = np.split(out_stream,[int(0.75 * len(out_stream))])\n",
    "print(inp_stream.shape)\n",
    "print(out_stream.shape)\n",
    "print(train_x.shape,train_y.shape)\n",
    "print(val_x.shape,val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 4)]               0         \n",
      "                                                                 \n",
      " fc_3_ (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " re_lu_9 (ReLU)              (None, 4)                 0         \n",
      "                                                                 \n",
      " fc_4_ (Dense)               (None, 4)                 20        \n",
      "                                                                 \n",
      " softmax_9 (Softmax)         (None, 4)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40 (160.00 Byte)\n",
      "Trainable params: 40 (160.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "19660/19660 - 26s - loss: 0.0060 - accuracy: 0.9963 - val_loss: 2.1375e-08 - val_accuracy: 1.0000 - 26s/epoch - 1ms/step\n",
      "Epoch 2/10\n",
      "19660/19660 - 29s - loss: 1.1186e-05 - accuracy: 1.0000 - val_loss: 2.7479e-10 - val_accuracy: 1.0000 - 29s/epoch - 1ms/step\n",
      "Epoch 3/10\n",
      "19660/19660 - 26s - loss: 6.8074e-06 - accuracy: 1.0000 - val_loss: 3.6576e-08 - val_accuracy: 1.0000 - 26s/epoch - 1ms/step\n",
      "Epoch 4/10\n",
      "19660/19660 - 27s - loss: 1.4059e-05 - accuracy: 1.0000 - val_loss: 7.9800e-11 - val_accuracy: 1.0000 - 27s/epoch - 1ms/step\n",
      "Epoch 5/10\n",
      "19660/19660 - 27s - loss: 9.0138e-06 - accuracy: 1.0000 - val_loss: 2.5147e-08 - val_accuracy: 1.0000 - 27s/epoch - 1ms/step\n",
      "Epoch 6/10\n",
      "19660/19660 - 26s - loss: 1.3633e-05 - accuracy: 1.0000 - val_loss: 8.4987e-11 - val_accuracy: 1.0000 - 26s/epoch - 1ms/step\n",
      "Epoch 7/10\n",
      "19660/19660 - 27s - loss: 9.0925e-06 - accuracy: 1.0000 - val_loss: 4.4043e-09 - val_accuracy: 1.0000 - 27s/epoch - 1ms/step\n",
      "Epoch 8/10\n",
      "19660/19660 - 25s - loss: 2.0463e-05 - accuracy: 1.0000 - val_loss: 1.4567e-11 - val_accuracy: 1.0000 - 25s/epoch - 1ms/step\n",
      "Epoch 9/10\n",
      "19660/19660 - 26s - loss: 1.2961e-05 - accuracy: 1.0000 - val_loss: 1.7097e-10 - val_accuracy: 1.0000 - 26s/epoch - 1ms/step\n",
      "Epoch 10/10\n",
      "19660/19660 - 25s - loss: 1.2877e-05 - accuracy: 1.0000 - val_loss: 7.5432e-09 - val_accuracy: 1.0000 - 25s/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train decoder\n",
    "decoder.compile(optimizer=Adam(learning_rate=learning_rate),loss=\"binary_crossentropy\",metrics = ['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience =n_epochs//10)\n",
    "mc = ModelCheckpoint(best_model_name_and_path,monitor='val_accuracy',mode='max',verbose=1,save_best_only=True)\n",
    "history = decoder.fit(train_x,train_y,validation_data = (val_x,val_y),epochs = n_epochs,verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
