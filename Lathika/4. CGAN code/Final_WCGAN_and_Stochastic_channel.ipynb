{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "\n",
    "#To datasets -> import tensorflow_datasets as tfds\n",
    "\n",
    "# For models\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, \\\n",
    "                                    Dropout, Embedding, Input, Concatenate #, Conv2DTranspose\n",
    "\n",
    "from scipy.stats import nakagami\n",
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import uniform\n",
    "# For visualisation\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating the data set\n",
    "k = 2\n",
    "M = 2**k\n",
    "\n",
    "NUM_CHANNEL_USES = 2\n",
    "\n",
    "block_size = 320\n",
    "n_blocks_train = 10**4\n",
    "n_blocks_val = 10**3\n",
    "n_blocks_train_GAN = 10**4\n",
    "\n",
    "n_train = block_size * n_blocks_train\n",
    "n_val   = block_size * n_blocks_val\n",
    "\n",
    "n_train_GAN = block_size * n_blocks_train_GAN\n",
    "\n",
    "num_epoches_AE = 5\n",
    "num_epoches_WCGAN= 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_parameters = {\n",
    "    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "    \"roll_off\" : 0.35,          # Roll off factor\n",
    "    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1) \n",
    "    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period \n",
    "    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1 \n",
    "    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "}\n",
    "\n",
    "nakagami_m = 5 # m=1 for reighley\n",
    "OMEGA = np.sqrt(2)\n",
    "AWGN_std = np.sqrt(1/10**(channel_parameters['snr']/10))#np.sqrt(OMEGA * 10 ** (-0.1 * gamma_bar) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        out = tf.nn.l2_normalize(inputs, axis=-1)\n",
    "        print(\"normalize output shape = \",out.shape)\n",
    "        return out\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "    \n",
    "\n",
    "def generate_nakagami_samples(m, omega):\n",
    "      \n",
    "    nakagami_amp_vec = nakagami.rvs(m,omega,size =  NUM_CHANNEL_USES)   # Same gain for the real part and the imaginary part\n",
    "    nakagami_phase_vec = np.random.uniform(low=0.0, high=2*np.pi, size = NUM_CHANNEL_USES)    # phase shift will effect the complex number\n",
    "    nakagami_for_real = np.reshape(nakagami_amp_vec*np.cos(nakagami_phase_vec),(-1,1))\n",
    "    nakagami_for_imag = np.reshape(nakagami_amp_vec*np.sin(nakagami_phase_vec),(-1,1))\n",
    "    fading_vec = np.reshape(np.concatenate((nakagami_for_real,nakagami_for_imag),axis=1),(1,-1))[0]\n",
    "    return  tf.constant(fading_vec, dtype=tf.float32)\n",
    "    \n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "    def call(self, inputs, training=False):\n",
    "        if  1 or training:\n",
    "            fading = generate_nakagami_samples(m = self.distribution_params[\"m\"], \n",
    "                                              omega = self.distribution_params[\"omega\"]) \n",
    "            return inputs * fading\n",
    "        else:\n",
    "            return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create the complex values\n",
    "def real_to_complex_tensor(inp_tensor):\n",
    "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
    "  real_part = inp_tensor[:, 0]\n",
    "  imag_part = inp_tensor[:, 1]\n",
    "  complex_tensor = tf.complex(real_part, imag_part)\n",
    "  return complex_tensor\n",
    "\n",
    "def complex_to_real_tensor(inp_tensor):\n",
    "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
    "   real_part = tf.reshape(real_part,[-1,1])\n",
    "   imag_part = tf.reshape(imag_part,[-1,1])\n",
    "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
    "\n",
    "# Upsample\n",
    "def upsampling(inp,r):\n",
    "  com_reshape = tf.reshape(inp,[-1,1])\n",
    "  padding = tf.constant([[0,0],[0,r-1]])\n",
    "  upsampled = tf.pad(com_reshape,padding,\"CONSTANT\")\n",
    "  return tf.reshape(upsampled,[-1])\n",
    "\n",
    "# Normalized RRC with time shift\n",
    "def NRRC_filter(num_taps, roll_off, time_delay):\n",
    "  t = np.linspace(-(num_taps-1)/2,(num_taps-1)/2,num_taps) - time_delay\n",
    "  eps = np.finfo(float).eps # Small epsilon to avoid divisiomn by zero\n",
    "  pi = np.pi\n",
    "  def RRC_filter_coff(t):\n",
    "    if abs(t) < eps:  # For t==0\n",
    "      return 1.0 - roll_off + (4*roll_off/pi)\n",
    "    elif roll_off != 0 and (abs(t-1/(4*roll_off))<eps or abs(t+1/(4*roll_off))<eps):\n",
    "      return (roll_off/np.sqrt(2))*(1 + 2/pi)*np.sin(pi/(4*roll_off)) + (1- 2/pi)*np.cos(pi/(4*roll_off))\n",
    "    else:\n",
    "      nu = np.sin(pi*t*(1-roll_off)) + 4*roll_off*t*np.cos(pi*t*(1+roll_off))\n",
    "      den = pi*t*(1-(4*roll_off*t)**2)\n",
    "      return nu/(den + eps)\n",
    "  filter_coff = np.array([RRC_filter_coff(T) for T in t])\n",
    "  NRRC_filter_coff = filter_coff / np.sum(np.abs(filter_coff))\n",
    "  print(f\"Time_delay = {time_delay}\")\n",
    "  plt.stem(t,NRRC_filter_coff)  # Plot for visualization\n",
    "  return tf.constant(NRRC_filter_coff,dtype = tf.float32)\n",
    "\n",
    "# Phase offset\n",
    "def PhaseOffset_vec(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "  l = batch_size*r*NUM_CHANNEL_USES+num_taps-1\n",
    "  CFO_off = 0.1*CFO_std#truncnorm.rvs(-1.96,1.96)*CFO_std  # boundaries will be selected for 95% confidence\n",
    "  print(\"CFO_off =\",CFO_off)   \n",
    "  print(\"Phase offset = \",phase_off)                                          # CFO_min and CFO_max (boundaries) will be selected for 95% confidence\n",
    "  exp_vec = []\n",
    "  for i in range(l):\n",
    "    exp_vec.append(tf.math.exp(tf.constant([0+(2*np.pi*i*CFO_off+phase_off)*1j],dtype=tf.complex64)))\n",
    "  return tf.reshape(tf.stack(exp_vec),[-1])\n",
    "   \n",
    "\n",
    "class UpsamplingLayer(keras.layers.Layer):\n",
    "    def __init__(self, r =r):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "    def call(self,inputs):\n",
    "       return upsampling(inputs,self.r)\n",
    "    \n",
    "class PulseShaping(keras.layers.Layer): \n",
    "    def __init__(self,num_taps,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "    def call(self, inputs):\n",
    "      padding_size = self.num_taps // 2\n",
    "      paddings = tf.constant([[padding_size, padding_size]])\n",
    "      real_part = tf.pad(tf.math.real(inputs), paddings, \"CONSTANT\")\n",
    "      imag_part = tf.pad(tf.math.imag(inputs), paddings, \"CONSTANT\")\n",
    "      real_part = tf.reshape(real_part,[1,-1,1])\n",
    "      imag_part = tf.reshape(imag_part,[1,-1,1])\n",
    "      real_conv = tf.nn.conv1d(real_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      imag_conv = tf.nn.conv1d(imag_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      real_conv = tf.reshape(real_conv,[-1])\n",
    "      imag_conv = tf.reshape(imag_conv,[-1])\n",
    "      return tf.complex(real_conv,imag_conv)\n",
    "\n",
    "class PhaseOffset(keras.layers.Layer):\n",
    "    def __init__(self,batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std,phase_off):\n",
    "      super().__init__()\n",
    "      self.batch_size = batch_size\n",
    "      self.num_channel_uses = NUM_CHANNEL_USES\n",
    "      self.num_taps = num_taps\n",
    "      self.r = r\n",
    "      self.CFO_std = CFO_std\n",
    "      self.phase_off = phase_off\n",
    "    def call(self,inputs):\n",
    "       return inputs * PhaseOffset_vec(self.batch_size, self.num_channel_uses,self.num_taps,self.r,self.CFO_std, self.phase_off)\n",
    "\n",
    "\n",
    "class StochasticChannelLayer(keras.layers.Layer):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        channel_parameters ---> custom class for parameters store\n",
    "                                channel_parameters = {\n",
    "                                    \"r\"        : 4,             # For upsampling -> number of complex samples per symbol\n",
    "                                    \"roll_off\" : 0.35,          # Roll off factor\n",
    "                                    \"num_taps\" : 31,            # L -> Number of taps (odd) for RRC filter\n",
    "                                    \"f_s\"      : 25e4,          # Add what is in the physical implementation\n",
    "                                    \"T_bound\"  : 1/25e4,        # 1/f_s Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1) \n",
    "                                    \"time_delay\" : np.random.uniform(-1,1), # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period \n",
    "                                    \"CFO\"      : 5e3,           # Observe from the physical implementation\n",
    "                                    \"CFO_std\"  : 5e3/25e4,      # CFO/f_s\n",
    "                                    \"snr\"      : 6,             # noise power will be calculating assuming transmittting power of 1 \n",
    "                                    \"phase_off\": uniform.rvs(scale = 2*np.pi)  # constant for one channel input\n",
    "                                }\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain, \n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self,name,NUM_CHANNEL_USES,batch_size,channel_parameters,**kwargs):\n",
    "        super(StochasticChannelLayer,self).__init__(name=name,**kwargs)\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(r)\n",
    "        self.PulseShaping_inst = PulseShaping(channel_parameters['num_taps'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['CFO_std'],channel_parameters['phase_off'])\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(channel_parameters['snr']/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder mask layer\n",
    "\n",
    "class PulseShaping_Dec(keras.layers.Layer): \n",
    "    def __init__(self,num_taps,r,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "      self.r =r\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[1,-1,1])\n",
    "      inp_conv = tf.nn.conv1d(inputs,self.nrrc_filter,stride=self.r,padding=\"VALID\")\n",
    "      inp_conv = tf.reshape(inp_conv,[-1])\n",
    "      return inp_conv\n",
    "\n",
    "class DecoderMaskLayer(keras.layers.Layer):\n",
    "    def __init__(self,name,channel_parameters,NUM_CHANNEL_USES):\n",
    "        super(DecoderMaskLayer,self).__init__(name=name)\n",
    "        # self.Convo = PulseShaping_Dec(channel_parameters['num_taps'],channel_parameters['r'],channel_parameters['roll_off'],channel_parameters['time_delay'])\n",
    "        self.Convo = tf.keras.layers.Conv1D(1,channel_parameters['num_taps'],strides=channel_parameters['r'], padding = 'valid',activation = 'relu',use_bias=True)\n",
    "        self.channel_uses = NUM_CHANNEL_USES\n",
    "    def call(self,inputs):\n",
    "        inp = tf.reshape(inputs,[-1,2])\n",
    "        real_part, imag_part = inp[:,0],inp[:,1]\n",
    "        vec_shape = real_part.shape[0]\n",
    "        #print(\"real shape\",real_part.shape)\n",
    "        real_part, imag_part = tf.reshape(real_part,[1,vec_shape,1]), tf.reshape(imag_part,[1,vec_shape,1])\n",
    "        real_part = tf.reshape(self.Convo(real_part),[-1,1])\n",
    "        imag_part = tf.reshape(self.Convo(imag_part),[-1,1])\n",
    "        #print(\"real shape after conv \",real_part.shape)\n",
    "        outputs = tf.concat([real_part,imag_part],1)\n",
    "        return tf.reshape(outputs,[-1,2*self.channel_uses])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the Encoder, channel and the decoder model for given parameteres\n",
    "\n",
    "def AE_out(k,NUM_CHANNEL_USES,num_epoches,channel_parameters):\n",
    "\n",
    "    # generating the data set\n",
    "    x_train = np.array(np.random.rand(n_train,k)<0.5).astype(np.float32)\n",
    "    y_train = x_train\n",
    "    x_val = np.array(np.random.rand(n_val,k)<0.5).astype(np.float32)\n",
    "    y_val = x_val\n",
    "\n",
    "    act_func = 'tanh' # 'relu'\n",
    "\n",
    "    print(f\"-------  start ----------\")\n",
    "\n",
    "    def create_AE():\n",
    "        AE = Sequential([\n",
    "\n",
    "                        Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "                        Dense(2**k, activation=act_func),\n",
    "                        Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "                        L2Normalization(name=\"normalization_layer\"),\n",
    "                        #L2Normalization_Range(NUM_CHANNEL_USES),####\n",
    "                        \n",
    "                        StochasticChannelLayer(\"st_channel\",NUM_CHANNEL_USES,block_size,channel_parameters), \n",
    "                        DecoderMaskLayer(\"Decoder_mask\",channel_parameters,NUM_CHANNEL_USES),\n",
    "                        #NakagamiNoiseLayer({\"omega\":OMEGA,\"m\":nakagami_m}),\n",
    "                        #keras.layers.GaussianNoise(stddev = AWGN_std),\n",
    "\n",
    "                        Dense(2**k, activation=act_func,name=\"decoder_start\"),\n",
    "                        Dense(2**k, activation=act_func,name=\"decoder_middle\"),\n",
    "                        Dense(k, activation='sigmoid')\n",
    "\n",
    "                        ])\n",
    "        return AE\n",
    "\n",
    "    AE = create_AE()\n",
    "    AE.summary()\n",
    "    history = []\n",
    "\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                              patience=3)\n",
    "    AE.compile(optimizer=Adam(learning_rate=1e-2),loss=\"binary_crossentropy\")\n",
    "    history.append(AE.fit(x_train,y_train,batch_size=block_size,epochs=num_epoches,verbose=2,validation_data=(x_val,y_val),callbacks=[callback]))\n",
    "    AE.compile(optimizer=Adam(learning_rate=1e-3),loss=\"binary_crossentropy\")\n",
    "    history.append(AE.fit(x_train,y_train,batch_size=block_size,epochs=num_epoches,verbose=2,validation_data=(x_val,y_val),callbacks=[callback]))\n",
    "\n",
    "    preds = AE.predict(x_val,batch_size=block_size)>0.5\n",
    "    #         accuracy = np.mean( preds == y_val  )\n",
    "    def calc_block_accuracy(preds,y_val):\n",
    "        n_bits_per_block = preds.shape[1]\n",
    "        n_correct_bits = np.sum(preds == y_val,axis=1)\n",
    "        block_accuracy = np.mean(n_correct_bits == n_bits_per_block)\n",
    "        return block_accuracy\n",
    "    accuracy =  calc_block_accuracy(preds,y_val)\n",
    "    print(f\"validation accuracy = {accuracy}\")\n",
    "\n",
    "    encoder = Model(inputs=AE.input,outputs=AE.get_layer('normalization_layer').output)\n",
    "    channel = Model(inputs = AE.get_layer(\"st_channel\").input,outputs=AE.get_layer(\"Decoder_mask\").output)\n",
    "    decoder = Model(inputs=AE.get_layer(\"decoder_start\").input,outputs=AE.output)\n",
    "\n",
    "    return  encoder , channel, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional wasserstein GAN\n",
    "https://www.kaggle.com/code/ritvik1909/wasserstein-gan-with-gradient-penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Wasserstein GAN\n",
    "\n",
    "\"\"\"\n",
    "Conditional info ----> Channel coefficient real and imaginary parts for each channel use + Encodee outputs (all the channel uses)\n",
    "                       If the num_channel_uses = 2, there will be two vectors of length 4,  concaternated. First vector is the real and imaginary of the encoder outputs and \n",
    "                       the second vector of channel coefficients (2 complex channel coefficients -> 4 numbers)  \n",
    "Genarator inputs ----> Noise vector of encoder outpus size + conditional infomation\n",
    " \"\"\"\n",
    "\n",
    "def build_generator():\n",
    "    inp_length = 2* NUM_CHANNEL_USES \n",
    "    noise = Input(shape= (inp_length,))#(shape=(16,))\n",
    "    input_pilot_conditional = Input(shape=(inp_length,))#(2  **k  *NUM_CHANNEL_USES  *2,))\n",
    "    enc_out_conditional = Input(shape = (inp_length,))#(shape=(2,)) # real and imag parts of any symbol\n",
    "    concat = Concatenate()([noise,input_pilot_conditional,enc_out_conditional])\n",
    "\n",
    "    l = Dense(128)(concat)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(128)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(128)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    output = Dense(inp_length,activation='linear')(l)#(2,activation = 'linear')(l) # real and imag parts of any symbol\n",
    "\n",
    "    model = Model([noise,input_pilot_conditional,enc_out_conditional],output)\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "\n",
    "generator.summary()\n",
    "# tf.keras.utils.plot_model(generator, show_shapes=True)\n",
    "\n",
    "\n",
    "def build_discriminator():\n",
    "    inp_length = 2* NUM_CHANNEL_USES \n",
    "    dicr_inp = Input(shape = (inp_length,))\n",
    "    input_pilot_conditional = Input(shape=(inp_length,))#(2  **k  *NUM_CHANNEL_USES  *2,))\n",
    "    enc_out_conditional = Input(shape = (inp_length,))#(shape=(2,)) # real and imag parts of any symbol\n",
    "    concat = Concatenate()([dicr_inp,input_pilot_conditional,enc_out_conditional])\n",
    "\n",
    "    l = Dense(32)(concat)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(32)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    l = Dense(32)(l)\n",
    "    l = LeakyReLU(alpha = 0.2)(l)\n",
    "    output = Dense(1,activation = 'linear')(l)\n",
    "\n",
    "    model = Model([dicr_inp,input_pilot_conditional,enc_out_conditional],output)\n",
    "    return model\n",
    "\n",
    "discriminator = build_discriminator()\n",
    "\n",
    "discriminator.summary()\n",
    "# tf.keras.utils.plot_model(discriminator, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_true * y_pred)\n",
    "\n",
    "def gradient_penalty(batch_size, real, fake, discriminator):\n",
    "    epsilon = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "    interpolated = epsilon*real + (1-epsilon)*fake #real + epsilon * diff\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(interpolated)\n",
    "        pred = discriminator(interpolated, training=True)\n",
    "    grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "    gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "    return gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 5 8 3 5 8], shape=(6,), dtype=int32)\n",
      "tf.Tensor([3 5 8 3 5 8 3 5 8], shape=(9,), dtype=int32)\n",
      "[array([3, 5, 8]), array([3, 5, 8]), array([3, 5, 8])]\n",
      "tf.Tensor(\n",
      "[[3. 5. 8.]\n",
      " [3. 5. 8.]\n",
      " [3. 5. 8.]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(5.3333335, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a =np.array([3,5,8])\n",
    "b=Concatenate()([a,a])\n",
    "print(b)\n",
    "c= Concatenate()([b,a])\n",
    "d = tf.constant([a,a,a],dtype=tf.float32)\n",
    "print(c)\n",
    "print([a,a,a])\n",
    "print(d)\n",
    "print(tf.reduce_mean(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_gp = 10.0  # gradient penalty weight\n",
    "\n",
    "# optimizers\n",
    "opt_g = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "opt_d = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "\n",
    "# models remain the same\n",
    "generator_WGAN = build_generator()\n",
    "discriminator_WGAN = build_discriminator()\n",
    "\n",
    "# custom training step to include Wasserstein loss and gradient penalty\n",
    "class WGANGP(Model):\n",
    "    def __init__(self ,latent_dim ,discriminator_extra_steps , generator, discriminator, **kwargs):\n",
    "        super(WGANGP, self).__init__(**kwargs)\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.latent_dim = latent_dim        # 2*NUM_CHANNEL_USES prefered\n",
    "        self.d_steps = discriminator_extra_steps    # prefered 5\n",
    "\n",
    "    def compile(self, g_optimizer, d_optimizer, g_loss_fn, d_loss_fn, **kwargs):\n",
    "        super(WGANGP, self).compile(**kwargs)\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "\n",
    "    def train_step(self, real_channel_outputs,input_pilot_conditionals,enc_out_conditional ):\n",
    "        ########################################\n",
    "        if isinstance(real_channel_outputs, tuple):\n",
    "            real_channel_outputs = real_channel_outputs[0]\n",
    "\n",
    "        batch_size = tf.shape(real_channel_outputs)[0]\n",
    "\n",
    "        # train discriminator (critic)\n",
    "        for _ in range(self.d_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            inputs = [random_latent_vectors,input_pilot_conditionals,enc_out_conditional]\n",
    "            real_channel_outputs = [real_channel_outputs,input_pilot_conditionals,enc_out_conditional]\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_channel_outputs = self.generator(inputs, training=True)\n",
    "                fake_channel_outputs = [fake_channel_outputs,input_pilot_conditionals,enc_out_conditional]\n",
    "                fake_logits = self.discriminator(fake_channel_outputs, training=True)\n",
    "                real_logits = self.discriminator(real_channel_outputs, training=True)\n",
    "                # d_cost = self.d_loss_fn(tf.ones_like(real_logits), real_logits) + \\\n",
    "                #         self.d_loss_fn(-tf.ones_like(fake_logits), fake_logits)\n",
    "                d_cost = -tf.reduce_mean(real_logits) + tf.reduce_mean(fake_logits)\n",
    "                gp = gradient_penalty(batch_size, real_channel_outputs, fake_channel_outputs, self.discriminator)\n",
    "                d_loss = d_cost + lambda_gp * gp\n",
    "\n",
    "            d_grads = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            self.d_optimizer.apply_gradients(zip(d_grads, self.discriminator.trainable_variables))\n",
    "\n",
    "        # train generator\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        inputs = [random_latent_vectors,input_pilot_conditionals,enc_out_conditional]\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(random_latent_vectors, training=True)\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            g_loss = -tf.reduce_mean(gen_img_logits) #self.g_loss_fn(-tf.ones_like(gen_img_logits), gen_img_logits)\n",
    "\n",
    "        g_grads = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(g_grads, self.generator.trainable_variables))\n",
    "\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}\n",
    "\n",
    "# # compile the model\n",
    "# gan = WGANGP(2*NUM_CHANNEL_USES,5,generator_WGAN, discriminator_WGAN)\n",
    "# gan.summary()\n",
    "# gan.compile(\n",
    "#     g_optimizer=opt_g,\n",
    "#     d_optimizer=opt_d,\n",
    "#     #g_loss_fn=wasserstein_loss,\n",
    "#     #d_loss_fn=wasserstein_loss,\n",
    "# )\n",
    "\n",
    "# # training\n",
    "# history = gan.fit(dataset, batch_size=block_size, epochs=num_epoches_WCGAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating with synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_to_complex(a):\n",
    "    a= np.reshape(a,(len(a)//2,2))\n",
    "    a= np.vectorize(complex)(np.transpose(a[:,0]),np.transpose(a[:,1]))\n",
    "    return a\n",
    "\n",
    "# We input x & y two real arrays. ex:- x = [1,2,3,4] y = [5,6,7,8]\n",
    "# Then convert them into complex and calculate the channel coefficient \n",
    "# x-> [1+2j,3+4j], y-> [5+6j,7+8j]\n",
    "# h-> [a+bj] -> [a,b] returns as two real values\n",
    "def get_channel_coeff(x,y):\n",
    "    h = np.matmul(real_to_complex(x).conj().T,real_to_complex(y))/np.matmul(real_to_complex(x).conj().T,real_to_complex(x))\n",
    "    return np.array([np.real(h),np.imag(h)])\n",
    "\n",
    "# there will be different h for each frame. batch_size*3/4 of same h values will be there corresponding to the x and y values\n",
    "h = np.ones((int(num_frames*batch_size*3/4),2))\n",
    "\n",
    "for i in range(num_frames):\n",
    "    u = int(i*batch_size/4*n*2)\n",
    "    stp = int(batch_size/4)\n",
    "    temp_x = pilot_x[u:u+stp*2*n]\n",
    "    temp_y = pilot_y[u:u+stp*2*n]\n",
    "    h_temp = get_channel_coeff(temp_x,temp_y)\n",
    "    h_temp = np.reshape(np.tile(h_temp,stp*3),(stp*3,2))\n",
    "    h[i*stp*3:(i+1)*stp*3]=h_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creat_GAN_dataset(k,NUM_CHANNEL_USES,encoder,channel):\n",
    "    x_train_GAN = np.array(np.random.rand(n_train_GAN,k)<0.5).astype(np.float32)\n",
    "    enc_out_conditional = encoder(x_train_GAN)\n",
    "    size_1,size_2 = enc_out_conditional.shape[0],enc_out_conditional.shape[1]\n",
    "    channel_out = channel(enc_out_conditional)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Train_and_Get_CWGAN(channel_parameters,k,NUM_CHANNEL_USES):\n",
    "\n",
    "    encoder , channel, decoder = AE_out(k,NUM_CHANNEL_USES,num_epoches_AE,channel_parameters)\n",
    "\n",
    "    # Training GAN\n",
    "\n",
    "    lambda_gp = 10.0  # gradient penalty weight\n",
    "    # optimizers\n",
    "    opt_g = Adam(learning_rate=0.001, beta_1=0.5)\n",
    "    opt_d = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "    # models remain the same\n",
    "    generator_WGAN = build_generator()\n",
    "    discriminator_WGAN = build_discriminator()\n",
    "    # compile the model\n",
    "    gan = WGANGP(2*NUM_CHANNEL_USES,5,generator_WGAN, discriminator_WGAN)\n",
    "    gan.summary()\n",
    "    gan.compile(\n",
    "        g_optimizer=opt_g,\n",
    "        d_optimizer=opt_d,\n",
    "        #g_loss_fn=wasserstein_loss,\n",
    "        #d_loss_fn=wasserstein_loss,\n",
    "    )\n",
    "    \n",
    "    # GAN dataset\n",
    "    \n",
    "\n",
    "\n",
    "    # training\n",
    "    history = gan.fit(dataset, batch_size=block_size, epochs=num_epoches_WCGAN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
