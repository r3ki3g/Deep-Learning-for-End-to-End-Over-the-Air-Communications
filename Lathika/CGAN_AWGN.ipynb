{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resourses\n",
    "https://github.com/haoyye/End2End_GAN/tree/master\n",
    "https://github.com/matusstas/cGAN/blob/main/cgan.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 22 00:25:35 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 537.13                 Driver Version: 537.13       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce MX230         WDDM  | 00000000:02:00.0 Off |                  N/A |\n",
      "| N/A   43C    P0              N/A / ERR! |      0MiB /  2048MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "    print('Not connected to a GPU')\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb (weights and biases) -> tracking tool\n",
    "!pip install -q wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#To datasets -> import tensorflow_datasets as tfds\n",
    "\n",
    "# For models\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten, Reshape, LeakyReLU, Dropout, Embedding, Input, Concatenate #, Conv2DTranspose\n",
    "\n",
    "# Callbacks\n",
    "# Visit this -> https://kvirajdatt.medium.com/essential-tensorflow-and-keras-callbacks-for-your-neural-networks-54539244db39#:~:text=Some%20advantages%20of%20using%20these,of%20epochs%20for%20your%20training\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# For streamlining ML workflow\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# For model memory\n",
    "from tensorflow.keras import backend as k\n",
    "import humanize\n",
    "\n",
    "# For visualisation\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 7\n",
    "k = 4\n",
    "\n",
    "Input_Shape = (2*n,1)#(n*2,1)   # Shape of the conditional input (this is normalized)\n",
    "noise_std = 1           # Standerd deviation for the noise to be added to the conditional values for better generalization (change this)\n",
    "\n",
    "\"\"\"---- Import dataset here ----\"\"\"\n",
    "\n",
    "\"\"\"--------\"\"\"\n",
    "\n",
    "# latent_vector_dim = 100 # For the Generator input\n",
    "batch_size = 320\n",
    "\n",
    "#n_batches = len(data//batch_size)\n",
    "\n",
    "N_epochs = 10\n",
    "\n",
    "# Name of the project for Weights and Biases platform\n",
    "WB_project = \"CGAN\"\n",
    "\n",
    "# Entity (login) for Weights and Biases platform\n",
    "WB_entity = \"matusstas\" # shearch this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Making data - Get real data\"\"\"\n",
    "\n",
    "# Here for every 320 messages, 1/4 of them (90) are pilot symbols . every message has 2*n values (n complex values)\n",
    "num_frames = 100\n",
    "dummy_data = np.random.uniform(-1,1,num_frames*batch_size*2*n)\n",
    "\n",
    "n_batches = len(dummy_data//batch_size)\n",
    "\n",
    "def nakagami_channel(iq_samples, m, omega, snr_db):\n",
    "    # Generate Nakagami fading coefficients\n",
    "    gamma = np.random.gamma(m, scale=1/m, size=iq_samples.shape)\n",
    "\n",
    "    # Apply fading to in-phase and quadrature components\n",
    "    faded_iq = iq_samples * np.sqrt(gamma)\n",
    "\n",
    "    # Simulate AWGN\n",
    "    noise_var = 10**(-snr_db/10) / (2 * m)  # Convert SNR dB to noise variance\n",
    "    noise = np.random.normal(scale=np.sqrt(noise_var), size=iq_samples.shape) #+ 1j * np.random.normal(scale=np.sqrt(noise_var), size=iq_samples.shape)\n",
    "\n",
    "    # Add noise to faded signal\n",
    "    return faded_iq + noise\n",
    "\n",
    "i_val = int(num_frames*batch_size/4*2*n)\n",
    "x = np.zeros(i_val*3)\n",
    "y = np.zeros(i_val*3)\n",
    "pilot_x = np.zeros(i_val)\n",
    "pilot_y = np.zeros(i_val)\n",
    "\n",
    "m_list = [0.5,1,1.5]\n",
    "snr_list = [1,3,6] \n",
    "\n",
    "i_val= int(batch_size/4*2*n)\n",
    "for i in range(num_frames):\n",
    "    \n",
    "    left_i_xy = 3*i_val*i\n",
    "    right_i_xy = left_i_xy + 3*i_val\n",
    "    left_i_p = i*i_val\n",
    "    right_i_p = left_i_p + i_val\n",
    "\n",
    "\n",
    "    m = np.random.choice(m_list)\n",
    "    omega = 2*np.pi\n",
    "    snr = np.random.choice(snr_list)\n",
    "\n",
    "    x_hat = dummy_data[i*batch_size*2*n:i*batch_size*2*n+batch_size*2*n]\n",
    "    x[left_i_xy:right_i_xy] = x_hat[0:3*i_val]\n",
    "    pilot_x[left_i_p:right_i_p] = x_hat[3*i_val:batch_size*2*n]\n",
    "    y_hat = nakagami_channel(x_hat,m,omega,snr)\n",
    "    y[left_i_xy:right_i_xy] = y_hat[0:3*i_val]\n",
    "    pilot_y[left_i_p:right_i_p] = y_hat[3*i_val:batch_size*2*n]\n",
    "\n",
    "    # for every 90*2*n values in pilot, there are 270*2*n values for normal signals\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(336000,)\n",
      "(336000,)\n",
      "(112000,)\n",
      "(112000,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(pilot_x.shape)\n",
    "print(pilot_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate channel function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11251814+0.89331898j  0.87539909-0.67693898j  0.63174895+0.64181104j\n",
      " ... -0.06901767+0.21416178j  0.63896359-0.40965382j\n",
      " -0.92664883-0.35104461j]\n",
      "[-0.03893125-0.38876497j  0.42148561-1.41094349j  0.681181  -1.03244978j\n",
      " ... -0.55325849+0.08069552j -0.16755595-0.43548219j\n",
      " -1.05568085+0.50445823j]\n",
      "[ 0.11251814+0.89331898j  0.87539909-0.67693898j  0.63174895+0.64181104j\n",
      " ... -0.06901767+0.21416178j  0.63896359-0.40965382j\n",
      " -0.92664883-0.35104461j]\n",
      "[ 0.11251814+0.89331898j  0.87539909-0.67693898j  0.63174895+0.64181104j\n",
      " ... -0.06901767+0.21416178j  0.63896359-0.40965382j\n",
      " -0.92664883-0.35104461j]\n",
      "(0.8718785362900613+0.0025636499707518976j)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def real_to_complex(a):\n",
    "    a= np.reshape(a,(len(a)//2,2))\n",
    "    a= np.vectorize(complex)(np.transpose(a[:,0]),np.transpose(a[:,1]))\n",
    "    print(a)\n",
    "    return a\n",
    "\n",
    "h = np.matmul(real_to_complex(x).conj().T,real_to_complex(y))/np.matmul(real_to_complex(x).conj().T,real_to_complex(x))\n",
    "print(h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5  11  23]\n",
      " [ 11  25  53]\n",
      " [ 23  53 113]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4],[7,8]])\n",
    "print(np.matmul(a,a.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
