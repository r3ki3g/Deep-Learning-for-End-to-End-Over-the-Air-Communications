{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSTgsilO1_ur"
   },
   "source": [
    "online version of this notebook : https://colab.research.google.com/drive/12iz5_mTOmTa0oyn5IZZYnEskVUonViVW#scrollTo=VSTgsilO1_ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:08.515186Z",
     "start_time": "2024-04-16T15:45:01.104864Z"
    },
    "id": "pWavhXJRGytK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:08.530553Z",
     "start_time": "2024-04-16T15:45:08.516134Z"
    },
    "id": "4k-_9gsVQnu1"
   },
   "outputs": [],
   "source": [
    "def get_feature_extractor():\n",
    "  raise NotImplementedError()\n",
    "\n",
    "def get_internal_slicer():\n",
    "  raise NotImplementedError()\n",
    "\n",
    "\n",
    "def get_rx_decoder():\n",
    "  raise NotImplementedError()\n",
    "\n",
    "def phase_multiply(internally_sliced_y,h):\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNx0nzHGxCtg"
   },
   "source": [
    "## PARAMS\n",
    "<a name=\"params\">.</a>\n",
    "<a href=\"#datasyn\">go to data gen</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:08.545398Z",
     "start_time": "2024-04-16T15:45:08.532756Z"
    },
    "id": "eQvOU0nYbPdu"
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "\n",
    "k = 4\n",
    "NUM_CHANNEL_USES = 7\n",
    "block_size = 320\n",
    "\n",
    "snr = 6 #9 for training\n",
    "\n",
    "model_training_num_of_frames = 10**3 #10**4\n",
    "model_validating_num_of_frames = 10**2 #10**3\n",
    "\n",
    "n_train = block_size * model_training_num_of_frames\n",
    "n_val   = block_size * model_validating_num_of_frames\n",
    "\n",
    "# Geanerating dataset\n",
    "model_output_num_of_frames = 10**5\n",
    "n_out = block_size * model_output_num_of_frames\n",
    "\n",
    "num_epoches = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:08.564213Z",
     "start_time": "2024-04-16T15:45:08.547392Z"
    },
    "id": "8llGxbteuvUt"
   },
   "outputs": [],
   "source": [
    "SLICED_Y_LENGTH = 16\n",
    "BATCH_SIZE =  1\n",
    "\n",
    "# in teh feature extractor path \"f\" : design param\n",
    "# Our experiments have shown that even a\n",
    "# small number of features, e.g., F = 4, significantly improves\n",
    "# the performance.\n",
    "N_FEATURES_EXTRACTED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:08.575823Z",
     "start_time": "2024-04-16T15:45:08.569203Z"
    },
    "id": "AU4v5qeU_LTW"
   },
   "outputs": [],
   "source": [
    "def R2C(a):\n",
    "\n",
    "    aa = tf.cast(tf.reshape(a,shape=(BATCH_SIZE,-1,2)),tf.float32)\n",
    "\n",
    "    aaa = tf.complex(aa[:,:,0],aa[:,:,1])\n",
    "    return aaa\n",
    "\n",
    "def C2R(a):\n",
    "    real, imag = tf.expand_dims(tf.math.real(a),axis=2) ,tf.expand_dims(tf.math.imag(a), axis=2)\n",
    "    R = tf.concat((real,imag),axis=2)\n",
    "    R = tf.reshape(R , (BATCH_SIZE,-1)  )\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9Oj3oPvZcHV"
   },
   "source": [
    "# Stochastic Channel Model & Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsd5N4qhfV0O"
   },
   "source": [
    "### Additional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:08.623365Z",
     "start_time": "2024-04-16T15:45:08.576820Z"
    },
    "id": "a73PhgGbfYlk"
   },
   "outputs": [],
   "source": [
    "class L2Normalization(tf.keras.layers.Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        out = tf.nn.l2_normalize(inputs, axis=-1)\n",
    "        print(\"normalize output shape = \",out.shape)\n",
    "        return out\n",
    "    def get_config(self):\n",
    "        return super(L2Normalization, self).get_config()\n",
    "\n",
    "\n",
    "def generate_nakagami_samples(m, omega):\n",
    "    nakagami_amp_vec = nakagami.rvs(m,omega,size =  NUM_CHANNEL_USES)   # Same gain for the real part and the imaginary part\n",
    "    nakagami_phase_vec = np.random.uniform(low=0.0, high=2*np.pi, size = NUM_CHANNEL_USES)    # phase shift will effect the complex number\n",
    "    nakagami_for_real = np.reshape(nakagami_amp_vec*np.cos(nakagami_phase_vec),(-1,1))\n",
    "    nakagami_for_imag = np.reshape(nakagami_amp_vec*np.sin(nakagami_phase_vec),(-1,1))\n",
    "    fading_vec = np.reshape(np.concatenate((nakagami_for_real,nakagami_for_imag),axis=1),(1,-1))[0]\n",
    "    return  tf.constant(fading_vec, dtype=tf.float32)\n",
    "\n",
    "class NakagamiNoiseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, distribution_params, **kwargs):\n",
    "        super(NakagamiNoiseLayer, self).__init__(**kwargs)\n",
    "        self.distribution_params = distribution_params\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "      fading = generate_nakagami_samples(m = self.distribution_params[\"m\"],\n",
    "                                        omega = self.distribution_params[\"omega\"])\n",
    "      return inputs * fading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1ejiEuHf1B0"
   },
   "source": [
    "### Stochastic channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.325859Z",
     "start_time": "2024-04-16T15:45:08.625364Z"
    },
    "id": "Tm8yRX0xa_ul"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import truncnorm\n",
    "from scipy.stats import uniform\n",
    "\n",
    "r = 4           # For upsampling -> number of complex samples per symbol\n",
    "roll_off = 0.35 # Roll off factor\n",
    "L = 31          # Number of taps (odd) for RRC filter\n",
    "f_s = 25e4      # 25e4 is used in our physical implementation  # 2e6 used in the paper\n",
    "T_bound = 1/f_s # Go through the resharch paper Deep Learning Based Communication Over the Air  (content under table 1)\n",
    "time_delay = np.random.uniform(-1,1) # To convert the time delay into discrete domain, time dilay is giving relative to the sampling period\n",
    "CFO = 5e3       # 5e3 is used in our physical implementation\n",
    "CFO_std = CFO/f_s\n",
    "snr = snr         # Snr in db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.357243Z",
     "start_time": "2024-04-16T15:45:09.326864Z"
    },
    "id": "gA_f6Q7cZiUN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# function to create the complex values\n",
    "def real_to_complex_tensor(inp_tensor):\n",
    "  inp_tensor = tf.reshape(inp_tensor, [-1, 2])\n",
    "  real_part = inp_tensor[:, 0]\n",
    "  imag_part = inp_tensor[:, 1]\n",
    "  complex_tensor = tf.complex(real_part, imag_part)\n",
    "  return complex_tensor\n",
    "\n",
    "def complex_to_real_tensor(inp_tensor):\n",
    "   real_part , imag_part = tf.math.real(inp_tensor), tf.math.imag(inp_tensor)\n",
    "   real_part = tf.reshape(real_part,[-1,1])\n",
    "   imag_part = tf.reshape(imag_part,[-1,1])\n",
    "   return tf.reshape(tf.concat([real_part,imag_part],1),[-1])\n",
    "\n",
    "# Upsample\n",
    "def upsampling(inp,r):\n",
    "  com_reshape = tf.reshape(inp,[-1,1])\n",
    "  padding = tf.constant([[0,0],[0,r-1]])\n",
    "  upsampled = tf.pad(com_reshape,padding,\"CONSTANT\")\n",
    "  return tf.reshape(upsampled,[-1])\n",
    "\n",
    "# Normalized RRC with time shift\n",
    "def NRRC_filter(num_taps, roll_off, time_delay):\n",
    "  t = np.linspace(-(num_taps-1)/2,(num_taps-1)/2,num_taps) - time_delay\n",
    "  eps = np.finfo(float).eps # Small epsilon to avoid divisiomn by zero\n",
    "  pi = np.pi\n",
    "  def RRC_filter_coff(t):\n",
    "    if abs(t) < eps:  # For t==0\n",
    "      return 1.0 - roll_off + (4*roll_off/pi)\n",
    "    elif roll_off != 0 and (abs(t-1/(4*roll_off))<eps or abs(t+1/(4*roll_off))<eps):\n",
    "      return (roll_off/np.sqrt(2))*(1 + 2/pi)*np.sin(pi/(4*roll_off)) + (1- 2/pi)*np.cos(pi/(4*roll_off))\n",
    "    else:\n",
    "      nu = np.sin(pi*t*(1-roll_off)) + 4*roll_off*t*np.cos(pi*t*(1+roll_off))\n",
    "      den = pi*t*(1-(4*roll_off*t)**2)\n",
    "      return nu/(den + eps)\n",
    "  filter_coff = np.array([RRC_filter_coff(T) for T in t])\n",
    "  NRRC_filter_coff = filter_coff / np.sum(np.abs(filter_coff))\n",
    "  print(f\"Time_delay = {time_delay}\")\n",
    "  plt.stem(t,NRRC_filter_coff)  # Plot for visualization\n",
    "  return tf.constant(NRRC_filter_coff,dtype = tf.float32)\n",
    "\n",
    "# Phase offset\n",
    "def PhaseOffset_vec(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std):\n",
    "  l = batch_size*r*NUM_CHANNEL_USES+num_taps-1\n",
    "  CFO_off = truncnorm.rvs(-1.96,1.96)*CFO_std  # boundaries will be selected for 95% confidence\n",
    "  print(\"CFO_off =\",CFO_off)                   # CFO_min and CFO_max (boundaries) will be selected for 95% confidence\n",
    "  exp_vec = []\n",
    "  phase_off = 0\n",
    "  for i in range(l):\n",
    "    if i%r ==0:\n",
    "      phase_off = uniform.rvs(scale = 2*np.pi)\n",
    "    exp_vec.append(tf.math.exp(tf.constant([0+(2*np.pi*i*CFO_off+phase_off)*1j],dtype=tf.complex64)))\n",
    "  return tf.reshape(tf.stack(exp_vec),[-1])\n",
    "\n",
    "\n",
    "class UpsamplingLayer(keras.layers.Layer):\n",
    "    def __init__(self, r =r):\n",
    "        super().__init__()\n",
    "        self.r = r\n",
    "    def call(self,inputs):\n",
    "       return upsampling(inputs,self.r)\n",
    "\n",
    "class PulseShaping(keras.layers.Layer):\n",
    "    def __init__(self,num_taps,roll_off,time_delay):\n",
    "      super().__init__()\n",
    "      self.nrrc_filter = NRRC_filter(num_taps,roll_off,time_delay)\n",
    "      self.nrrc_filter = tf.reshape(self.nrrc_filter,[num_taps,1,1])\n",
    "      self.num_taps = num_taps\n",
    "    def call(self, inputs):\n",
    "      padding_size = self.num_taps // 2\n",
    "      paddings = tf.constant([[padding_size, padding_size]])\n",
    "      real_part = tf.pad(tf.math.real(inputs), paddings, \"CONSTANT\")\n",
    "      imag_part = tf.pad(tf.math.imag(inputs), paddings, \"CONSTANT\")\n",
    "      real_part = tf.reshape(real_part,[1,-1,1])\n",
    "      imag_part = tf.reshape(imag_part,[1,-1,1])\n",
    "      real_conv = tf.nn.conv1d(real_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      imag_conv = tf.nn.conv1d(imag_part,self.nrrc_filter,stride=1,padding=\"SAME\")\n",
    "      real_conv = tf.reshape(real_conv,[-1])\n",
    "      imag_conv = tf.reshape(imag_conv,[-1])\n",
    "      return tf.complex(real_conv,imag_conv)\n",
    "\n",
    "class PhaseOffset(keras.layers.Layer):\n",
    "    def __init__(self,batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std):\n",
    "      super().__init__()\n",
    "      self.batch_size = batch_size\n",
    "      self.num_channel_uses = NUM_CHANNEL_USES\n",
    "      self.num_taps = num_taps\n",
    "      self.r = r\n",
    "      self.CFO_std = CFO_std\n",
    "    def call(self,inputs):\n",
    "       return inputs * PhaseOffset_vec(self.batch_size, self.num_channel_uses,self.num_taps,self.r,self.CFO_std)\n",
    "\n",
    "class StochasticChannelLayer(keras.layers.Layer):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "        r ----------> upsampling constant (number of complex samples per symbol)\n",
    "        time_delay -> uniformly distributed time delay between (-1,1), discrete domain,\n",
    "                      time dilay is giving relative to the sampling period\n",
    "        CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "        snr --------> snr for AWGN channel\n",
    "        output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self, NUM_CHANNEL_USES,batch_size,r,roll_off,num_taps,time_delay,CFO_std,snr):\n",
    "        super().__init__()\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(r)\n",
    "        self.PulseShaping_inst = PulseShaping(num_taps,roll_off,time_delay)\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std)\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(snr/10)))\n",
    "    def call(self, inputs):\n",
    "      inputs = tf.reshape(inputs,[-1])\n",
    "      inputs = real_to_complex_tensor(inputs)\n",
    "      x = self.UpSamplingLayer_inst(inputs)\n",
    "      x = self.PulseShaping_inst(x)\n",
    "      x = self.PhaseOffset_inst(x)\n",
    "\n",
    "      x = complex_to_real_tensor(x)\n",
    "      x = self.AWGNlayer(x)\n",
    "      #print(\"StochasticChannelLayer output shape = \",x.shape)\n",
    "      return x\n",
    "\n",
    "# Stochastic channel model\n",
    "class StochasticChannelModel(keras.Model):\n",
    "    \"\"\"This channel will output 1D tensor.\n",
    "    r ----------> upsampling constant (number of complex samples per symbol)\n",
    "    time_delay -> uniformly distributed time delay between (-1,1), discrete domain,\n",
    "                    time dilay is giving relative to the sampling period\n",
    "    CFO_std ----> CFO_frequency / sampling_frequency is taken as the standared deviation\n",
    "    snr --------> snr for AWGN channel\n",
    "    output_shape -> None - output_shape is 1D tensor for sequence decoder, or give an output shape prefer \"\"\"\n",
    "    def __init__(self, NUM_CHANNEL_USES,batch_size,r,roll_off,num_taps,time_delay,CFO_std,snr):\n",
    "        super().__init__()\n",
    "        self.UpSamplingLayer_inst = UpsamplingLayer(r)\n",
    "        self.PulseShaping_inst = PulseShaping(num_taps,roll_off,time_delay)\n",
    "        self.PhaseOffset_inst = PhaseOffset(batch_size,NUM_CHANNEL_USES,num_taps,r,CFO_std)\n",
    "        self.AWGNlayer = keras.layers.GaussianNoise(stddev = np.sqrt(1/10**(snr/10)))\n",
    "    def call(self, inputs):\n",
    "        inputs = tf.reshape(inputs,[-1])\n",
    "        inputs = real_to_complex_tensor(inputs)\n",
    "        x = self.UpSamplingLayer_inst(inputs)\n",
    "        x = self.PulseShaping_inst(x)\n",
    "        x = self.PhaseOffset_inst(x)\n",
    "        x = complex_to_real_tensor(x)\n",
    "        x = self.AWGNlayer(x)\n",
    "        #print(\"StochasticChannelModel output shape = \",x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG_PMHaC_Nbd"
   },
   "source": [
    "## Main Blocks in the Sequence Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.388271Z",
     "start_time": "2024-04-16T15:45:09.359218Z"
    },
    "id": "Mx-vTDXeUVmT"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeatureExtractor(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->FeatureExtractor->cf1\")\n",
    "\n",
    "        self.cf2 = Dense(N_FEATURES_EXTRACTED,name=\"r3->FeatureExtractor->cf2\")\n",
    "\n",
    "        self.cf_state = Dense(8,name=\"featureExtractor_stateFC\")\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE):\n",
    "       \n",
    "\n",
    "        # combine the sliced_y and prev_state_FE\n",
    "        sliced_y = tf.concat([sliced_y,prev_state_FE],axis=1)\n",
    "\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "\n",
    "        state_FE = self.cf_state(sliced_y) # state calculated here\n",
    "\n",
    "        sliced_y = self.cf2(state_FE)\n",
    "\n",
    "        return sliced_y,state_FE\n",
    "\n",
    "class PhaseEstimator(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->PhaseEstimator->cf1\")\n",
    "        self.cf2 = Dense(2,name=\"r3->PhaseEstimator->cf2\")\n",
    "\n",
    "        self.cf_state = Dense(8,name=\"PhaseEstimator_stateFC\")\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_PE):\n",
    "        # combine sliced_y and prev_state_PE\n",
    "        sliced_y = tf.concat([sliced_y,prev_state_PE],axis=1)\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "\n",
    "        state_PE = self.cf_state(sliced_y) # state calculated here\n",
    "\n",
    "        sliced_y = self.cf2(state_PE)\n",
    "\n",
    "        return sliced_y,state_PE\n",
    "\n",
    "\n",
    "class Rx_Decoder_old(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "        self.cf2 = Dense(256)\n",
    "        self.cf3 = Dense(16)\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "class Rx_Decoder_new(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256,name=\"r3->Rx_Decoder_new->cf1\")\n",
    "        self.cf2 = Dense(256,name=\"r3->Rx_Decoder_new->cf2\")\n",
    "        self.cf3 = Dense(16,name=\"final_out_cf3\")\n",
    "\n",
    "        # useless\n",
    "        #self.cf4_state = Dense(8,name=\"state_dense_cf4\")\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        # state = self.cf4_state(concat)\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class InternalSlicer(Model):\n",
    "    def __init__(self,l1,l2,complex_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the slice boundaries\n",
    "        mid = complex_length // 2\n",
    "        self.start = mid - l1\n",
    "        self.end = mid + l2 + 1\n",
    "\n",
    "    def call(self,sliced_y):\n",
    "\n",
    "        ret = C2R(R2C(sliced_y)[:, self.start:self.end])\n",
    "\n",
    "        return ret\n",
    "\n",
    "\n",
    "def phase_multiply(internally_sliced_y,estimated_phase):\n",
    "    # (a,b) * (c,d) = (ac-bd,ad+bc)\n",
    "\n",
    "    internally_sliced_y_complex = R2C(internally_sliced_y)\n",
    "    estimated_phase_complex = R2C(estimated_phase)\n",
    "    phase_corrected_complex = estimated_phase_complex * internally_sliced_y_complex\n",
    "\n",
    "    phase_corrected = C2R(phase_corrected_complex)\n",
    "    return phase_corrected\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T9CJbZr_UgK"
   },
   "source": [
    "## Fake data syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.403712Z",
     "start_time": "2024-04-16T15:45:09.392399Z"
    },
    "id": "mj1GemkdxHCs"
   },
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "\n",
    "# m = 512* 2** 2\n",
    "# X = tf.random.normal(shape=(block_size,SLICED_Y_LENGTH),\n",
    "#                      mean=0,\n",
    "#                      stddev=1)\n",
    "\n",
    "# Y = tf.random.uniform(shape=(m,1),\n",
    "#                       minval=0,\n",
    "#                       maxval=16,\n",
    "#                       dtype=tf.int32)\n",
    "# Y = keras.utils.to_categorical(Y,16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4xqcXAB_XdM"
   },
   "source": [
    "## Main Model : Sequence Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.419205Z",
     "start_time": "2024-04-16T15:45:09.405706Z"
    },
    "id": "M_bSkx9vHEAd"
   },
   "outputs": [],
   "source": [
    "# sequence decoder\n",
    "\n",
    "\n",
    "class SequenceDecoder(Model):\n",
    "\n",
    "    def __init__(self,take_prev_phase_state=False):\n",
    "        super(SequenceDecoder,self).__init__()\n",
    "\n",
    "        self.take_prev_phase_state = take_prev_phase_state\n",
    "\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.phase_estimator = PhaseEstimator()\n",
    "        self.internal_slicer = InternalSlicer(l1=3,l2=3,complex_length=SLICED_Y_LENGTH//2)\n",
    "\n",
    "        if take_prev_phase_state:\n",
    "            self.rx_decoder_RNN = Rx_Decoder_new()\n",
    "        else:\n",
    "            raise Exception(\"How here come??\")\n",
    "            #self.rx_decoder = Rx_Decoder_old()\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE=None,prev_state_PE=None):\n",
    "\n",
    "        if prev_state_PE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_PE = tf.constant(tf.zeros((block_size,8)))\n",
    "        if prev_state_FE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_FE = tf.constant(tf.zeros((block_size,8)))\n",
    "\n",
    "\n",
    "        # RNN conn starts here\n",
    "\n",
    "        output_FE = self.feature_extractor(sliced_y,prev_state_FE=prev_state_FE)\n",
    "        extracted_features,state_FE = output_FE[0], output_FE[1]\n",
    "\n",
    "\n",
    "\n",
    "        output_PE = self.phase_estimator(sliced_y,prev_state_PE=prev_state_PE)\n",
    "        estimated_phase,state_PE = output_PE[0], output_PE[1]\n",
    "\n",
    "        # RNN conn ends here\n",
    "\n",
    "        internally_sliced_y = self.internal_slicer(sliced_y)\n",
    "\n",
    "\n",
    "\n",
    "        phase_corrected_ = phase_multiply(internally_sliced_y,estimated_phase)\n",
    "\n",
    "        concat = tf.concat((extracted_features,phase_corrected_),axis=1)\n",
    "        if self.take_prev_phase_state:\n",
    "            st_hat = self.rx_decoder_RNN(concat)\n",
    "            return (st_hat,state_FE,state_PE)\n",
    "        else:\n",
    "            raise Exception(\"How came here????\")\n",
    "            print(\"--PROBLEM--\")\n",
    "            st_hat = self.rx_decoder(concat)\n",
    "            return st_hat\n",
    "\n",
    "\n",
    "\n",
    "    def custom_train(self,X,Y,epochs=1): # X =  vertically stacked sliced_y, y = message index\n",
    "\n",
    "        # tarin per each time step\n",
    "        for _ in range(epochs):\n",
    "\n",
    "            # temp_prev_state_PE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last PE state here\n",
    "            # temp_prev_state_FE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last FE state here\n",
    "\n",
    "            temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "            temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "\n",
    "            loss_acc = 0\n",
    "\n",
    "            for i in range(X.shape[0]):\n",
    "                print(f\"iterration : {i}\")\n",
    "                x =  tf.expand_dims(X[i,:],axis=0)\n",
    "\n",
    "                y = tf.expand_dims(Y[i,:],axis=0)\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    output = self.call(x,\n",
    "                                       prev_state_PE=temp_prev_state_PE,\n",
    "                                       prev_state_FE=temp_prev_state_FE)\n",
    "\n",
    "                    st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                    loss = self.compiled_loss(y,st_hat)\n",
    "\n",
    "                    #temp_prev_state = state ###### assign add dala balanna\n",
    "\n",
    "                    temp_prev_state_FE = (state_FE)\n",
    "                    temp_prev_state_PE = (state_PE)\n",
    "\n",
    "                grads = tape.gradient(loss,self.trainable_variables)\n",
    "                self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "                loss_acc += loss.numpy() / X.shape[0] # take the mean\n",
    "                print(\"loss (individual): \", loss.numpy())\n",
    "            print(f'Epoch  : {_}/{epochs} --> Loss = {loss_acc}')\n",
    "\n",
    "        # returning the final batch's loss\n",
    "        return loss_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T06:45:05.437856Z",
     "start_time": "2024-04-15T06:45:05.422233Z"
    },
    "id": "jq24YZr4baut"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.434413Z",
     "start_time": "2024-04-16T15:45:09.425233Z"
    },
    "id": "KqIhonChiDnM",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test the SD\n",
    "# tested and worked\n",
    "# mySD =   SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "# mySD.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#              loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# mySD.custom_train(X,Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.449880Z",
     "start_time": "2024-04-16T15:45:09.436409Z"
    },
    "id": "_rXUaAKBtGjj"
   },
   "outputs": [],
   "source": [
    "# mySD.build((2048,16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ft4zIJOAb70O"
   },
   "source": [
    "# Autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.465366Z",
     "start_time": "2024-04-16T15:45:09.453850Z"
    },
    "id": "t3LnggrMdYqV"
   },
   "outputs": [],
   "source": [
    "AWGN_std = np.sqrt(1/10**(snr/10))\n",
    "act_func = 'tanh' # 'relu'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.481226Z",
     "start_time": "2024-04-16T15:45:09.466364Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "4hLPpWIedf60",
    "outputId": "8341a7e9-8951-4f82-f9ee-2ba4bf06660a"
   },
   "outputs": [],
   "source": [
    "# # Encoder\n",
    "# Encoder = Sequential([\n",
    "#                     Dense(2**k, activation=act_func,input_shape=(2**k,)),#Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "#                     Dense(2**k, activation=act_func),\n",
    "#                     Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "#                     L2Normalization(name=\"normalization_layer\"),\n",
    "# ])\n",
    "\n",
    "# # Channel\n",
    "# Stochastic_channel = StochasticChannelModel(NUM_CHANNEL_USES,block_size,r,roll_off,L,time_delay,CFO_std,snr)\n",
    "\n",
    "# # Sequence decoder\n",
    "# Seq_decoder = SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "# # Auto encoder\n",
    "# Autoencoder = Sequential([\n",
    "#     Encoder,\n",
    "#     Stochastic_channel,\n",
    "#     # Seq_decoder\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:09.497025Z",
     "start_time": "2024-04-16T15:45:09.482246Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "D6QP70azZKLR",
    "outputId": "3bddf272-7540-429e-f177-585c26f9e1c3"
   },
   "outputs": [],
   "source": [
    "# Autoencoder.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#                     loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "\n",
    "# # cxannot connect the RNN for a whoe batch\n",
    "\n",
    "# # history = Autoencoder.fit(x_train,\n",
    "# #                           y_train,\n",
    "# #                           batch_size=block_size,\n",
    "# #                           epochs=num_epoches,\n",
    "# #                           verbose=2,\n",
    "# #                           validation_data=(x_val,y_val))\n",
    "\n",
    "# train_history = Autoencoder.custom_train(x_train,y_train,epochs=1)\n",
    "# print(\"train_history\", train_history)\n",
    "\n",
    "\n",
    "# def calc_block_accuracy(preds,y_val):\n",
    "#     n_bits_per_block = preds.shape[1]\n",
    "#     n_correct_bits = np.sum(preds == y_val,axis=1)\n",
    "#     block_accuracy = np.mean(n_correct_bits == n_bits_per_block)\n",
    "#     return block_accuracy\n",
    "\n",
    "# preds = AE.predict(x_val,batch_size=block_size)>0.5\n",
    "# accuracy =  calc_block_accuracy(preds,y_val)\n",
    "# print(f\"validation accuracy = {accuracy}\")\n",
    "# print(f\"snr = {snr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "420o_lm0p9b9"
   },
   "source": [
    "<a href=\"#params\">go toparams</a><br/>\n",
    "\n",
    "<a name=\"datasyn\">Generate Data</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:10.170365Z",
     "start_time": "2024-04-16T15:45:09.498042Z"
    },
    "id": "zhVsDdfPpM6V"
   },
   "outputs": [],
   "source": [
    "# synthesize some data\n",
    "x_train = tf.cast(tf.random.uniform((block_size,),minval=0,maxval=2**k),\n",
    "                  (tf.int32))\n",
    "\n",
    "y_train = tf.expand_dims(x_train,axis=1)\n",
    "\n",
    "x_train =  tf.one_hot(x_train,depth=2**k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kPSeSA6tq-4r"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:10.185770Z",
     "start_time": "2024-04-16T15:45:10.175594Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6d5-uKR_o-71",
    "outputId": "a605d800-01cf-42be-f1b8-1e947919655c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape:  (320, 16)\n",
      "y_train.shape:  (320, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \",x_train.shape)\n",
    "print(\"y_train.shape: \",y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:10.200981Z",
     "start_time": "2024-04-16T15:45:10.191657Z"
    }
   },
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def ExternalSlicer(input_vec,padding=30,gamma=4):\n",
    "    '''\n",
    "    input_vec: should be the real and imag parts separately.\n",
    "    padding  : how much the window should expand per each side\n",
    "    '''\n",
    "    assert len(input_vec.shape) == 1, \"Need 1D vector. Cannot process multiple frames at once\"\n",
    "    assert (input_vec.shape[0]-2*padding ) / (2 * NUM_CHANNEL_USES * gamma) == block_size\n",
    "    \n",
    "    output_array = []\n",
    "    \n",
    "    for i in range(block_size):\n",
    "        window_size = (2 * NUM_CHANNEL_USES * gamma)\n",
    "        start = window_size * i\n",
    "        end = start + window_size + padding * 2\n",
    "        output_array.append(input_vec[start:end])\n",
    "    \n",
    "    return tf.stack(output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:15:49.082422Z",
     "start_time": "2024-04-16T16:15:49.062355Z"
    }
   },
   "outputs": [],
   "source": [
    "class End2EndSys(Model):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(End2EndSys,self).__init__()\n",
    "        \n",
    "        self.encoder = Sequential([\n",
    "                    Dense(2**k, activation=act_func,input_shape=(None,2**k,),name=\"e2es->encoder->cf1\"),#Dense(2**k, activation=act_func,input_shape=(k,)),\n",
    "                    Dense(2**k, activation=act_func,name=\"e2es->encoder->cf2\"),\n",
    "                    Dense(2*NUM_CHANNEL_USES, activation='linear',name=\"Encode_last_dense\"),\n",
    "                    L2Normalization(name=\"normalization_layer\"),\n",
    "                    ])\n",
    "\n",
    "        # Channel\n",
    "        self.stochastic_channel = StochasticChannelModel(NUM_CHANNEL_USES,\n",
    "                                                         block_size,\n",
    "                                                         r,\n",
    "                                                         roll_off,\n",
    "                                                         L,\n",
    "                                                         time_delay,\n",
    "                                                         CFO_std,\n",
    "                                                         snr)\n",
    "\n",
    "        # Sequence decoder\n",
    "        self.seq_decoder = SequenceDecoder(take_prev_phase_state=True)\n",
    "    \n",
    "    \n",
    "    def call(self,x):\n",
    "        \n",
    "        encodings = self.encoder(x)\n",
    "        all_y = self.stochastic_channel(encodings)\n",
    "        \n",
    "        slices = ExternalSlicer(all_y,)\n",
    "        st_hat_array = []\n",
    "        \n",
    "        temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "        temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "\n",
    "        # take one slice only --- for testing\n",
    "        for i in range(slices.shape[0]):\n",
    "            test_slice = tf.expand_dims(slices[i,:],axis=0)\n",
    "\n",
    "            \n",
    "            output = self.seq_decoder(test_slice,\n",
    "                                      temp_prev_state_FE,\n",
    "                                      temp_prev_state_PE)\n",
    "            # update states as well\n",
    "            st_hat,temp_prev_state_FE,temp_prev_state_PE = output[0], output[1], output[2]\n",
    "        \n",
    "            st_hat_array.append(st_hat[0])\n",
    "        \n",
    "        return tf.stack(st_hat_array)\n",
    "        \n",
    "#     @tf.function\n",
    "\n",
    "    def custom_fit(self,x,y,epochs=1):\n",
    "\n",
    "        for _ in range(epochs):\n",
    "            \n",
    "            loss_acc = 0.\n",
    "            \n",
    "            temp_prev_state_PE = tf.constant(tf.zeros((1,8)))\n",
    "            temp_prev_state_FE = tf.constant(tf.zeros((1,8)))\n",
    "            \n",
    "            J = tf.Variable(0.,dtype=tf.float32)\n",
    "            \n",
    "            with tf.GradientTape(persistent=False) as tape:\n",
    "                \n",
    "                encodings = self.encoder(x,\n",
    "                                         training=True)\n",
    "                print(\"r3 1\")\n",
    "\n",
    "                all_y = self.stochastic_channel(encodings)\n",
    "                print(\"r3 2\")\n",
    "                \n",
    "                \n",
    "                slices = ExternalSlicer(all_y,)\n",
    "                print(\"r3 3\")\n",
    "    #             st_hat_array = []\n",
    "\n",
    "    \n",
    "                for i in range(slices.shape[0]):\n",
    "                    print(\"iteration\" , i)\n",
    "                    test_slice = tf.expand_dims(slices[i,:],axis=0)\n",
    "                    corr_label = tf.expand_dims(y[i,:],axis=0)\n",
    "\n",
    "\n",
    "                    output = self.seq_decoder(test_slice,\n",
    "                                              temp_prev_state_FE,\n",
    "                                              temp_prev_state_PE)\n",
    "                    \n",
    "                    # update states as well\n",
    "                    st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                    loss = self.compiled_loss(corr_label,st_hat)\n",
    "                    J.assign_add(loss)\n",
    "\n",
    "    #                 st_hat_array.append(st_hat[0])\n",
    "#                     with tape.stop_recording():\n",
    "#                         grads = tape.gradient(loss,self.trainable_variables)\n",
    "#                         self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "                    temp_prev_state_FE = state_FE\n",
    "                    temp_prev_state_PE = state_PE\n",
    "                    \n",
    "#                     print(type(loss.numpy()))\n",
    "                    loss_acc += loss.numpy() / slices.shape[0]\n",
    "    \n",
    "            # backpropagate\n",
    "            grads = tape.gradient(J,self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "                \n",
    "            print(f'Epoch  : {_}/{epochs} --> Loss = {loss_acc}')\n",
    "\n",
    "    \n",
    "        \n",
    "        return \"done\", loss_acc\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T16:15:54.289473Z",
     "start_time": "2024-04-16T16:15:50.230148Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalize output shape =  (None, None, 14)\n",
      "Time_delay = 0.6403280091427501\n",
      "normalize output shape =  (320, 14)\n",
      "r3 1\n",
      "CFO_off = -0.007438365780791521\n",
      "r3 2\n",
      "r3 3\n",
      "iteration 0\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "iteration 100\n",
      "iteration 101\n",
      "iteration 102\n",
      "iteration 103\n",
      "iteration 104\n",
      "iteration 105\n",
      "iteration 106\n",
      "iteration 107\n",
      "iteration 108\n",
      "iteration 109\n",
      "iteration 110\n",
      "iteration 111\n",
      "iteration 112\n",
      "iteration 113\n",
      "iteration 114\n",
      "iteration 115\n",
      "iteration 116\n",
      "iteration 117\n",
      "iteration 118\n",
      "iteration 119\n",
      "iteration 120\n",
      "iteration 121\n",
      "iteration 122\n",
      "iteration 123\n",
      "iteration 124\n",
      "iteration 125\n",
      "iteration 126\n",
      "iteration 127\n",
      "iteration 128\n",
      "iteration 129\n",
      "iteration 130\n",
      "iteration 131\n",
      "iteration 132\n",
      "iteration 133\n",
      "iteration 134\n",
      "iteration 135\n",
      "iteration 136\n",
      "iteration 137\n",
      "iteration 138\n",
      "iteration 139\n",
      "iteration 140\n",
      "iteration 141\n",
      "iteration 142\n",
      "iteration 143\n",
      "iteration 144\n",
      "iteration 145\n",
      "iteration 146\n",
      "iteration 147\n",
      "iteration 148\n",
      "iteration 149\n",
      "iteration 150\n",
      "iteration 151\n",
      "iteration 152\n",
      "iteration 153\n",
      "iteration 154\n",
      "iteration 155\n",
      "iteration 156\n",
      "iteration 157\n",
      "iteration 158\n",
      "iteration 159\n",
      "iteration 160\n",
      "iteration 161\n",
      "iteration 162\n",
      "iteration 163\n",
      "iteration 164\n",
      "iteration 165\n",
      "iteration 166\n",
      "iteration 167\n",
      "iteration 168\n",
      "iteration 169\n",
      "iteration 170\n",
      "iteration 171\n",
      "iteration 172\n",
      "iteration 173\n",
      "iteration 174\n",
      "iteration 175\n",
      "iteration 176\n",
      "iteration 177\n",
      "iteration 178\n",
      "iteration 179\n",
      "iteration 180\n",
      "iteration 181\n",
      "iteration 182\n",
      "iteration 183\n",
      "iteration 184\n",
      "iteration 185\n",
      "iteration 186\n",
      "iteration 187\n",
      "iteration 188\n",
      "iteration 189\n",
      "iteration 190\n",
      "iteration 191\n",
      "iteration 192\n",
      "iteration 193\n",
      "iteration 194\n",
      "iteration 195\n",
      "iteration 196\n",
      "iteration 197\n",
      "iteration 198\n",
      "iteration 199\n",
      "iteration 200\n",
      "iteration 201\n",
      "iteration 202\n",
      "iteration 203\n",
      "iteration 204\n",
      "iteration 205\n",
      "iteration 206\n",
      "iteration 207\n",
      "iteration 208\n",
      "iteration 209\n",
      "iteration 210\n",
      "iteration 211\n",
      "iteration 212\n",
      "iteration 213\n",
      "iteration 214\n",
      "iteration 215\n",
      "iteration 216\n",
      "iteration 217\n",
      "iteration 218\n",
      "iteration 219\n",
      "iteration 220\n",
      "iteration 221\n",
      "iteration 222\n",
      "iteration 223\n",
      "iteration 224\n",
      "iteration 225\n",
      "iteration 226\n",
      "iteration 227\n",
      "iteration 228\n",
      "iteration 229\n",
      "iteration 230\n",
      "iteration 231\n",
      "iteration 232\n",
      "iteration 233\n",
      "iteration 234\n",
      "iteration 235\n",
      "iteration 236\n",
      "iteration 237\n",
      "iteration 238\n",
      "iteration 239\n",
      "iteration 240\n",
      "iteration 241\n",
      "iteration 242\n",
      "iteration 243\n",
      "iteration 244\n",
      "iteration 245\n",
      "iteration 246\n",
      "iteration 247\n",
      "iteration 248\n",
      "iteration 249\n",
      "iteration 250\n",
      "iteration 251\n",
      "iteration 252\n",
      "iteration 253\n",
      "iteration 254\n",
      "iteration 255\n",
      "iteration 256\n",
      "iteration 257\n",
      "iteration 258\n",
      "iteration 259\n",
      "iteration 260\n",
      "iteration 261\n",
      "iteration 262\n",
      "iteration 263\n",
      "iteration 264\n",
      "iteration 265\n",
      "iteration 266\n",
      "iteration 267\n",
      "iteration 268\n",
      "iteration 269\n",
      "iteration 270\n",
      "iteration 271\n",
      "iteration 272\n",
      "iteration 273\n",
      "iteration 274\n",
      "iteration 275\n",
      "iteration 276\n",
      "iteration 277\n",
      "iteration 278\n",
      "iteration 279\n",
      "iteration 280\n",
      "iteration 281\n",
      "iteration 282\n",
      "iteration 283\n",
      "iteration 284\n",
      "iteration 285\n",
      "iteration 286\n",
      "iteration 287\n",
      "iteration 288\n",
      "iteration 289\n",
      "iteration 290\n",
      "iteration 291\n",
      "iteration 292\n",
      "iteration 293\n",
      "iteration 294\n",
      "iteration 295\n",
      "iteration 296\n",
      "iteration 297\n",
      "iteration 298\n",
      "iteration 299\n",
      "iteration 300\n",
      "iteration 301\n",
      "iteration 302\n",
      "iteration 303\n",
      "iteration 304\n",
      "iteration 305\n",
      "iteration 306\n",
      "iteration 307\n",
      "iteration 308\n",
      "iteration 309\n",
      "iteration 310\n",
      "iteration 311\n",
      "iteration 312\n",
      "iteration 313\n",
      "iteration 314\n",
      "iteration 315\n",
      "iteration 316\n",
      "iteration 317\n",
      "iteration 318\n",
      "iteration 319\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable: (['e2es->encoder->cf1/kernel:0', 'e2es->encoder->cf1/bias:0', 'e2es->encoder->cf2/kernel:0', 'e2es->encoder->cf2/bias:0', 'Encode_last_dense/kernel:0', 'Encode_last_dense/bias:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/kernel:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/bias:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/kernel:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/bias:0', 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/kernel:0', 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/bias:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/kernel:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/bias:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/kernel:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/bias:0', 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/kernel:0', 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/bias:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/kernel:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/bias:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/kernel:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/bias:0', 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/kernel:0', 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'e2es->encoder->cf1/kernel:0' shape=(16, 16) dtype=float32, numpy=\narray([[-0.2955562 ,  0.36528322, -0.4286609 ,  0.36248556,  0.23076239,\n        -0.2630827 ,  0.3893524 , -0.33243126, -0.03276142, -0.20028277,\n         0.12415716, -0.2145506 ,  0.362649  , -0.32062152,  0.406602  ,\n        -0.37260944],\n       [ 0.1095005 ,  0.3406417 ,  0.3943412 , -0.35508317, -0.21189553,\n        -0.31782904,  0.3457469 ,  0.35477117, -0.3767752 , -0.39773586,\n         0.3609182 , -0.05417791,  0.40670046, -0.20824935,  0.00934565,\n        -0.1179997 ],\n       [-0.38006386, -0.00722626,  0.12655929,  0.36440548, -0.3084647 ,\n        -0.23733105, -0.42987344,  0.13792107,  0.12086734,  0.20083418,\n        -0.30365288, -0.10348645, -0.11035687,  0.12959573,  0.27205834,\n        -0.3142802 ],\n       [-0.33387712, -0.28900397,  0.37136367, -0.26068044,  0.04209158,\n         0.06391978,  0.23684242,  0.4283065 , -0.1259791 , -0.37075093,\n         0.34221503,  0.2695326 , -0.13170436,  0.04295734, -0.3932805 ,\n        -0.24734424],\n       [ 0.11507472,  0.3712609 ,  0.1601074 , -0.27682257,  0.00160423,\n         0.24714974, -0.40721655,  0.3260713 ,  0.37293723, -0.36703673,\n         0.2786031 ,  0.13756314,  0.28171495, -0.06608415,  0.05959222,\n         0.29092357],\n       [-0.06226084, -0.36697954,  0.09584484,  0.2029458 , -0.18438716,\n         0.2622532 , -0.24837486,  0.00462919, -0.2515452 , -0.0837889 ,\n        -0.15430725,  0.43142107, -0.26872405, -0.1783784 , -0.16039675,\n         0.1594201 ],\n       [-0.03392884,  0.28678116,  0.4139444 , -0.01837704, -0.26955935,\n         0.29987898, -0.37443715,  0.04816797, -0.260392  , -0.39988995,\n         0.3085669 , -0.31861952, -0.03690013,  0.06533867,  0.15341392,\n         0.3886504 ],\n       [-0.04818657, -0.31337842,  0.42974344, -0.32502195, -0.08716118,\n        -0.22524527, -0.06682593, -0.02228263, -0.10453886, -0.1877934 ,\n        -0.01910165, -0.36863136, -0.25535637,  0.13114545,  0.28469244,\n        -0.2469953 ],\n       [ 0.22736558, -0.13507634,  0.08436933, -0.03139663, -0.08946124,\n         0.00875026,  0.10692367, -0.08535987,  0.3842924 ,  0.43267295,\n         0.24151698,  0.25966266,  0.2676967 ,  0.23656604,  0.18603846,\n        -0.2542102 ],\n       [-0.25847065, -0.2904647 ,  0.42432806, -0.25727946, -0.12567163,\n        -0.1961874 , -0.32593924,  0.15165147, -0.2955307 , -0.42448634,\n        -0.3362269 , -0.11745417, -0.28406176,  0.40934613, -0.15140647,\n        -0.23617819],\n       [ 0.24332598, -0.112867  , -0.06033081,  0.08178094, -0.03509328,\n         0.04739162, -0.31444725,  0.41184273,  0.17733857, -0.3152803 ,\n        -0.18263036, -0.33627874, -0.24901092, -0.40793467, -0.06985834,\n         0.22138736],\n       [ 0.37941203, -0.2480925 , -0.06890082, -0.23103859,  0.31168893,\n         0.2907968 , -0.00781277,  0.09895173,  0.26454118, -0.00231388,\n         0.16436568,  0.22155097, -0.22392432,  0.354848  , -0.131951  ,\n        -0.3377277 ],\n       [ 0.3067874 , -0.06925502, -0.08177689,  0.2669401 ,  0.2868881 ,\n        -0.21846953,  0.06285384,  0.15975335, -0.20510833,  0.32872286,\n         0.18894991,  0.01189998,  0.11435571, -0.06425983, -0.0925563 ,\n        -0.06956175],\n       [-0.17233834,  0.31139997,  0.3609248 ,  0.23291454,  0.00403279,\n         0.39159146,  0.02606177,  0.11995056, -0.39646974,  0.383334  ,\n         0.15817794,  0.18689546, -0.36749986, -0.24330504, -0.10321093,\n         0.3290172 ],\n       [ 0.36434373,  0.16598806, -0.17351577, -0.27941623, -0.09891361,\n        -0.37057936,  0.11309919,  0.08521524,  0.35043982, -0.3609215 ,\n        -0.34142753, -0.0538207 ,  0.39966717,  0.02862385,  0.31173995,\n         0.12493888],\n       [-0.2849561 , -0.29971063,  0.4068621 ,  0.20480058, -0.37627584,\n        -0.426857  , -0.09292117,  0.4210129 ,  0.26586333,  0.23356   ,\n        -0.36498806,  0.2586926 ,  0.35753337, -0.01672131,  0.15578988,\n         0.23942009]], dtype=float32)>), (None, <tf.Variable 'e2es->encoder->cf1/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'e2es->encoder->cf2/kernel:0' shape=(16, 16) dtype=float32, numpy=\narray([[-0.16309416,  0.0044283 , -0.09066591,  0.29463974,  0.33108017,\n        -0.05624896,  0.28010455,  0.30195484, -0.3528672 ,  0.2519171 ,\n         0.00596055, -0.304355  ,  0.1494526 ,  0.31020507, -0.0341312 ,\n         0.3052673 ],\n       [ 0.08912519, -0.14351565,  0.01993263,  0.2652097 ,  0.12600127,\n         0.14869896,  0.2781274 , -0.18349281, -0.4008582 ,  0.10581729,\n         0.16566977,  0.3631929 ,  0.35065553, -0.22888327, -0.20854574,\n        -0.06576857],\n       [ 0.07765064, -0.36793244, -0.11430138, -0.07887527,  0.1957247 ,\n        -0.3761033 , -0.19113255,  0.41836205, -0.06852162, -0.16057423,\n         0.3369693 ,  0.12166962,  0.02815092, -0.16637704, -0.15785173,\n        -0.4117617 ],\n       [-0.3382916 , -0.30520546, -0.32074428, -0.4122934 , -0.2877993 ,\n         0.41251948, -0.0878149 ,  0.41132924,  0.15975007, -0.42826137,\n        -0.21784277, -0.02947134, -0.34325826,  0.06048864,  0.3176519 ,\n        -0.3109225 ],\n       [-0.24855357, -0.32023644,  0.42373237, -0.30565342, -0.10062212,\n         0.27340284, -0.1814867 , -0.41925278, -0.3765079 , -0.03077224,\n        -0.06668428, -0.1800594 , -0.23780069,  0.13503286,  0.00544304,\n        -0.3556124 ],\n       [ 0.3086566 , -0.41823062,  0.06271198,  0.08826378, -0.00870463,\n        -0.40611592,  0.19367746,  0.05594233,  0.04304934, -0.39500913,\n        -0.41644853,  0.02744228, -0.13409156, -0.04884925, -0.1679186 ,\n         0.32187268],\n       [ 0.21178773,  0.25782403,  0.24311176, -0.37717235, -0.20264775,\n        -0.333121  ,  0.12183806,  0.0987061 ,  0.30545852, -0.19812736,\n         0.10974219, -0.31320983,  0.21382341,  0.03810689,  0.32171586,\n        -0.25257698],\n       [ 0.41487238,  0.0290876 , -0.31421292,  0.34317413,  0.19190702,\n         0.13302943, -0.07925281, -0.33903974, -0.42752156,  0.20549735,\n         0.30635843, -0.27334952, -0.25626537, -0.03063917,  0.13249466,\n         0.40865353],\n       [ 0.27639   ,  0.26601294,  0.2585049 ,  0.23115978, -0.01822621,\n         0.06035587, -0.30310428,  0.40323249, -0.17567983, -0.3069946 ,\n         0.2717602 , -0.34978727, -0.04446968,  0.3269498 ,  0.02956033,\n        -0.40849876],\n       [-0.10111693, -0.11845094,  0.37588742,  0.21863624,  0.01293969,\n        -0.38901997,  0.24298456, -0.41483575,  0.19661191, -0.4155165 ,\n         0.12754974, -0.07977501,  0.3447323 , -0.31275457, -0.09260121,\n        -0.43111446],\n       [-0.28552124, -0.17780542, -0.21153884, -0.42411107, -0.377684  ,\n         0.19561413, -0.12557036,  0.37553623,  0.12791678,  0.33656862,\n        -0.02343747, -0.10268193,  0.08376899,  0.00640789,  0.12272313,\n         0.4069346 ],\n       [-0.11531478, -0.23537695,  0.13272932,  0.26610354, -0.18841459,\n        -0.26271582,  0.25889286, -0.3056915 , -0.07499218, -0.23475495,\n         0.17331126, -0.0320498 , -0.3385795 ,  0.07399812,  0.30862275,\n        -0.260146  ],\n       [ 0.33519658,  0.0425415 ,  0.1636363 ,  0.30509356, -0.10838595,\n        -0.33960146, -0.3907071 , -0.15211219,  0.3272101 , -0.35875928,\n        -0.0485096 ,  0.1588718 , -0.20802306,  0.12444493,  0.24838498,\n        -0.37898213],\n       [ 0.25370225, -0.36267728, -0.34743094, -0.26424012,  0.17421171,\n        -0.18358056, -0.32269022, -0.19160208,  0.42487463, -0.01920903,\n        -0.07522994, -0.1002804 ,  0.4106166 , -0.01679665, -0.08290106,\n         0.13449565],\n       [ 0.2329078 , -0.38639256,  0.0070712 , -0.34867156,  0.03386101,\n        -0.05213451,  0.4123744 , -0.14130655, -0.3595756 , -0.34757373,\n        -0.07232296,  0.36163232,  0.01972327, -0.3753182 ,  0.10984811,\n         0.24358419],\n       [ 0.21201572,  0.38377395, -0.08729777, -0.42255104, -0.36882615,\n         0.13322672, -0.04049262, -0.4180639 , -0.2433231 , -0.1355758 ,\n        -0.24443199, -0.32286665, -0.362767  ,  0.04893816, -0.11083424,\n         0.28864458]], dtype=float32)>), (None, <tf.Variable 'e2es->encoder->cf2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'Encode_last_dense/kernel:0' shape=(16, 14) dtype=float32, numpy=\narray([[-0.32883555, -0.32864225, -0.41569158, -0.35500664, -0.31679952,\n         0.4198798 ,  0.04061374, -0.26616013, -0.29625934,  0.34477842,\n        -0.4024731 , -0.38037077, -0.00292054, -0.29441762],\n       [ 0.39279598, -0.02891496,  0.15785271, -0.37133172, -0.00671038,\n        -0.18884405,  0.40365225, -0.3244986 ,  0.05379075,  0.42827666,\n        -0.42179176, -0.29730672, -0.05203733,  0.34841782],\n       [-0.23112294,  0.28361982,  0.1464122 ,  0.37483263,  0.19062382,\n        -0.3653256 ,  0.42171764,  0.42489386, -0.23011811, -0.36715686,\n         0.34449315, -0.23437977,  0.2617798 , -0.35374856],\n       [ 0.406493  ,  0.0946672 , -0.11238417,  0.12246579,  0.26014555,\n        -0.36625087, -0.43083444,  0.01918432, -0.01569387, -0.12979674,\n         0.40529054, -0.11193773, -0.06190857,  0.12843794],\n       [ 0.43511134,  0.05227658,  0.22538292, -0.33610708, -0.24073264,\n        -0.11631134,  0.19609821, -0.1463159 , -0.23701647, -0.27477014,\n        -0.00803208, -0.30782825, -0.06204507, -0.4332657 ],\n       [-0.15951926, -0.42244697, -0.36327147,  0.13173705,  0.4381562 ,\n        -0.1832223 , -0.07673946,  0.36293584,  0.03496256, -0.05875954,\n        -0.4082053 ,  0.4394955 , -0.27438956,  0.30430222],\n       [-0.19099742, -0.262466  ,  0.42200714, -0.01743665, -0.14440179,\n        -0.43374088, -0.41629657, -0.44326136, -0.06069392, -0.02381948,\n        -0.37830546, -0.17085308, -0.39194438, -0.3735995 ],\n       [-0.21835524,  0.32811147,  0.31110203, -0.44691578, -0.1312688 ,\n        -0.28479952, -0.03312552,  0.12220156,  0.4244148 ,  0.04352498,\n        -0.43723762,  0.19512689,  0.36836195,  0.19598359],\n       [ 0.4349904 ,  0.24350911,  0.12747288,  0.24327177,  0.24842739,\n         0.02442011,  0.4017105 ,  0.26086932,  0.17216551, -0.41140008,\n        -0.00046167, -0.1456126 , -0.03210396, -0.44616824],\n       [-0.11577162, -0.41452843,  0.06066757,  0.02752072, -0.00108683,\n        -0.10233253,  0.330913  ,  0.04952547,  0.02544251,  0.41391402,\n         0.3676225 , -0.2692659 ,  0.4290594 ,  0.19718033],\n       [-0.09558249, -0.09936124, -0.0606854 , -0.04604527,  0.18186319,\n         0.10798508, -0.10757905, -0.37000978, -0.12444761, -0.00389412,\n        -0.39288694, -0.12093318,  0.41579086,  0.03439862],\n       [ 0.346964  , -0.32786238, -0.12498787,  0.04235926,  0.42971432,\n         0.25695848, -0.1967724 , -0.10078508,  0.33943313, -0.27776307,\n         0.38370168, -0.33239508,  0.02901506, -0.03902492],\n       [ 0.23699182,  0.22165698,  0.44713557,  0.20436555,  0.42451715,\n         0.2875139 ,  0.24736059, -0.40996116,  0.2479403 ,  0.25635892,\n         0.03409293, -0.00508052, -0.09044427,  0.25067407],\n       [ 0.09033829,  0.44248718,  0.0131073 , -0.2827635 ,  0.09693849,\n         0.19768524,  0.3352431 , -0.01135877, -0.12357479, -0.14077368,\n         0.13370335,  0.15253443,  0.42119414, -0.14300692],\n       [ 0.17789769,  0.2852214 ,  0.06507391,  0.09993708,  0.31887257,\n         0.3990301 , -0.21353275,  0.20507991,  0.02838919, -0.14955512,\n         0.11901867,  0.34645092, -0.42220065, -0.26866025],\n       [-0.38176563, -0.09448126, -0.09368616,  0.24353439,  0.00407273,\n         0.1364153 ,  0.29859537, -0.3753091 , -0.27461115,  0.08365381,\n        -0.39045313,  0.09525162,  0.252635  , -0.25779623]],\n      dtype=float32)>), (None, <tf.Variable 'Encode_last_dense/bias:0' shape=(14,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/kernel:0' shape=(124, 256) dtype=float32, numpy=\narray([[-0.09602914,  0.0206054 ,  0.05003852, ...,  0.11691457,\n         0.01888394,  0.00686687],\n       [-0.08121756, -0.06287105,  0.07644905, ..., -0.11417445,\n        -0.12489573,  0.07514276],\n       [-0.08978828,  0.08156046,  0.02344207, ...,  0.09093824,\n        -0.04955614, -0.08691775],\n       ...,\n       [-0.09871513,  0.07279322, -0.01567698, ..., -0.11646644,\n        -0.09626462,  0.08802012],\n       [-0.00237435,  0.10235688,  0.10367432, ...,  0.00675358,\n        -0.00800576,  0.09696451],\n       [-0.03635739,  0.06430128,  0.00420938, ..., -0.08154231,\n         0.08758235, -0.03847566]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/kernel:0' shape=(8, 8) dtype=float32, numpy=\narray([[-0.4385894 ,  0.15461665,  0.39588577,  0.0386939 ,  0.04479468,\n        -0.09826344,  0.19699633, -0.18545204],\n       [ 0.33092505, -0.01353562, -0.26279956,  0.13427329, -0.51454467,\n         0.05445749,  0.07413012, -0.5146835 ],\n       [-0.13523355,  0.21030974, -0.36462384,  0.20058054, -0.2360405 ,\n         0.03501451, -0.05378443, -0.5208618 ],\n       [ 0.18130314,  0.46856862,  0.5268943 , -0.3035458 , -0.3832292 ,\n        -0.2246714 , -0.0474112 , -0.5826779 ],\n       [ 0.43082553,  0.08697075,  0.24999642,  0.2991652 ,  0.08303326,\n        -0.57571775, -0.133809  , -0.6098237 ],\n       [ 0.38420373,  0.14263403, -0.55154204, -0.4199861 ,  0.1673364 ,\n        -0.466442  , -0.24007946,  0.5817091 ],\n       [ 0.44497603,  0.25478995, -0.22779977, -0.28558928, -0.26542583,\n         0.5840122 , -0.37215865, -0.12076676],\n       [ 0.13379937, -0.25267613,  0.19722909,  0.07469177,  0.49674124,\n         0.48525888, -0.0412733 ,  0.1425342 ]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/kernel:0' shape=(256, 8) dtype=float32, numpy=\narray([[ 0.01262662,  0.05650933, -0.07557854, ...,  0.08060171,\n         0.07018189,  0.12418863],\n       [-0.1403246 ,  0.04757459, -0.1080391 , ...,  0.1399554 ,\n         0.10882303, -0.05271796],\n       [ 0.10391629, -0.08590183, -0.09136627, ...,  0.11373794,\n         0.01352437,  0.113599  ],\n       ...,\n       [-0.11158414,  0.00363182,  0.13975453, ..., -0.02873233,\n        -0.0296543 , -0.01717056],\n       [-0.06577233, -0.09036508,  0.05360132, ..., -0.03513823,\n        -0.11046873, -0.00425044],\n       [-0.02095079, -0.00513585, -0.1340391 , ..., -0.06767814,\n         0.06926836, -0.02829189]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/kernel:0' shape=(124, 256) dtype=float32, numpy=\narray([[ 0.1255088 ,  0.09892711, -0.02228037, ...,  0.11655751,\n         0.03712787,  0.06265666],\n       [-0.06920841,  0.02177346,  0.04313475, ..., -0.06275918,\n        -0.00020368, -0.05691434],\n       [-0.02655125, -0.10888477, -0.055384  , ..., -0.05163211,\n         0.02229193, -0.02852656],\n       ...,\n       [-0.03305863,  0.07967381,  0.01856446, ..., -0.04513834,\n        -0.01759784, -0.00189046],\n       [ 0.12000702,  0.00762276, -0.03809982, ...,  0.12044634,\n         0.10092402, -0.00195008],\n       [ 0.08548132,  0.05697441, -0.09805112, ..., -0.00486378,\n        -0.01647208,  0.08491004]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/kernel:0' shape=(8, 2) dtype=float32, numpy=\narray([[ 0.17138177,  0.6050559 ],\n       [-0.33472118,  0.6827978 ],\n       [ 0.42242908, -0.4936069 ],\n       [ 0.1765827 , -0.5710938 ],\n       [-0.04441142, -0.3474577 ],\n       [ 0.4004295 ,  0.08964872],\n       [-0.52785236, -0.09692615],\n       [-0.6678139 , -0.23122269]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/kernel:0' shape=(256, 8) dtype=float32, numpy=\narray([[-0.00045694,  0.08325186,  0.10804152, ...,  0.02599585,\n        -0.09746647,  0.00924665],\n       [-0.11468854, -0.11348359, -0.11939922, ...,  0.03350638,\n         0.1309045 , -0.09932109],\n       [ 0.04327439, -0.0718836 , -0.00549513, ...,  0.10426226,\n        -0.14678057, -0.0988575 ],\n       ...,\n       [ 0.05972914, -0.03520325,  0.1081925 , ..., -0.02397589,\n         0.11819682, -0.08707597],\n       [ 0.05072881, -0.01016484,  0.0572127 , ...,  0.04210541,\n        -0.01278523,  0.07204755],\n       [-0.09778302,  0.06835544, -0.05484582, ..., -0.07837775,\n        -0.00352407,  0.05214331]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/kernel:0' shape=(22, 256) dtype=float32, numpy=\narray([[-0.02881597, -0.02066214, -0.04428317, ...,  0.13636148,\n        -0.01898035,  0.10682216],\n       [-0.1296188 ,  0.0684949 , -0.08894788, ..., -0.08172371,\n         0.00701697, -0.13412581],\n       [-0.01989503,  0.11153594,  0.02727145, ..., -0.0019471 ,\n         0.10452238, -0.13863912],\n       ...,\n       [ 0.10514611, -0.04605528,  0.07571094, ...,  0.08980994,\n         0.1093601 , -0.00806329],\n       [-0.06132045, -0.09953479, -0.05740868, ..., -0.11216252,\n        -0.0304207 , -0.02276358],\n       [-0.03319267,  0.06296608, -0.11596037, ...,  0.06346412,\n         0.06949914, -0.07063578]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/kernel:0' shape=(256, 256) dtype=float32, numpy=\narray([[ 0.00353738,  0.08921119, -0.10816082, ...,  0.0285866 ,\n        -0.02523169, -0.02119195],\n       [ 0.0413932 ,  0.05399486, -0.08463463, ...,  0.00501237,\n        -0.00779955, -0.07802269],\n       [-0.07490572, -0.07233222, -0.08687227, ..., -0.06065837,\n         0.08898611, -0.04535636],\n       ...,\n       [ 0.08897906, -0.02361725, -0.04401185, ..., -0.07488058,\n         0.00930489,  0.08641528],\n       [-0.00453417,  0.01662072,  0.07192967, ..., -0.07897222,\n        -0.07941305,  0.08892032],\n       [ 0.10529102,  0.08998635,  0.04625849, ..., -0.06259479,\n        -0.09103437, -0.01632912]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/kernel:0' shape=(256, 16) dtype=float32, numpy=\narray([[ 0.03853336,  0.04469034,  0.10974187, ...,  0.0544221 ,\n         0.13371643,  0.002748  ],\n       [-0.00804029,  0.08272548, -0.06219885, ...,  0.03281567,\n        -0.03633802, -0.02241693],\n       [-0.11594397, -0.01124713, -0.14381337, ...,  0.04935078,\n        -0.08052032, -0.04279769],\n       ...,\n       [-0.08878183, -0.06218285,  0.02266562, ..., -0.10762064,\n        -0.06609511, -0.09306784],\n       [-0.1081979 ,  0.13315436,  0.05201417, ...,  0.02699493,\n         0.02303644, -0.14669624],\n       [ 0.08752851,  0.04627149,  0.04585549, ..., -0.13453324,\n         0.07126364,  0.05330408]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>)).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/2370095014.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mend2end\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcustom_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/2898332873.py\u001b[0m in \u001b[0;36mcustom_fit\u001b[1;34m(self, x, y, epochs)\u001b[0m\n\u001b[0;32m    107\u001b[0m             \u001b[1;31m# backpropagate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mJ\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Epoch  : {_}/{epochs} --> Loss = {loss_acc}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[0;32m    638\u001b[0m       \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mcalled\u001b[0m \u001b[1;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcross\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mreplica\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    639\u001b[0m     \"\"\"\n\u001b[1;32m--> 640\u001b[1;33m     \u001b[0mgrads_and_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter_empty_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    641\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\utils.py\u001b[0m in \u001b[0;36mfilter_empty_gradients\u001b[1;34m(grads_and_vars)\u001b[0m\n\u001b[0;32m     71\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfiltered\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvariable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     raise ValueError(f\"No gradients provided for any variable: {variable}. \"\n\u001b[0m\u001b[0;32m     74\u001b[0m                      f\"Provided `grads_and_vars` is {grads_and_vars}.\")\n\u001b[0;32m     75\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mvars_with_empty_grads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No gradients provided for any variable: (['e2es->encoder->cf1/kernel:0', 'e2es->encoder->cf1/bias:0', 'e2es->encoder->cf2/kernel:0', 'e2es->encoder->cf2/bias:0', 'Encode_last_dense/kernel:0', 'Encode_last_dense/bias:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/kernel:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/bias:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/kernel:0', 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/bias:0', 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/kernel:0', 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/bias:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/kernel:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/bias:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/kernel:0', 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/bias:0', 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/kernel:0', 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/bias:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/kernel:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/bias:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/kernel:0', 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/bias:0', 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/kernel:0', 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/bias:0'],). Provided `grads_and_vars` is ((None, <tf.Variable 'e2es->encoder->cf1/kernel:0' shape=(16, 16) dtype=float32, numpy=\narray([[-0.2955562 ,  0.36528322, -0.4286609 ,  0.36248556,  0.23076239,\n        -0.2630827 ,  0.3893524 , -0.33243126, -0.03276142, -0.20028277,\n         0.12415716, -0.2145506 ,  0.362649  , -0.32062152,  0.406602  ,\n        -0.37260944],\n       [ 0.1095005 ,  0.3406417 ,  0.3943412 , -0.35508317, -0.21189553,\n        -0.31782904,  0.3457469 ,  0.35477117, -0.3767752 , -0.39773586,\n         0.3609182 , -0.05417791,  0.40670046, -0.20824935,  0.00934565,\n        -0.1179997 ],\n       [-0.38006386, -0.00722626,  0.12655929,  0.36440548, -0.3084647 ,\n        -0.23733105, -0.42987344,  0.13792107,  0.12086734,  0.20083418,\n        -0.30365288, -0.10348645, -0.11035687,  0.12959573,  0.27205834,\n        -0.3142802 ],\n       [-0.33387712, -0.28900397,  0.37136367, -0.26068044,  0.04209158,\n         0.06391978,  0.23684242,  0.4283065 , -0.1259791 , -0.37075093,\n         0.34221503,  0.2695326 , -0.13170436,  0.04295734, -0.3932805 ,\n        -0.24734424],\n       [ 0.11507472,  0.3712609 ,  0.1601074 , -0.27682257,  0.00160423,\n         0.24714974, -0.40721655,  0.3260713 ,  0.37293723, -0.36703673,\n         0.2786031 ,  0.13756314,  0.28171495, -0.06608415,  0.05959222,\n         0.29092357],\n       [-0.06226084, -0.36697954,  0.09584484,  0.2029458 , -0.18438716,\n         0.2622532 , -0.24837486,  0.00462919, -0.2515452 , -0.0837889 ,\n        -0.15430725,  0.43142107, -0.26872405, -0.1783784 , -0.16039675,\n         0.1594201 ],\n       [-0.03392884,  0.28678116,  0.4139444 , -0.01837704, -0.26955935,\n         0.29987898, -0.37443715,  0.04816797, -0.260392  , -0.39988995,\n         0.3085669 , -0.31861952, -0.03690013,  0.06533867,  0.15341392,\n         0.3886504 ],\n       [-0.04818657, -0.31337842,  0.42974344, -0.32502195, -0.08716118,\n        -0.22524527, -0.06682593, -0.02228263, -0.10453886, -0.1877934 ,\n        -0.01910165, -0.36863136, -0.25535637,  0.13114545,  0.28469244,\n        -0.2469953 ],\n       [ 0.22736558, -0.13507634,  0.08436933, -0.03139663, -0.08946124,\n         0.00875026,  0.10692367, -0.08535987,  0.3842924 ,  0.43267295,\n         0.24151698,  0.25966266,  0.2676967 ,  0.23656604,  0.18603846,\n        -0.2542102 ],\n       [-0.25847065, -0.2904647 ,  0.42432806, -0.25727946, -0.12567163,\n        -0.1961874 , -0.32593924,  0.15165147, -0.2955307 , -0.42448634,\n        -0.3362269 , -0.11745417, -0.28406176,  0.40934613, -0.15140647,\n        -0.23617819],\n       [ 0.24332598, -0.112867  , -0.06033081,  0.08178094, -0.03509328,\n         0.04739162, -0.31444725,  0.41184273,  0.17733857, -0.3152803 ,\n        -0.18263036, -0.33627874, -0.24901092, -0.40793467, -0.06985834,\n         0.22138736],\n       [ 0.37941203, -0.2480925 , -0.06890082, -0.23103859,  0.31168893,\n         0.2907968 , -0.00781277,  0.09895173,  0.26454118, -0.00231388,\n         0.16436568,  0.22155097, -0.22392432,  0.354848  , -0.131951  ,\n        -0.3377277 ],\n       [ 0.3067874 , -0.06925502, -0.08177689,  0.2669401 ,  0.2868881 ,\n        -0.21846953,  0.06285384,  0.15975335, -0.20510833,  0.32872286,\n         0.18894991,  0.01189998,  0.11435571, -0.06425983, -0.0925563 ,\n        -0.06956175],\n       [-0.17233834,  0.31139997,  0.3609248 ,  0.23291454,  0.00403279,\n         0.39159146,  0.02606177,  0.11995056, -0.39646974,  0.383334  ,\n         0.15817794,  0.18689546, -0.36749986, -0.24330504, -0.10321093,\n         0.3290172 ],\n       [ 0.36434373,  0.16598806, -0.17351577, -0.27941623, -0.09891361,\n        -0.37057936,  0.11309919,  0.08521524,  0.35043982, -0.3609215 ,\n        -0.34142753, -0.0538207 ,  0.39966717,  0.02862385,  0.31173995,\n         0.12493888],\n       [-0.2849561 , -0.29971063,  0.4068621 ,  0.20480058, -0.37627584,\n        -0.426857  , -0.09292117,  0.4210129 ,  0.26586333,  0.23356   ,\n        -0.36498806,  0.2586926 ,  0.35753337, -0.01672131,  0.15578988,\n         0.23942009]], dtype=float32)>), (None, <tf.Variable 'e2es->encoder->cf1/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'e2es->encoder->cf2/kernel:0' shape=(16, 16) dtype=float32, numpy=\narray([[-0.16309416,  0.0044283 , -0.09066591,  0.29463974,  0.33108017,\n        -0.05624896,  0.28010455,  0.30195484, -0.3528672 ,  0.2519171 ,\n         0.00596055, -0.304355  ,  0.1494526 ,  0.31020507, -0.0341312 ,\n         0.3052673 ],\n       [ 0.08912519, -0.14351565,  0.01993263,  0.2652097 ,  0.12600127,\n         0.14869896,  0.2781274 , -0.18349281, -0.4008582 ,  0.10581729,\n         0.16566977,  0.3631929 ,  0.35065553, -0.22888327, -0.20854574,\n        -0.06576857],\n       [ 0.07765064, -0.36793244, -0.11430138, -0.07887527,  0.1957247 ,\n        -0.3761033 , -0.19113255,  0.41836205, -0.06852162, -0.16057423,\n         0.3369693 ,  0.12166962,  0.02815092, -0.16637704, -0.15785173,\n        -0.4117617 ],\n       [-0.3382916 , -0.30520546, -0.32074428, -0.4122934 , -0.2877993 ,\n         0.41251948, -0.0878149 ,  0.41132924,  0.15975007, -0.42826137,\n        -0.21784277, -0.02947134, -0.34325826,  0.06048864,  0.3176519 ,\n        -0.3109225 ],\n       [-0.24855357, -0.32023644,  0.42373237, -0.30565342, -0.10062212,\n         0.27340284, -0.1814867 , -0.41925278, -0.3765079 , -0.03077224,\n        -0.06668428, -0.1800594 , -0.23780069,  0.13503286,  0.00544304,\n        -0.3556124 ],\n       [ 0.3086566 , -0.41823062,  0.06271198,  0.08826378, -0.00870463,\n        -0.40611592,  0.19367746,  0.05594233,  0.04304934, -0.39500913,\n        -0.41644853,  0.02744228, -0.13409156, -0.04884925, -0.1679186 ,\n         0.32187268],\n       [ 0.21178773,  0.25782403,  0.24311176, -0.37717235, -0.20264775,\n        -0.333121  ,  0.12183806,  0.0987061 ,  0.30545852, -0.19812736,\n         0.10974219, -0.31320983,  0.21382341,  0.03810689,  0.32171586,\n        -0.25257698],\n       [ 0.41487238,  0.0290876 , -0.31421292,  0.34317413,  0.19190702,\n         0.13302943, -0.07925281, -0.33903974, -0.42752156,  0.20549735,\n         0.30635843, -0.27334952, -0.25626537, -0.03063917,  0.13249466,\n         0.40865353],\n       [ 0.27639   ,  0.26601294,  0.2585049 ,  0.23115978, -0.01822621,\n         0.06035587, -0.30310428,  0.40323249, -0.17567983, -0.3069946 ,\n         0.2717602 , -0.34978727, -0.04446968,  0.3269498 ,  0.02956033,\n        -0.40849876],\n       [-0.10111693, -0.11845094,  0.37588742,  0.21863624,  0.01293969,\n        -0.38901997,  0.24298456, -0.41483575,  0.19661191, -0.4155165 ,\n         0.12754974, -0.07977501,  0.3447323 , -0.31275457, -0.09260121,\n        -0.43111446],\n       [-0.28552124, -0.17780542, -0.21153884, -0.42411107, -0.377684  ,\n         0.19561413, -0.12557036,  0.37553623,  0.12791678,  0.33656862,\n        -0.02343747, -0.10268193,  0.08376899,  0.00640789,  0.12272313,\n         0.4069346 ],\n       [-0.11531478, -0.23537695,  0.13272932,  0.26610354, -0.18841459,\n        -0.26271582,  0.25889286, -0.3056915 , -0.07499218, -0.23475495,\n         0.17331126, -0.0320498 , -0.3385795 ,  0.07399812,  0.30862275,\n        -0.260146  ],\n       [ 0.33519658,  0.0425415 ,  0.1636363 ,  0.30509356, -0.10838595,\n        -0.33960146, -0.3907071 , -0.15211219,  0.3272101 , -0.35875928,\n        -0.0485096 ,  0.1588718 , -0.20802306,  0.12444493,  0.24838498,\n        -0.37898213],\n       [ 0.25370225, -0.36267728, -0.34743094, -0.26424012,  0.17421171,\n        -0.18358056, -0.32269022, -0.19160208,  0.42487463, -0.01920903,\n        -0.07522994, -0.1002804 ,  0.4106166 , -0.01679665, -0.08290106,\n         0.13449565],\n       [ 0.2329078 , -0.38639256,  0.0070712 , -0.34867156,  0.03386101,\n        -0.05213451,  0.4123744 , -0.14130655, -0.3595756 , -0.34757373,\n        -0.07232296,  0.36163232,  0.01972327, -0.3753182 ,  0.10984811,\n         0.24358419],\n       [ 0.21201572,  0.38377395, -0.08729777, -0.42255104, -0.36882615,\n         0.13322672, -0.04049262, -0.4180639 , -0.2433231 , -0.1355758 ,\n        -0.24443199, -0.32286665, -0.362767  ,  0.04893816, -0.11083424,\n         0.28864458]], dtype=float32)>), (None, <tf.Variable 'e2es->encoder->cf2/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'Encode_last_dense/kernel:0' shape=(16, 14) dtype=float32, numpy=\narray([[-0.32883555, -0.32864225, -0.41569158, -0.35500664, -0.31679952,\n         0.4198798 ,  0.04061374, -0.26616013, -0.29625934,  0.34477842,\n        -0.4024731 , -0.38037077, -0.00292054, -0.29441762],\n       [ 0.39279598, -0.02891496,  0.15785271, -0.37133172, -0.00671038,\n        -0.18884405,  0.40365225, -0.3244986 ,  0.05379075,  0.42827666,\n        -0.42179176, -0.29730672, -0.05203733,  0.34841782],\n       [-0.23112294,  0.28361982,  0.1464122 ,  0.37483263,  0.19062382,\n        -0.3653256 ,  0.42171764,  0.42489386, -0.23011811, -0.36715686,\n         0.34449315, -0.23437977,  0.2617798 , -0.35374856],\n       [ 0.406493  ,  0.0946672 , -0.11238417,  0.12246579,  0.26014555,\n        -0.36625087, -0.43083444,  0.01918432, -0.01569387, -0.12979674,\n         0.40529054, -0.11193773, -0.06190857,  0.12843794],\n       [ 0.43511134,  0.05227658,  0.22538292, -0.33610708, -0.24073264,\n        -0.11631134,  0.19609821, -0.1463159 , -0.23701647, -0.27477014,\n        -0.00803208, -0.30782825, -0.06204507, -0.4332657 ],\n       [-0.15951926, -0.42244697, -0.36327147,  0.13173705,  0.4381562 ,\n        -0.1832223 , -0.07673946,  0.36293584,  0.03496256, -0.05875954,\n        -0.4082053 ,  0.4394955 , -0.27438956,  0.30430222],\n       [-0.19099742, -0.262466  ,  0.42200714, -0.01743665, -0.14440179,\n        -0.43374088, -0.41629657, -0.44326136, -0.06069392, -0.02381948,\n        -0.37830546, -0.17085308, -0.39194438, -0.3735995 ],\n       [-0.21835524,  0.32811147,  0.31110203, -0.44691578, -0.1312688 ,\n        -0.28479952, -0.03312552,  0.12220156,  0.4244148 ,  0.04352498,\n        -0.43723762,  0.19512689,  0.36836195,  0.19598359],\n       [ 0.4349904 ,  0.24350911,  0.12747288,  0.24327177,  0.24842739,\n         0.02442011,  0.4017105 ,  0.26086932,  0.17216551, -0.41140008,\n        -0.00046167, -0.1456126 , -0.03210396, -0.44616824],\n       [-0.11577162, -0.41452843,  0.06066757,  0.02752072, -0.00108683,\n        -0.10233253,  0.330913  ,  0.04952547,  0.02544251,  0.41391402,\n         0.3676225 , -0.2692659 ,  0.4290594 ,  0.19718033],\n       [-0.09558249, -0.09936124, -0.0606854 , -0.04604527,  0.18186319,\n         0.10798508, -0.10757905, -0.37000978, -0.12444761, -0.00389412,\n        -0.39288694, -0.12093318,  0.41579086,  0.03439862],\n       [ 0.346964  , -0.32786238, -0.12498787,  0.04235926,  0.42971432,\n         0.25695848, -0.1967724 , -0.10078508,  0.33943313, -0.27776307,\n         0.38370168, -0.33239508,  0.02901506, -0.03902492],\n       [ 0.23699182,  0.22165698,  0.44713557,  0.20436555,  0.42451715,\n         0.2875139 ,  0.24736059, -0.40996116,  0.2479403 ,  0.25635892,\n         0.03409293, -0.00508052, -0.09044427,  0.25067407],\n       [ 0.09033829,  0.44248718,  0.0131073 , -0.2827635 ,  0.09693849,\n         0.19768524,  0.3352431 , -0.01135877, -0.12357479, -0.14077368,\n         0.13370335,  0.15253443,  0.42119414, -0.14300692],\n       [ 0.17789769,  0.2852214 ,  0.06507391,  0.09993708,  0.31887257,\n         0.3990301 , -0.21353275,  0.20507991,  0.02838919, -0.14955512,\n         0.11901867,  0.34645092, -0.42220065, -0.26866025],\n       [-0.38176563, -0.09448126, -0.09368616,  0.24353439,  0.00407273,\n         0.1364153 ,  0.29859537, -0.3753091 , -0.27461115,  0.08365381,\n        -0.39045313,  0.09525162,  0.252635  , -0.25779623]],\n      dtype=float32)>), (None, <tf.Variable 'Encode_last_dense/bias:0' shape=(14,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/kernel:0' shape=(124, 256) dtype=float32, numpy=\narray([[-0.09602914,  0.0206054 ,  0.05003852, ...,  0.11691457,\n         0.01888394,  0.00686687],\n       [-0.08121756, -0.06287105,  0.07644905, ..., -0.11417445,\n        -0.12489573,  0.07514276],\n       [-0.08978828,  0.08156046,  0.02344207, ...,  0.09093824,\n        -0.04955614, -0.08691775],\n       ...,\n       [-0.09871513,  0.07279322, -0.01567698, ..., -0.11646644,\n        -0.09626462,  0.08802012],\n       [-0.00237435,  0.10235688,  0.10367432, ...,  0.00675358,\n        -0.00800576,  0.09696451],\n       [-0.03635739,  0.06430128,  0.00420938, ..., -0.08154231,\n         0.08758235, -0.03847566]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf1/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/kernel:0' shape=(8, 8) dtype=float32, numpy=\narray([[-0.4385894 ,  0.15461665,  0.39588577,  0.0386939 ,  0.04479468,\n        -0.09826344,  0.19699633, -0.18545204],\n       [ 0.33092505, -0.01353562, -0.26279956,  0.13427329, -0.51454467,\n         0.05445749,  0.07413012, -0.5146835 ],\n       [-0.13523355,  0.21030974, -0.36462384,  0.20058054, -0.2360405 ,\n         0.03501451, -0.05378443, -0.5208618 ],\n       [ 0.18130314,  0.46856862,  0.5268943 , -0.3035458 , -0.3832292 ,\n        -0.2246714 , -0.0474112 , -0.5826779 ],\n       [ 0.43082553,  0.08697075,  0.24999642,  0.2991652 ,  0.08303326,\n        -0.57571775, -0.133809  , -0.6098237 ],\n       [ 0.38420373,  0.14263403, -0.55154204, -0.4199861 ,  0.1673364 ,\n        -0.466442  , -0.24007946,  0.5817091 ],\n       [ 0.44497603,  0.25478995, -0.22779977, -0.28558928, -0.26542583,\n         0.5840122 , -0.37215865, -0.12076676],\n       [ 0.13379937, -0.25267613,  0.19722909,  0.07469177,  0.49674124,\n         0.48525888, -0.0412733 ,  0.1425342 ]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/r3->FeatureExtractor->cf2/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/kernel:0' shape=(256, 8) dtype=float32, numpy=\narray([[ 0.01262662,  0.05650933, -0.07557854, ...,  0.08060171,\n         0.07018189,  0.12418863],\n       [-0.1403246 ,  0.04757459, -0.1080391 , ...,  0.1399554 ,\n         0.10882303, -0.05271796],\n       [ 0.10391629, -0.08590183, -0.09136627, ...,  0.11373794,\n         0.01352437,  0.113599  ],\n       ...,\n       [-0.11158414,  0.00363182,  0.13975453, ..., -0.02873233,\n        -0.0296543 , -0.01717056],\n       [-0.06577233, -0.09036508,  0.05360132, ..., -0.03513823,\n        -0.11046873, -0.00425044],\n       [-0.02095079, -0.00513585, -0.1340391 , ..., -0.06767814,\n         0.06926836, -0.02829189]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/feature_extractor_7/featureExtractor_stateFC/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/kernel:0' shape=(124, 256) dtype=float32, numpy=\narray([[ 0.1255088 ,  0.09892711, -0.02228037, ...,  0.11655751,\n         0.03712787,  0.06265666],\n       [-0.06920841,  0.02177346,  0.04313475, ..., -0.06275918,\n        -0.00020368, -0.05691434],\n       [-0.02655125, -0.10888477, -0.055384  , ..., -0.05163211,\n         0.02229193, -0.02852656],\n       ...,\n       [-0.03305863,  0.07967381,  0.01856446, ..., -0.04513834,\n        -0.01759784, -0.00189046],\n       [ 0.12000702,  0.00762276, -0.03809982, ...,  0.12044634,\n         0.10092402, -0.00195008],\n       [ 0.08548132,  0.05697441, -0.09805112, ..., -0.00486378,\n        -0.01647208,  0.08491004]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf1/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/kernel:0' shape=(8, 2) dtype=float32, numpy=\narray([[ 0.17138177,  0.6050559 ],\n       [-0.33472118,  0.6827978 ],\n       [ 0.42242908, -0.4936069 ],\n       [ 0.1765827 , -0.5710938 ],\n       [-0.04441142, -0.3474577 ],\n       [ 0.4004295 ,  0.08964872],\n       [-0.52785236, -0.09692615],\n       [-0.6678139 , -0.23122269]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/r3->PhaseEstimator->cf2/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/kernel:0' shape=(256, 8) dtype=float32, numpy=\narray([[-0.00045694,  0.08325186,  0.10804152, ...,  0.02599585,\n        -0.09746647,  0.00924665],\n       [-0.11468854, -0.11348359, -0.11939922, ...,  0.03350638,\n         0.1309045 , -0.09932109],\n       [ 0.04327439, -0.0718836 , -0.00549513, ...,  0.10426226,\n        -0.14678057, -0.0988575 ],\n       ...,\n       [ 0.05972914, -0.03520325,  0.1081925 , ..., -0.02397589,\n         0.11819682, -0.08707597],\n       [ 0.05072881, -0.01016484,  0.0572127 , ...,  0.04210541,\n        -0.01278523,  0.07204755],\n       [-0.09778302,  0.06835544, -0.05484582, ..., -0.07837775,\n        -0.00352407,  0.05214331]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/phase_estimator_7/PhaseEstimator_stateFC/bias:0' shape=(8,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/kernel:0' shape=(22, 256) dtype=float32, numpy=\narray([[-0.02881597, -0.02066214, -0.04428317, ...,  0.13636148,\n        -0.01898035,  0.10682216],\n       [-0.1296188 ,  0.0684949 , -0.08894788, ..., -0.08172371,\n         0.00701697, -0.13412581],\n       [-0.01989503,  0.11153594,  0.02727145, ..., -0.0019471 ,\n         0.10452238, -0.13863912],\n       ...,\n       [ 0.10514611, -0.04605528,  0.07571094, ...,  0.08980994,\n         0.1093601 , -0.00806329],\n       [-0.06132045, -0.09953479, -0.05740868, ..., -0.11216252,\n        -0.0304207 , -0.02276358],\n       [-0.03319267,  0.06296608, -0.11596037, ...,  0.06346412,\n         0.06949914, -0.07063578]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf1/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/kernel:0' shape=(256, 256) dtype=float32, numpy=\narray([[ 0.00353738,  0.08921119, -0.10816082, ...,  0.0285866 ,\n        -0.02523169, -0.02119195],\n       [ 0.0413932 ,  0.05399486, -0.08463463, ...,  0.00501237,\n        -0.00779955, -0.07802269],\n       [-0.07490572, -0.07233222, -0.08687227, ..., -0.06065837,\n         0.08898611, -0.04535636],\n       ...,\n       [ 0.08897906, -0.02361725, -0.04401185, ..., -0.07488058,\n         0.00930489,  0.08641528],\n       [-0.00453417,  0.01662072,  0.07192967, ..., -0.07897222,\n        -0.07941305,  0.08892032],\n       [ 0.10529102,  0.08998635,  0.04625849, ..., -0.06259479,\n        -0.09103437, -0.01632912]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/r3->Rx_Decoder_new->cf2/bias:0' shape=(256,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0.], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/kernel:0' shape=(256, 16) dtype=float32, numpy=\narray([[ 0.03853336,  0.04469034,  0.10974187, ...,  0.0544221 ,\n         0.13371643,  0.002748  ],\n       [-0.00804029,  0.08272548, -0.06219885, ...,  0.03281567,\n        -0.03633802, -0.02241693],\n       [-0.11594397, -0.01124713, -0.14381337, ...,  0.04935078,\n        -0.08052032, -0.04279769],\n       ...,\n       [-0.08878183, -0.06218285,  0.02266562, ..., -0.10762064,\n        -0.06609511, -0.09306784],\n       [-0.1081979 ,  0.13315436,  0.05201417, ...,  0.02699493,\n         0.02303644, -0.14669624],\n       [ 0.08752851,  0.04627149,  0.04585549, ..., -0.13453324,\n         0.07126364,  0.05330408]], dtype=float32)>), (None, <tf.Variable 'sequence_decoder_7/rx__decoder_new_7/final_out_cf3/bias:0' shape=(16,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n      dtype=float32)>))."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "end2end = End2EndSys()\n",
    "\n",
    "# end2end(x_train).shape\n",
    "\n",
    "end2end.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "               loss=SparseCategoricalCrossentropy(from_logits=True))\n",
    "\n",
    "\n",
    "end2end.custom_fit(x_train,y_train,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:18.787461Z",
     "start_time": "2024-04-16T15:45:18.773424Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMXg7FqQsYoU",
    "outputId": "2de71e71-5be4-45dc-cb21-5f6044d91932"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56.1875, 60)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17980/320,17980%320\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:19.869762Z",
     "start_time": "2024-04-16T15:45:18.791451Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G7XwICWFtf06",
    "outputId": "79af9993-71f3-4dbc-fd03-1e8a6412c8a8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18376/4097829577.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Encoder' is not defined"
     ]
    }
   ],
   "source": [
    "Encoder(x_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:19.875339Z",
     "start_time": "2024-04-16T15:45:19.875339Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6VG8egR82WV",
    "outputId": "ec21fdc1-1486-4e42-f996-2b827bb1d792"
   },
   "outputs": [],
   "source": [
    "(2*28+30) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:19.876335Z",
     "start_time": "2024-04-16T15:45:19.876335Z"
    },
    "id": "3FbYic3G88ti"
   },
   "outputs": [],
   "source": [
    "(17980-60)/(28*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T15:45:19.877331Z",
     "start_time": "2024-04-16T15:45:19.877331Z"
    }
   },
   "outputs": [],
   "source": [
    "ExternalSlicer(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
