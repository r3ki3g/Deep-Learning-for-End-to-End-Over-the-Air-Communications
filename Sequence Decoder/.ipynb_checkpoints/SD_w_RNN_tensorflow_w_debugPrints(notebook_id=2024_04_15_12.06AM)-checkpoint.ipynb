{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VSTgsilO1_ur"
   },
   "source": [
    "online version of this notebook : https://colab.research.google.com/drive/12iz5_mTOmTa0oyn5IZZYnEskVUonViVW#scrollTo=VSTgsilO1_ur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:33.110175Z",
     "start_time": "2024-04-14T18:38:23.288057Z"
    },
    "id": "pWavhXJRGytK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.activations import relu, softmax\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:33.141438Z",
     "start_time": "2024-04-14T18:38:33.125802Z"
    },
    "id": "4k-_9gsVQnu1"
   },
   "outputs": [],
   "source": [
    "def get_feature_extractor():\n",
    "  raise NotImplementedError()\n",
    "\n",
    "def get_internal_slicer():\n",
    "  raise NotImplementedError()\n",
    "\n",
    "\n",
    "def get_rx_decoder():\n",
    "  raise NotImplementedError()\n",
    "\n",
    "def phase_multiply(internally_sliced_y,h):\n",
    "  raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNx0nzHGxCtg"
   },
   "source": [
    "## PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:33.203926Z",
     "start_time": "2024-04-14T18:38:33.188303Z"
    },
    "id": "8llGxbteuvUt"
   },
   "outputs": [],
   "source": [
    "SLICED_Y_LENGTH = 16\n",
    "BATCH_SIZE =  2048\n",
    "\n",
    "# in teh feature extractor path \"f\" : design param\n",
    "# Our experiments have shown that even a\n",
    "# small number of features, e.g., F = 4, significantly improves\n",
    "# the performance.\n",
    "N_FEATURES_EXTRACTED = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:33.235594Z",
     "start_time": "2024-04-14T18:38:33.219966Z"
    },
    "id": "AU4v5qeU_LTW"
   },
   "outputs": [],
   "source": [
    "def R2C(a):\n",
    "#     print(\"reached here 01\")\n",
    "#     print(a.shape)\n",
    "    aa = tf.cast(tf.reshape(a,shape=(BATCH_SIZE,-1,2)),tf.float32)\n",
    "    # print(aa)\n",
    "    aaa = tf.complex(aa[:,:,0],aa[:,:,1])\n",
    "    return aaa\n",
    "\n",
    "def C2R(a):\n",
    "    real, imag = tf.expand_dims(tf.math.real(a),axis=2) ,tf.expand_dims(tf.math.imag(a), axis=2)\n",
    "    R = tf.concat((real,imag),axis=2)\n",
    "    R = tf.reshape(R , (BATCH_SIZE,-1)  )\n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG_PMHaC_Nbd"
   },
   "source": [
    "## Main Blocks in the Sequence Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:33.282464Z",
     "start_time": "2024-04-14T18:38:33.251218Z"
    },
    "id": "Mx-vTDXeUVmT"
   },
   "outputs": [],
   "source": [
    "\n",
    "class FeatureExtractor(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "\n",
    "        self.cf2 = Dense(N_FEATURES_EXTRACTED)\n",
    "\n",
    "        self.cf_state = Dense(8)\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE):\n",
    "        print(\"sliced_y.shape\", sliced_y.shape)\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "        state_FE = self.cf_state(sliced_y) # state calculated here\n",
    "        sliced_y = self.cf2(sliced_y)\n",
    "        return sliced_y,state_FE\n",
    "\n",
    "class PhaseEstimator(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "        self.cf2 = Dense(2)\n",
    "\n",
    "        self.cf_state = Dense(8)\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_PE):\n",
    "        sliced_y = self.cf1(sliced_y)\n",
    "        sliced_y = relu(sliced_y)\n",
    "        state_PE = self.cf_state(sliced_y) # state calculated here\n",
    "        sliced_y = self.cf2(sliced_y)\n",
    "        return sliced_y,state_PE\n",
    "\n",
    "\n",
    "class Rx_Decoder_old(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "        self.cf2 = Dense(256)\n",
    "        self.cf3 = Dense(16)\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "\n",
    "class Rx_Decoder_new(Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cf1 = Dense(256)\n",
    "        self.cf2 = Dense(256)\n",
    "        self.cf3 = Dense(16,name=\"final_out_cf3\")\n",
    "\n",
    "        # useless\n",
    "        #self.cf4_state = Dense(8,name=\"state_dense_cf4\")\n",
    "\n",
    "    def call(self,concat):\n",
    "\n",
    "        concat = self.cf1(concat)\n",
    "        concat = relu(concat)\n",
    "        concat = self.cf2(concat)\n",
    "        concat = relu(concat)\n",
    "\n",
    "        # state = self.cf4_state(concat)\n",
    "        concat = self.cf3(concat)\n",
    "\n",
    "\n",
    "\n",
    "        # do not use softmax here : put from logit  = True in loss func\n",
    "        # concat = softmax(concat)\n",
    "\n",
    "        return concat\n",
    "\n",
    "class InternalSlicer(Model):\n",
    "    def __init__(self,l1,l2,complex_length):\n",
    "        super().__init__()\n",
    "\n",
    "        # define the slice boundaries\n",
    "        mid = complex_length // 2\n",
    "        self.start = mid - l1\n",
    "        self.end = mid + l2 + 1\n",
    "\n",
    "    def call(self,sliced_y):\n",
    "        print(f\"internal slicer : sliced_y.shape : {sliced_y.shape}\")\n",
    "        ret = C2R(R2C(sliced_y)[:, self.start:self.end])\n",
    "        print(f\"internal slicer : ret.shape : {ret.shape}\")\n",
    "        return ret\n",
    "\n",
    "\n",
    "def phase_multiply(internally_sliced_y,estimated_phase):\n",
    "    # (a,b) * (c,d) = (ac-bd,ad+bc)\n",
    "    print(\"internally_sliced_y.shape:\", internally_sliced_y.shape)\n",
    "    print(\"estimated_phase.shape: \", estimated_phase.shape)\n",
    "    internally_sliced_y_complex = R2C(internally_sliced_y)\n",
    "    estimated_phase_complex = R2C(estimated_phase)\n",
    "    phase_corrected_complex = estimated_phase_complex * internally_sliced_y_complex\n",
    "\n",
    "    phase_corrected = C2R(phase_corrected_complex)\n",
    "    return phase_corrected\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2T9CJbZr_UgK"
   },
   "source": [
    "## Fake data syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:34.101751Z",
     "start_time": "2024-04-14T18:38:33.298096Z"
    },
    "id": "mj1GemkdxHCs"
   },
   "outputs": [],
   "source": [
    "# generate fake data\n",
    "m = 512* 2** 2\n",
    "X = tf.random.normal(shape=(m,SLICED_Y_LENGTH),\n",
    "                     mean=0,\n",
    "                     stddev=1)\n",
    "\n",
    "Y = tf.random.uniform(shape=(m,1),\n",
    "                      minval=0,\n",
    "                      maxval=16,\n",
    "                      dtype=tf.int32)\n",
    "# Y = keras.utils.to_categorical(Y,16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4xqcXAB_XdM"
   },
   "source": [
    "## Main Model : Sequence Decoder Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:34.133402Z",
     "start_time": "2024-04-14T18:38:34.117774Z"
    },
    "id": "M_bSkx9vHEAd"
   },
   "outputs": [],
   "source": [
    "# sequence decoder\n",
    "\n",
    "\n",
    "class SequenceDecoder(Model):\n",
    "\n",
    "    def __init__(self,take_prev_phase_state=False):\n",
    "        super(SequenceDecoder,self).__init__()\n",
    "\n",
    "        self.take_prev_phase_state = take_prev_phase_state\n",
    "\n",
    "        self.feature_extractor = FeatureExtractor()\n",
    "        self.phase_estimator = PhaseEstimator()\n",
    "        self.internal_slicer = InternalSlicer(l1=3,l2=3,complex_length=SLICED_Y_LENGTH//2)\n",
    "        if take_prev_phase_state:\n",
    "            self.rx_decoder_RNN = Rx_Decoder_new()\n",
    "        else:\n",
    "            raise Exception(\"How here come??\")\n",
    "            self.rx_decoder = Rx_Decoder_old()\n",
    "\n",
    "\n",
    "\n",
    "    def call(self,sliced_y,prev_state_FE=None,prev_state_PE=None):\n",
    "\n",
    "        if prev_state_PE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_PE = tf.constant(tf.zeros((X.shape[0],8)))\n",
    "        if prev_state_FE is None:\n",
    "            print(\" How this none?\")\n",
    "            prev_state_FE = tf.constant(tf.zeros((X.shape[0],8)))\n",
    "\n",
    "\n",
    "        # RNN conn starts here\n",
    "\n",
    "        output_FE = self.feature_extractor(sliced_y,prev_state_FE=prev_state_FE)\n",
    "        extracted_features,state_FE = output_FE[0], output_FE[1]\n",
    "\n",
    "        output_PE = self.phase_estimator(sliced_y,prev_state_PE=prev_state_PE)\n",
    "        estimated_phase,state_PE = output_PE[0], output_PE[1]\n",
    "\n",
    "        # RNN conn ends here\n",
    "\n",
    "        internally_sliced_y = self.internal_slicer(sliced_y)\n",
    "\n",
    "        print(\"SD call estimated_phase.shape\",estimated_phase.shape)\n",
    "        print(\"SD call internally_sliced_y.shape\",internally_sliced_y.shape)\n",
    "\n",
    "        phase_corrected_ = phase_multiply(internally_sliced_y,estimated_phase)\n",
    "\n",
    "        concat = tf.concat((extracted_features,phase_corrected_),axis=1)\n",
    "        if self.take_prev_phase_state:\n",
    "            st_hat = self.rx_decoder_RNN(concat)\n",
    "            return (st_hat,state_FE,state_PE)\n",
    "        else:\n",
    "            print(\"--PROBLEM--\")\n",
    "            st_hat = self.rx_decoder(concat)\n",
    "            return st_hat\n",
    "\n",
    "\n",
    "\n",
    "    def custom_train(self,X,Y,epochs=1): # X =  vertically stacked sliced_y, y = message index\n",
    "\n",
    "        # temp_prev_state_PE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last PE state here\n",
    "        # temp_prev_state_FE = [tf.constant(tf.zeros((X.shape[0],8)))] #append the last FE state here\n",
    "\n",
    "        temp_prev_state_PE = tf.constant(tf.zeros((X.shape[0],8)))\n",
    "        temp_prev_state_FE = tf.constant(tf.zeros((X.shape[0],8)))\n",
    "\n",
    "        loss_acc = 0\n",
    "\n",
    "        # tarin per each time step\n",
    "        for i in range(epochs):\n",
    "            print(f\"iterration : {i}\")\n",
    "            x = X # tf.expand_dims(X[i,:],axis=0)\n",
    "            print(\"x shape:\", x.shape)\n",
    "            y = Y # tf.expand_dims(Y[i,:],axis=0)\n",
    "            print(\"y shape:\", y.shape)\n",
    "            with tf.GradientTape() as tape:\n",
    "                output = self.call(x,\n",
    "                                   prev_state_PE=temp_prev_state_PE,\n",
    "                                   prev_state_FE=temp_prev_state_FE)\n",
    "                st_hat,state_FE,state_PE = output[0], output[1], output[2]\n",
    "                loss = self.compiled_loss(y,st_hat)\n",
    "\n",
    "                #temp_prev_state = state ###### assign add dala balanna\n",
    "                # print and see the shapes\n",
    "                print(\"state_FE.shape\",state_FE.shape)\n",
    "                print(\"state_PE.shape\",state_PE.shape)\n",
    "                print(\"----------\")\n",
    "                temp_prev_state_FE = (state_FE)\n",
    "                temp_prev_state_PE = (state_PE)\n",
    "\n",
    "            grads = tape.gradient(loss,self.trainable_variables)\n",
    "            self.optimizer.apply_gradients(zip(grads,self.trainable_variables))\n",
    "\n",
    "            loss_acc += tf.stop_gradient(loss).numpy()\n",
    "\n",
    "        return loss_acc\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:34.164648Z",
     "start_time": "2024-04-14T18:38:34.149024Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jq24YZr4baut",
    "outputId": "564196e5-8ea8-4bff-f6b2-342e1ab44a53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2048, 16])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:34.572546Z",
     "start_time": "2024-04-14T18:38:34.180280Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KqIhonChiDnM",
    "outputId": "68a00c82-c708-402c-a293-339cdced29e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterration : 0\n",
      "x shape: (2048, 16)\n",
      "y shape: (2048, 1)\n",
      "sliced_y.shape (2048, 16)\n",
      "internal slicer : sliced_y.shape : (2048, 16)\n",
      "internal slicer : ret.shape : (2048, 14)\n",
      "SD call estimated_phase.shape (2048, 2)\n",
      "SD call internally_sliced_y.shape (2048, 14)\n",
      "internally_sliced_y.shape: (2048, 14)\n",
      "estimated_phase.shape:  (2048, 2)\n",
      "state_FE.shape (2048, 8)\n",
      "state_PE.shape (2048, 8)\n",
      "----------\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['feature_extractor/dense_2/kernel:0', 'feature_extractor/dense_2/bias:0', 'phase_estimator/dense_5/kernel:0', 'phase_estimator/dense_5/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.7816436290740967"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the SD\n",
    "\n",
    "mySD =   SequenceDecoder(take_prev_phase_state=True)\n",
    "\n",
    "mySD.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "             loss=SparseCategoricalCrossentropy(from_logits=True),\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "mySD.custom_train(X,Y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-14T18:38:34.603794Z",
     "start_time": "2024-04-14T18:38:34.588163Z"
    },
    "id": "_rXUaAKBtGjj"
   },
   "outputs": [],
   "source": [
    "# mySD.build((2048,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
